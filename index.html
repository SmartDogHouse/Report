<!DOCTYPE html>
<html  dir="ltr">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title></title>
        <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
        <link rel="apple-touch-icon-precomposed" href="images/apple-touch-icon.png">

<link rel="stylesheet" href="./pandoc-uikit/uikit.css">

        <link rel="stylesheet" href="style.css">
        <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />
        <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
        <script src="./pandoc-uikit/uikit.js"></script>
        <script src="./pandoc-uikit/scripts.js"></script>
        <script src="./pandoc-uikit/jquery.sticky-kit.js"></script>

        <meta name="generator" content="pandoc-uikit" />
                <meta name="author" content="Kiade Sara " />
                <meta name="author" content="Caminati Gyordan " />
                <meta name="author" content="Lirussi Igor    Numero Gruppo: 97" />
                        <title>main</title>
        <style type="text/css">code{white-space: pre;}</style>
                                                    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
                               
    </head>

    <body>


        <div class="uk-container uk-container-center uk-margin-top uk-margin-large-bottom">

            
            <div class="uk-grid" data-uk-grid-margin >          
                <div class="uk-width-medium-1-4">
                    <div class="uk-overflow-container" data-uk-sticky="{top:25,media: 768}">
                        <div class="uk-panel uk-panel-box menu-begin" >

                                                        <ul class="incremental">
                                                        <li><a href="#introduzione"><span class="toc-section-number">1</span> Introduzione</a>
                                                        <ul class="incremental">
                                                        <li><a href="#overview"><span class="toc-section-number">1.1</span> Overview</a></li>
                                                        <li><a href="#problemi"><span class="toc-section-number">1.2</span> Problemi</a></li>
                                                        <li><a href="#obiettivi"><span class="toc-section-number">1.3</span> Obiettivi</a></li>
                                                        </ul></li>
                                                        <li><a href="#stato-dellarte"><span class="toc-section-number">2</span> Stato dell’Arte</a></li>
                                                        <li><a href="#analisi-dei-requisiti"><span class="toc-section-number">3</span> Analisi dei Requisiti</a>
                                                        <ul class="incremental">
                                                        <li><a href="#requisiti-di-business"><span class="toc-section-number">3.1</span> Requisiti di Business</a></li>
                                                        <li><a href="#requisiti-utente"><span class="toc-section-number">3.2</span> Requisiti Utente</a></li>
                                                        <li><a href="#requisiti-funzionali"><span class="toc-section-number">3.3</span> Requisiti Funzionali</a></li>
                                                        <li><a href="#requisiti-non-funzionali"><span class="toc-section-number">3.4</span> Requisiti non Funzionali</a></li>
                                                        <li><a href="#requisiti-implementativi"><span class="toc-section-number">3.5</span> Requisiti Implementativi</a></li>
                                                        </ul></li>
                                                        <li><a href="#design-architetturale"><span class="toc-section-number">4</span> Design Architetturale</a>
                                                        <ul class="incremental">
                                                        <li><a href="#architettura-generale"><span class="toc-section-number">4.1</span> Architettura Generale</a></li>
                                                        <li><a href="#scelte-tecnologiche-cruciali"><span class="toc-section-number">4.2</span> Scelte Tecnologiche Cruciali</a></li>
                                                        <li><a href="#pattern-architetturali-utilizzati"><span class="toc-section-number">4.3</span> Pattern Architetturali Utilizzati</a></li>
                                                        </ul></li>
                                                        <li><a href="#design-di-dettaglio"><span class="toc-section-number">5</span> Design di Dettaglio</a>
                                                        <ul class="incremental">
                                                        <li><a href="#design-del-database"><span class="toc-section-number">5.1</span> Design del Database</a></li>
                                                        </ul></li>
                                                        <li><a href="#implementazione"><span class="toc-section-number">6</span> Implementazione</a>
                                                        <ul class="incremental">
                                                        <li><a href="#microcontrollori"><span class="toc-section-number">6.1</span> Microcontrollori</a></li>
                                                        <li><a href="#raspberry"><span class="toc-section-number">6.2</span> Raspberry</a></li>
                                                        </ul></li>
                                                        <li><a href="#testing-e-performance"><span class="toc-section-number">7</span> Testing e Performance</a>
                                                        <ul class="incremental">
                                                        <li><a href="#automazione-gabbia-e-monitoraggio-salute"><span class="toc-section-number">7.1</span> Automazione Gabbia e Monitoraggio Salute</a></li>
                                                        <li><a href="#videosorveglianza"><span class="toc-section-number">7.2</span> Videosorveglianza</a></li>
                                                        </ul></li>
                                                        <li><a href="#analisi-di-deployment-su-larga-scala"><span class="toc-section-number">8</span> Analisi di Deployment su Larga Scala</a></li>
                                                        <li><a href="#piano-di-lavoro"><span class="toc-section-number">9</span> Piano di Lavoro</a></li>
                                                        <li><a href="#iterazioni"><span class="toc-section-number">10</span> Iterazioni</a>
                                                        <ul class="incremental">
                                                        <li><a href="#sprint-0"><span class="toc-section-number">10.1</span> Sprint 0</a></li>
                                                        <li><a href="#sprint-1"><span class="toc-section-number">10.2</span> Sprint 1</a></li>
                                                        <li><a href="#sprint-2"><span class="toc-section-number">10.3</span> Sprint 2</a></li>
                                                        <li><a href="#sprint-3"><span class="toc-section-number">10.4</span> Sprint 3</a></li>
                                                        <li><a href="#sprint-4"><span class="toc-section-number">10.5</span> Sprint 4</a></li>
                                                        </ul></li>
                                                        <li><a href="#conclusioni"><span class="toc-section-number">11</span> Conclusioni</a></li>
                                                        </ul>
                            
                        </div>
                    </div>
                </div>

                <div class="uk-width-medium-3-4">
<section id="introduzione" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduzione</h1>
<p>Si vuole realizzare una soluzione in grado di fornire supporto alla <strong>gestione di un canile</strong> comunale, al fine di migliorarne le condizioni e alleggerire il carico di lavoro che grava sui gestori, il quale numero risulta essere sottodimensionato.</p>
<section id="overview" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> Overview</h2>
<p>Come riferimento è stato preso in considerazione il canile comunale di Pisa, il quale gestore si è offerto di indirizzarci permettendoci di rivolgerci a lui per avere feedback e indicazioni basate su esperienze reali.</p>
<p>L’idea ha avuto origine dopo un colloquio con il gestore del canile che, raccontando la propria esperienza, ha evidenziato alcuni problemi che riscontra nello svolgimento del proprio lavoro, molti dei quali sono risolvibili attraverso gli strumenti e le competenze che abbiamo a disposizione. Tuttavia, questo non può essere considerato un progetto su commissione, ma abbiamo fede nel fatto che una volta sviluppata la nostra soluzione questa possa essere utilizzato come base per sviluppare altri sistemi o rendere più tecnologici canili e gattili che riscontrano le stesse difficoltà.</p>
</section>
<section id="problemi" data-number="1.2">
<h2 data-number="1.2"><span class="header-section-number">1.2</span> Problemi</h2>
<p>Il canile di Pisa ospita circa una sessantina di cani e gatti di diversa taglia, randagi o abbandonati, che vengono prelevati dagli addetti del canile su segnalazione dei cittadini. I cani restano poi in cura finché non vengono adottati, mentre i gatti vengono rilasciati subito dopo aver ricevuto le cure mediche ed essersi ripresi. Ad occuparsi della salute dei cani è un <strong>responsabile sanitario</strong> sempre presente nella struttura, che coordina alcuni <strong>veterinari</strong> convenzionati con la struttura.</p>
<p>I principali problemi che vengono attualmente riscontrati sono i seguenti:</p>
<ul class="incremental">
<li><p><strong>responsabile sanitario:</strong> responsabile sanitario e i veterinari convenzionati, risiedono all’interno del canile. Attualmente non è possibile monitorare lo stato di salute di un animale, questo spesso si traduce in un intervento tardivo che se diagnosticato per tempo risulterebbe più gestibile.</p></li>
<li><p><strong>Rifornimento e consumi di cibo ed acqua:</strong> la maggior parte del lavoro manuale viene svolta dai volontari che prestano attività in forma gratuita e fortemente discontinua. Non è possibile sapere a priori quanti volontari si presenteranno a dare una mano, ed essendo in tanti non è nemmeno possibile sapere chi ha svolto quali mansioni. Operazioni come il rifornimento di cibo ed acqua vanno quindi monitorate personalmente dal gestore che deve recarsi fisicamente nelle gabbie per controllare gli approvvigionamenti; inoltre non è nemmeno possibile conoscere la quantità di cibo ed acqua consumata da un cane, il che rende più difficile individuare i segnali alimentari che sono sintomi di alcuni problemi di salute.</p></li>
<li><p><strong>Sorveglianza:</strong> il canile di Pisa, attualmente, non dispone di un sistema di sorveglianza da remoto, pertanto nel momento in cui si verificano furti, effrazioni ed atti vandalici, non è possibile risalire agevolmente al colpevole. E’ assente anche un sistema che possa permettere di sorvegliare da remoto cani che hanno particolari problemi. Nel caso di una gravidanza che volge al termine, ad esempio, il personale del canile è costretto a recarsi frequentemente sul luogo, durante la notte, per controllare se ha avuto inizio il travaglio o se si stanno verificando delle complicanze. Questa necessità crea un disagio al personale che si trova a doversi recare in canile fuori dall’orario di lavoro.</p></li>
<li><p><strong>Assenza di supporto informatico</strong>: attualmente il canile non dispone di un’infrastruttura informatica già presente,da poter integrare; inoltre non dispone nemmeno di un gestionale che dia supporto nella catalogazione degli animali presi in cura.</p></li>
</ul>
</section>
<section id="obiettivi" data-number="1.3">
<h2 data-number="1.3"><span class="header-section-number">1.3</span> Obiettivi</h2>
<p>L’obiettivo è quello di rendere il canile più "Smart", introducendo della strumentazione che permetta di risolvere in maniera parziale o totale le problematiche descritte precedentemente, mantenendo un costo accessibile. Nello specifico si vogliono incontrare le esigenze del gestore e degli addetti, agevolando le operazioni di:</p>
<ul class="incremental">
<li><p><strong>monitoraggio dello stato di salute dei cani</strong> tramite:</p>
<ul class="incremental">
<li><p>rilevazione dei <strong>consumi</strong> di cibo e acqua;</p></li>
<li><p>monitoraggio del <strong>comportamento</strong> del cane.</p></li>
</ul>
<p>In questo modo è possibile cogliere in maniera preventiva segnali che possono indicare un problema di salute e aiutare il <strong>responsabile sanitario</strong> nella risoluzione e nella diagnosi dello stesso.</p></li>
<li><p>automatizzazione delle operazioni di <strong>cura quotidiana</strong> attraverso:</p>
<ul class="incremental">
<li><p>automatizzazione del <strong>rifornimento</strong> di cibo e acqua</p></li>
<li><p>possibilità di scegliere, per ciascun cane, la <strong>quantità</strong> del cibo da somministrare e la <strong>frequenza</strong>.</p></li>
</ul>
<p>In questo modo è possibile gestire in maniera più precisa l’alimentazione dei cani e impostare delle quantità di cibo particolari in caso di condizioni di salute che richiedono un particolare piano alimentare, sollevando da questo incarico i volontari, che svolgono un’attività non tracciabile e discontinua. Inoltre, sarà possibile per il <strong>responsabile sanitario</strong> consultare i dati riguardanti l’alimentazione del cane e, di conseguenza, fornire diagnosi più precise.</p></li>
<li><p><strong>sorveglianza globale del canile da remoto</strong>: l’introduzione di un sistema di sorveglianza permetterà a chi di competenza di monitorare lo stato del canile anche da casa.</p></li>
<li><p><strong>Mantenimento dello storico dei dati registrati</strong>: in questo modo sarà possibile consultare sia le informazioni riguardanti i cani che i dati che riguardano le condizioni del canile, permettendo anche di fare dei confronti su base temporale;</p></li>
<li><p><strong>consultazione dei dati acquisiti ed elaborati:</strong> verrà fornita la possibilità di accedere allo storico dei dati medici su un Database, affinché il veterinario abbia una visione globale del quadro medico e possa velocemente filtrare le informazioni anche se non ha seguito il paziente dall’inizio.</p></li>
<li><p><em><span>[</span>optional<span>]</span></em> <strong>monitoraggio approfondito dei parametri vitali</strong>: mediante l’installazione di sensoristica che permetta il monitoraggio di temperatura, battiti, movimento, ecc… sarà possibile tenere ulteriormente sott’occhio cani che si trovano in condizioni di salute che necessitano di particolari attenzioni.</p></li>
<li><p><strong>Introduzione di un sistema informatico:</strong> poiché non vi è un sistema informatico preesistente da integrare e vi sono poche disponibilità economiche, si è pensato di avvalersi di una piattaforma cloud sulla quale è possibile mantenere lo storico ed operare tramite l’utilizzo di un broker MQTT per la comunicazione con sensori e attuatori. Questa soluzione è stata indicata come preferibile dal canile che ritiene più accessibile pagare mensilmente un servizio piuttosto che investire in una soluzione ad hoc.</p></li>
</ul>
</section>
</section>
<section id="stato-dellarte" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Stato dell’Arte</h1>
<p>Il topic scelto non gode di particolare attenzione in letteratura, ne sono presenti specifici paper in materia. Alcune ricerche sono state fatte riguardo l’automazione dell’alimentazione per gli allevamenti, ma di forte imprinting economico. Alcune soluzioni commerciali offrono la distribuzione automatica del cibo ad orari temporizzati, senza possibilità di dosaggio o di rilevamento dei consumi.</p>
</section>
<section id="analisi-dei-requisiti" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Analisi dei Requisiti</h1>
<p>In questa fase sono stati individuati i <strong>requisiti del sistema</strong>, partendo dalle descrizioni di alto livello, ottenute dal committente durante il <strong>knowledge crunching</strong>. Successivamente si è proceduto con un raffinamento che ha portato alla definizione di requisiti più <strong>specifici</strong>, <strong>chiari</strong> e <strong>strutturati</strong>.</p>
<section id="requisiti-di-business" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Requisiti di Business</h2>
<p>Si definiscono di seguito le aspettative del cliente e i requisiti che il prodotto dovrà soddisfare, espressi con una terminologia ad elevato livello astrattivo.</p>
<ul class="incremental">
<li><p>Il prodotto dovrà <strong>diminuire l’intervento umano</strong> necessario per la quotidiana cura degli ospiti (Riempimento ciotola acqua/cibo); la riduzione del lavoro deve essere maggiore o uguale al 30%.</p></li>
<li><p>Il prodotto dovrà consentire di <strong>diminuire il lavoro su base volontaria</strong>, grazie alla riduzione delle operazioni di cura quotidiana, permettendo ai volontari di concentrarsi solo sulla socializzazione e lo svago dell’animale. Diminuisce così l’interferenza al di fuori delle loro mansioni, e migliora la tracciabilità del lavoro svolto, essendo il lavoro volontario incostante e meno affidabile.</p></li>
<li><p>Opzionalmente il prodotto dovrà <strong>fornire un monitoraggio a distanza</strong> degli animali ospitati. Questo consentirà al personale incaricato di monitorare parametri come: frequenza cardiaca e temperatura corporea. Verrà diminuito anche l’intervento veterinario, non essendo necessaria la presenza in loco del professionista. La riduzione delle presenze dovrà consentire di diminuire i costi di un valore maggiore o uguale al 10%.</p></li>
</ul>
</section>
<section id="requisiti-utente" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> Requisiti Utente</h2>
<p>Di seguito vengono riportate le richieste mosse dal cliente in maniera informale evitando termini tecnici, successivamente tali richieste saranno formalizzate per quanto possibile. Il prodotto dovrà fornire:</p>
<ul class="incremental">
<li><p>l’accesso al sistema da qualunque dispositivo munito di connessione alla rete, anche esterna al canile</p></li>
<li><p>prestazioni adeguate alle operazioni richieste (con soglie adeguate caso per caso), come il rilevare se il cane ha bisogno di cibo o acqua</p></li>
<li><p>un interfaccia intuitiva, comprensiva di una pagina per l’accesso e un menu principale</p></li>
<li><p>uno storico per ogni animale</p></li>
<li><p>un accesso rapido e reattivo evitando tempi troppo lunghi per le operazioni</p></li>
<li><p>un sistema di sorveglianza semi automatizzato in grado di identificare eventuali anomalie, come cani che escono senza permesso</p></li>
<li><p><strong>opzionalmente</strong> delle notifiche sullo stato di salute dell’animale al personale</p></li>
<li><p>delle notifiche in caso di malfunzionamento del sistema stesso</p></li>
<li><p>delle notifiche, nel caso in cui il cibo sia in esaurimento</p></li>
</ul>
<section id="user-stories" data-number="3.2.1">
<h3 data-number="3.2.1"><span class="header-section-number">3.2.1</span> User stories</h3>
<p>Di seguito sono riportate tutte le <strong>user stories</strong> ritenute utili per lo sviluppo del prodotto.</p>
<ul class="incremental">
<li><p>Come <strong>gestore</strong> voglio:</p>
<ul class="incremental">
<li><p>poter visualizzare le i dati relativi all’occupante di una gabbia</p></li>
<li><p>voglio poter impostare i dati dell’occupante di una gabbia</p></li>
<li><p>poter aggiungere un cane a una gabbia</p></li>
<li><p>poter rimuovere un cane da una gabbia</p></li>
<li><p>poter visualizzare i consumi TOTALI del canile</p></li>
<li><p><em>opzionalmente</em> poter visualizzare l’umidità e la temperatura ambientale</p></li>
<li><p>poter <strong>impostare</strong> i dati relativi allo <strong>stato di salute</strong> di un cane</p></li>
<li><p>poter visualizzare i <strong>consumi di cibo</strong> relativi a un cane in un determinato lasso di tempo</p></li>
<li><p>poter visualizzare i <strong>consumi di acqua</strong> relativi a un cane in un determinato lasso di tempo</p></li>
</ul></li>
<li><p>Come <strong>responsabile sanitario</strong> voglio:</p>
<ul class="incremental">
<li><p><em>opzionalmente</em> poter <strong>visualizzare i battiti</strong> di un cane</p></li>
<li><p><em>opzionalmente</em> ricevere una <strong>notifica</strong> in caso di rilevazione di <strong>anomalie</strong> nei <strong>battiti</strong> o nella di un cane</p></li>
<li><p><em>opzionalmente</em> poter <strong>visualizzare la temperatura corporea</strong> di un cane</p></li>
<li><p><em>opzionalmente</em> ricevere una <strong>notifica</strong> in caso di rilevazione di <strong>anomalie</strong> nella <strong>temperatura</strong> corporea di un cane</p></li>
<li><p><em>opzionalmente</em> poter <strong>impostare</strong> gli intervalli di <strong>temperatura e battiti</strong> fuori dai quali vi è un’anomalia</p></li>
<li><p>poter <strong>impostare</strong> gli intervalli delle <strong>quantità di cibo e acqua</strong> assunti, fuori dai quali vi è un’anomalia</p></li>
<li><p>ricevere una <strong>notifica</strong> in caso di <strong>anomalie</strong> nella quantità di <strong>acqua</strong> assunta da un cane</p></li>
<li><p>ricevere una <strong>notifica</strong> in caso di <strong>anomalie</strong> nella quantità di <strong>cibo</strong> assunto da un cane</p></li>
<li><p>poter <strong>impostare</strong> i dati relativi allo <strong>stato di salute</strong> di un cane</p></li>
<li><p>poter <strong>impostare la quantità di cibo</strong> da erogare a un cane</p></li>
<li><p>poter visualizzare i <strong>consumi di cibo</strong> relativi a un cane in un determinato lasso di tempo</p></li>
<li><p>poter visualizzare i <strong>consumi di acqua</strong> relativi a un cane in un determinato lasso di tempo</p></li>
</ul></li>
<li><p>Come <strong>addetto ai rifornimenti</strong> voglio:</p>
<ul class="incremental">
<li><p>che la distribuzione di cibo agli animali sia automatizzata</p></li>
<li><p>che la distribuzione di acqua agli animali sia automatizzata</p></li>
<li><p>essere notificato se in una gabbia sta per esaurirsi il cibo</p></li>
<li><p>ricevere una notifica in caso di malfunzionamento al sistema</p></li>
<li><p>poter impostare la quantità di cibo da erogare a tutti i cani di una determinata taglia</p></li>
<li><p>poter <strong>impostare la quantità di cibo</strong> da erogare a un cane</p></li>
<li><p>poter visualizzare i <strong>consumi di cibo</strong> relativi a un cane in un determinato lasso di tempo</p></li>
<li><p>poter visualizzare i <strong>consumi di acqua</strong> relativi a un cane in un determinato lasso di tempo</p></li>
</ul></li>
<li><p>Come <strong>addetto alla sorveglianza</strong> voglio:</p>
<ul class="incremental">
<li><p>poter visualizzare le immagini acquisite dalla videocamera di sorveglianza</p></li>
<li><p>notificato in caso di uscita non autorizzata di un cane</p></li>
<li><p><em>opzionalmente</em> essere notificato in caso di rilevazione di suoni forti o anomali</p></li>
<li><p><em>opzionalmente</em> poter visualizzare l’umidità e la temperatura ambientale</p></li>
</ul></li>
</ul>
<p>Di seguito viene riportato lo schema, sotto-forma di diagramma di Venn, esplicativo delle intersezioni tra le User-Stories e le figure dell’organigramma.</p>
<figure>
<img src="Miro/DiagrammaUserStories.jpg" style="width:100.0%" alt="" /><figcaption>Diagramma di Venn delle User-Stories</figcaption>
</figure>
</section>
</section>
<section id="requisiti-funzionali" data-number="3.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> Requisiti Funzionali</h2>
<section id="casi-duso" data-number="3.3.1">
<h3 data-number="3.3.1"><span class="header-section-number">3.3.1</span> Casi d’uso</h3>
<figure>
<img src="DrawIo/useCaseWholeSystem.png" style="width:90.0%" alt="" /><figcaption>Diagramma dei casi d’uso del sistema, rappresenta le principali azioni effettuate degli attori</figcaption>
</figure>
<p>Si elencano i requisiti funzionali per ognuno dei seguenti macro-componenti:</p>
<ul class="incremental">
<li><p>Applicativo web</p></li>
<li><p>Opzionale collare</p></li>
<li><p>Strumentazione gabbia</p></li>
<li><p>Strumentazione videosorveglianza</p></li>
</ul>
</section>
<section id="applicativo-web" data-number="3.3.2">
<h3 data-number="3.3.2"><span class="header-section-number">3.3.2</span> Applicativo web</h3>
<p>L’applicativo web deve consentire ad ogni utente di accedere con una serie di credenziali, e dividere le operazioni consentite in base ai permessi concessi. Il sito è suddiviso in tre pagine principali:</p>
<ul class="incremental">
<li><p><strong>pagina di login</strong> La pagina iniziale a cui ogni utente deve far riferimento per effettuare l’accesso. Sostanzialmente contiene solo gli elementi necessari per effettuare il <strong>login</strong>, non è prevista una funzione di registrazione autonoma.</p></li>
<li><p><strong>home gestore</strong> Il gestore ha accesso alla pagina di amministrazione, dov’è possibile:</p>
<ul class="incremental">
<li><p>registrare un nuovo utente</p></li>
<li><p>eliminare un utente</p></li>
<li><p>visualizzare le statistiche del canile</p></li>
</ul></li>
<li><p><strong>home addetto rifornimenti</strong> La schermata deve consentire di:</p>
<ul class="incremental">
<li><p>visualizzare le eventuali notifiche</p></li>
<li><p>visualizzare i consumi di un cane</p></li>
<li><p>impostare la quantità di cibo adeguata per taglia di cane</p></li>
</ul></li>
<li><p><strong>home addetto sorveglianza</strong> La home del sorvegliante deve fornire:</p>
<ul class="incremental">
<li><p>un accesso in diretta alle videocamere disponibili</p></li>
<li><p>deve essere possibile aggiungere o rimuovere una videocamera</p></li>
<li><p>visualizzare le notifiche se presenti</p></li>
</ul></li>
<li><p><strong>home altri addetti</strong> In un futuro sviluppo del prodotto è certamente contemplata l’aggiunta di altre mansioni o addetti.</p></li>
<li><p><strong>responsabile sanitario</strong> La pagina deve consentire di:</p>
<ul class="incremental">
<li><p>visualizzare lo stato di salute di un cane</p></li>
<li><p>visualizzare i consumi di un cane</p></li>
<li><p>impostare la quantità di cibo per un cane degente o in terapia</p></li>
<li><p>aggiornare lo stato di salute di un cane</p></li>
</ul></li>
</ul>
<p>Nonostante un addetto possa ricoprire più ruoli, è stato scelto di modellare separatamente ogni mansione, questo consente: un maggiore controllo, rende più chiara la struttura e aiuta il lettore nella comprensione. Inoltre l’applicativo consentirà ad un utente di detenere uno o più ruoli, rendendo più agevole l’utilizzo.</p>
</section>
<section id="opzionale-collare" data-number="3.3.3">
<h3 data-number="3.3.3"><span class="header-section-number">3.3.3</span> Opzionale: collare</h3>
<p>Il collare smart deve costantemente inviare aggiornamenti sui parametri vitali dell’animale quali:</p>
<ul class="incremental">
<li><p>La frequenza cardiaca</p></li>
<li><p>La temperatura dell’animale</p></li>
</ul>
</section>
<section id="strumentazione-gabbia" data-number="3.3.4">
<h3 data-number="3.3.4"><span class="header-section-number">3.3.4</span> Strumentazione gabbia</h3>
<p>La gabbia smart deve:</p>
<ul class="incremental">
<li><p>monitorare il consumo di cibo e acqua del cane inviando aggiornamenti costanti</p></li>
<li><p>rifornire la ciotola di acqua quando troppo bassa</p></li>
<li><p>rifornire la ciotola di cibo con la quantità desiderata quando mancante</p></li>
<li><p>notificare la mancanza di cibo nel serbatoio</p></li>
</ul>
</section>
<section id="strumentazione-videosorveglianza" data-number="3.3.5">
<h3 data-number="3.3.5"><span class="header-section-number">3.3.5</span> Strumentazione videosorveglianza</h3>
<p>La strumentazione deve fornire uno streaming video e audio costante nel tempo. La bidirezionalità è opzionale.</p>
</section>
</section>
<section id="requisiti-non-funzionali" data-number="3.4">
<h2 data-number="3.4"><span class="header-section-number">3.4</span> Requisiti non Funzionali</h2>
<p>Il primo vicolo individuato è quello economico. Il costo del servizio, essendo l’attività non a scopo di lucro e mantenuta grazie all’azione dei volontari, deve essere minimo. Questo è comprensivo dell’istallazione, dei materiali e dei costi di servizio. Un secondo vincolo rappresenta la sicurezza, l’eventuale introduzione di strumentazione all’interno del canile non deve rappresentare in alcun modo un pericolo per la salute dell’animale.</p>
<p>Il sistema dovrà rispettare alcuni requisiti non funzionali che ne determineranno la <strong>qualità</strong>:</p>
<section id="di-sistema" data-number="3.4.1">
<h3 data-number="3.4.1"><span class="header-section-number">3.4.1</span> Di Sistema</h3>
<ul class="incremental">
<li><p><strong>Reattività</strong>:</p>
<ul class="incremental">
<li><p>l’utente non deve percepire <strong>ritardi</strong> nell’ordine dei secondi tra l’invio di un comando e l’esecuzione dello stesso all’interno della piattaforma.</p></li>
<li><p>le notifiche standard del sistema devono essere mostrate ai relativi utenti con un ritardo complessivo massimo non superiore al minuto.</p></li>
<li><p>le notifiche urgenti del sistema, ossia quelle relative a malfunzionamenti gravi o alla salute dell’animale, devono essere mostrate ai relativi utenti con un ritardo complessivo massimo non superiore ai dieci secondi.</p></li>
</ul></li>
<li><p><strong>Scalabilità</strong>: L’applicativo deve necessariamente consentire di aumentare o diminuire il numero di animali gestiti. Ciò deve avvenire senza una sensibile ripercussione sulle prestazioni del sistema e un disagio minimo a livello pratico. Per prevenire, inoltre, che la presenza di una connessione cablata limiti la scalabilità del sistema, è desiderabile che non ci siano altri collegamenti al di fuori dell’alimentazione già presente.</p></li>
<li><p><strong>Fault tolerance</strong>: la <strong>gestione degli errori</strong> deve essere adeguatamente implementata affinché le interruzioni involontarie non danneggino innanzitutto la salute degli animali. Eventuali malfunzionamenti di apparecchiature o sensoristica all’interno del canile non devono pregiudicare il funzionamento complessivo dell’applicativo, ma al massimo della singola unità logica.</p></li>
</ul>
</section>
<section id="della-sensoristica" data-number="3.4.2">
<h3 data-number="3.4.2"><span class="header-section-number">3.4.2</span> Della Sensoristica</h3>
<ul class="incremental">
<li><p><strong>Precisione</strong>:</p>
<ul class="incremental">
<li><p><strong>Bilancia</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 10 grammi.</p></li>
<li><p><strong>Temperatura</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 2 gradi.</p></li>
<li><p><strong>Umidità</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 5%.</p></li>
<li><p><strong>Livello acqua</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 1 centimetro.</p></li>
<li><p><strong>Frequenza cardiaca</strong> lo scarto tra misure sulla stessa frequenza deve essere al massimo 10 battiti.</p></li>
</ul></li>
<li><p><strong>Risoluzione</strong>:</p>
<ul class="incremental">
<li><p><strong>Bilancia</strong> il range di misura, partendo da vuota, deve riuscire a comprendere almeno un Kg.</p></li>
<li><p><strong>Temperatura</strong> il range deve variare tra 0 e 50 gradi.</p></li>
<li><p><strong>Umidità</strong> il range di umidità deve essere incluso tra 20-80%.</p></li>
<li><p><strong>Livello acqua</strong> Il range deve variare almeno di tre cm.</p></li>
<li><p><strong>Videocamera</strong>: necessaria almeno una risoluzione di 420p, non è richiesta la visione notturna.</p></li>
<li><p><strong>Frequenza cardiaca</strong> la misurazione deve essere in grado di rilevare una frequenza che oscilla tra i 60 e i 160 battiti al minuto.</p></li>
<li><p><strong>Microfono</strong> deve essere in grado di determinare suoni ad elevata intensità compresi tra 50 e 130 dB.</p></li>
</ul></li>
<li><p><strong>Accuratezza</strong>:</p>
<ul class="incremental">
<li><p><strong>Bilancia</strong> lo scostamento massimo dal valore reale deve essere inferiore o uguale a 10 grammi.</p></li>
<li><p><strong>Temperatura</strong> Lo scostamento dalla temperatura effettiva deve essere minore di 2 gradi.</p></li>
<li><p><strong>Umidità</strong> Si accetta un massimo di 5% accuratezza.</p></li>
<li><p><strong>Livello acqua</strong> l’accuratezza minima deve essere di 2cm.</p></li>
<li><p><strong>Frequenza cardiaca</strong> l’errore non deve superare i cinque battiti al minuto.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="requisiti-implementativi" data-number="3.5">
<h2 data-number="3.5"><span class="header-section-number">3.5</span> Requisiti Implementativi</h2>
<p>Si definiscono i constraint a livello di implementazione che sarà necessario rispettare nella realizzazione del progetto.</p>
<section id="metodologie-e-tecnologie-utilizzate" data-number="3.5.1">
<h3 data-number="3.5.1"><span class="header-section-number">3.5.1</span> Metodologie e Tecnologie Utilizzate</h3>
<p>Il software dovrà essere realizzato utilizzando almeno in parte le tecnologie studiate durante il corso di Smart-City. Dovranno inoltre essere necessariamente applicati i principi e i paradigmi assimilati durante lo stesso. Lo scopo infatti è quello di sviluppare software di valore sociale e importanza strategica per le amministrazioni e l’economia locale. L’applicazione software dovrà essere infatti d’ausilio alla realizzazione di servizi innovativi in contesti di città digitali. E’ necessario al raggiungimento di tale scopo, l’utilizzo di tecnologie di sensing e sistemi embedded per l’interfacciamento con il mondo fisico. Il focus preferibilmente sarà sulla programmazione di sistemi studiati, quali Raspberry PI e microcontrollori. A questi dovranno essere interfacciati sensori e attuatori IoT, tra i quali ve ne devono essere alcuni di complessità non banale. L’utilizzo dei protocolli di comunicazione dovrà essere adeguato all’uso che ne verrà fatto (MQTT). La metodologia di progettazione inoltre dovrà favorire lo sviluppo di applicativi mobili, in grado di essere usati in contesti e con dispositivi differenti. Altre tecnologie preferibilmente utilizzabili, data la diffusione oramai pervasiva, sono Cloud Computing e Fog Computing, eventualmente con piattaforme studiate come Amazon Web Services. Per la parte interfaccia utente verranno sviluppate Dashboard ad-hoc per la visualizzazione delle informazioni ricavate dai dati trasmessi dai sensori. Infine verrà possibilmente anche inclusa una parte di visione artificiale tramite l’utilizzo di videocamere per lo streaming, eventualmente con una minima elaborazione per la sorveglianza.</p>
</section>
</section>
</section>
<section id="design-architetturale" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Design Architetturale</h1>
<p>Dopo un intenso periodo di Domain Driven Design, si è passati si è proceduto alla fase di Design Architetturale, agevolata di molto da quest’ultimo. Infatti da un confronto mirato con il cliente l’architettura ottimale è emersa quasi naturalmente. Lasciando spazio alla definizione dei dettagli più tecnici che riportiamo in seguito.</p>
<section id="architettura-generale" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Architettura Generale</h2>
<p>L’architettura generale del sistema è stata concepita in due macro aree: la parte IoT [Fig. <a href="#fig:DesignArchitettura" data-reference-type="ref" data-reference="fig:DesignArchitettura">4.1</a>. in alto] e la parte cloud [Fig. <a href="#fig:DesignArchitettura" data-reference-type="ref" data-reference="fig:DesignArchitettura">4.1</a>. in basso]. Le due sfruttano la connessione internet per connettersi, lo scambio di messaggi avviene attraverso il protocollo MQTT, mentre il flusso video viene passato per mezzo del protocollo RTSP.</p>
<p>Il sistema IoT risiede su una rete privata e comunica all’esterno per mezzo di questi due protocolli. Le parti salienti sono la sensoristica che fornisce le informaioni sull’ambiente circostante al microcontrollore, il quale le elabora e utilizza gli attuatori in base alle informazioni ricavate sia dai sensori che dal cloud.</p>
<p>La parte cloud si interfaccia per mezzo dell’applicativo IOT Core ai sensori, i messaggi MQTT vengono elaborati da AWS Lambda e, qualora opportuno, immagazzinati come dati nel database. L’applicativo web, hostato su AWS Amplify, si interfaccia anch’esso con AWS Lambda, passando per Amazon API Gateway. Questo sia per recuperare i dati dal database DynamoDB e mostrare le statistiche, che per diramare il cambio dei settaggi fino ai microcontrollori. Infine, l’applicativo si occupa anche di mostrare il flusso video proveniente dalla board per le telecamere di sorveglianza.</p>
<figure>
<img src="DrawIo/Architecture.png" id="fig:DesignArchitettura" style="width:80.0%" alt="" /><figcaption>Design dell’architettura generale del sistema<span label="fig:DesignArchitettura"></span></figcaption>
</figure>
</section>
<section id="scelte-tecnologiche-cruciali" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Scelte Tecnologiche Cruciali</h2>
<section id="aws" data-number="4.2.1">
<h3 data-number="4.2.1"><span class="header-section-number">4.2.1</span> AWS</h3>
<p>Tra i servizi messi a disposizione da AWS vi è anche Amazon Cognito che permette di gestire gli utenti. E’ stato valutato Amazon Cognito ma è stato scartato perché gli utenti sono troppo pochi.</p>
</section>
<section id="protocolli-di-comunicazione" data-number="4.2.2">
<h3 data-number="4.2.2"><span class="header-section-number">4.2.2</span> Protocolli di comunicazione</h3>
<section id="scambio-messaggi" data-number="4.2.2.1">
<h4 data-number="4.2.2.1"><span class="header-section-number">4.2.2.1</span> Scambio messaggi</h4>
<p>Come protocolli di comunicazione sono stati considerati i principali protocolli per la comunicazione IoT. Tra quelli di livello applicazione:</p>
<ul class="incremental">
<li><p><strong>AMQP (Advanced Message Queuing Protocol)</strong>, protocollo che consente a un’ampia gamma di sistemi e applicazioni di interagire, creando messaggistica standardizzata su scala industriale.</p></li>
<li><p><strong>CoAP (Constrained Application Protocol)</strong>, protocollo adatto alle limitazioni di larghezza di banda e di rete, per dispositivi con capacità limitata, ma prevalentemente per la connessione nelle comunicazioni da computer a computer.</p></li>
<li><p><strong>DDS (Data Distribution Service)</strong>, protocollo per comunicazioni peer-to-peer. In generale semplifica la distribuzione, incrementa l’affidabilità e riduce la complessità.</p></li>
<li><p><strong>MQTT (Message Queue Telemetry Transport)</strong>, protocollo di messaggistica progettato per comunicazioni IoT. MQTT usa un criterio di tipo publish-subscribe ed è ideale per dispositivi di dimensioni ridotte che richiedono efficienza a livello di larghezza di banda e uso della batteria.</p></li>
</ul>
<p>La scelta è ricaduta su MQTT per la sua leggerezza ed efficienza, per la possibilità di instaurare comunicazioni bidirezionali tra molti dispositivi. Il design inoltre è molto semplificato dalla possibilità di creare topic a cui iscriversi o in cui pubblicare i messaggi.</p>
</section>
<section id="streaming-video" data-number="4.2.2.2">
<h4 data-number="4.2.2.2"><span class="header-section-number">4.2.2.2</span> Streaming Video</h4>
<p>Per lo streaming video sono stati considerate due opzioni: streaming attraverso RTSP e attraverso HTTP con un server e HTML5. RTSP è di sicuro la scelta più popolare perché adottato come protocollo dalle IP-cam e telecamere di sorveglianza. Nonostante ciò non è compatibile con HTTP e, non potendo fare lo stream su HTTP direttamente, non è visualizzabile nativamente dai browser. Questo protocollo è infatti usato internamente alle reti private. Volendo esporre il flusso video anche al di fuori della rete privata del committente la scelta è ricaduta sulla seconda opzione. Inoltre, con questa tecnologia alla videosorveglianza si ha accesso con qualsiasi browser, da computer o da smartphone.</p>
</section>
</section>
<section id="microcontrollori-e-soc" data-number="4.2.3">
<h3 data-number="4.2.3"><span class="header-section-number">4.2.3</span> Microcontrollori e Soc</h3>
<section id="hardware" data-number="4.2.3.1">
<h4 data-number="4.2.3.1"><span class="header-section-number">4.2.3.1</span> Hardware</h4>
<p>Le piattaforme di sviluppo per l’IoT tenute presente sono state molteplici, da board con potenza computazionale più elevata, come Raspberry Pi, a scendere fino a ESP e le varianti Arduino.</p>
<p>Le board Arduino sono state scartate quasi subito, per la poca potenza computazionale e la necessità di moduli aggiuntivi per le connessioni. La board RaspBerry Pi è stata scelta per task più computazionalmente onerosi, legati alla gestione ambientale, quali la video sorveglianza e l’analisi immagini. Questa scelta non può essere invece adottata per la gestione delle gabbie. Le principali motivazioni risiedono nel fatto che il numero è variabile e il costo supererebbe molto superiore al budget. La scelta in questo caso è ricaduta sull’ESP, non solo per il forte fattore cost-competitive, e per il supporto a BlueTooth e WiFi integrati, ma anche per il supporto della community e l’ottima potenza computazionale. Inoltre, rinunciando all’analisi immagini e alla qualità video a favore dei costi, il cliente potrà anche scegliere di sostituire la board Raspberry con un più economico ESP32-CAM. Con l’ESP8266 le prime settimane il lavoro di indagine preliminare ha rilevato qualche che risultava troppo limitato per utilizzare MicroPython. Tra ESP8266 e ESP32 è stato preferito quest’ultimo, anche per lasciare della capacità di calcolo per eventuali future espansioni e richieste del committente.</p>
</section>
<section id="linguaggio-di-programmazione" data-number="4.2.3.2">
<h4 data-number="4.2.3.2"><span class="header-section-number">4.2.3.2</span> Linguaggio di programmazione</h4>
<p>Per quanto riguarda l’implementazione del codice nel microcontrollore, sono state presi in considerazione quattro scelte relative ai framework di sviluppo e ai linguaggi da adottare:</p>
<ul class="incremental">
<li><p><strong>C++</strong> è il linguaggio attualmente più diffuso nell’ambito.</p></li>
<li><p><strong>Node-RED</strong> è un tool di programmazione flow-based basato su browser, sviluppato su NodeJs e programmabile in JavaScript.</p></li>
<li><p><strong>MicroPython</strong> è un porting più leggero del compilatore Python3, eseguibile direttamente su microcontrollori. Include le principali librerie di Python e moduli aggiuntivi per l’accesso all’hardware di basso livello.</p></li>
<li><p><strong>Espruino</strong> è un interprete JavaScript open-source per microcontrollori. E’ stato progettato per unità con poca RAM.</p></li>
</ul>
<p>Sicuramente il più performante e con più librerie è C, ma risulta anche difficilmente testabile e pone challange non indifferenti per la configurazione dei sensori e per lo sviluppo di programmi molto complessi. Node-RED, basato su Node.js, ha il pieno vantaggio del suo modello non bloccante e event-driven. MicroPython d’altra parte offre un modello ad oggetti, testabile, sia semplice che elastico, con una buona base di librerie. Infine, Espruino, interprete JavaScript anch’esso, di facile utilizzo e dall’interfaccia semplificata. I fattori chiave che il team ha preso in considerazione per la scelta sono stati:</p>
<ul class="incremental">
<li><p>la potenza espressiva rapportata alla chiarezza del linguaggio.</p></li>
<li><p>la testabilità del codice</p></li>
<li><p>il numero di librerie e la futura possibilità di estensione del progetto.</p></li>
</ul>
<p>Alla luce delle considerazioni fatte, si è scelto <strong>MicroPython</strong> per lo sviluppo, il testing e l’automatizzazione nei microcontrollori. Questo permette di allinearsi con l’utilizzo di <strong>Pyhton</strong> per il Raspberry.</p>
</section>
</section>
</section>
<section id="pattern-architetturali-utilizzati" data-number="4.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> Pattern Architetturali Utilizzati</h2>
<section id="client-server" data-number="4.3.1">
<h3 data-number="4.3.1"><span class="header-section-number">4.3.1</span> Client-Server</h3>
<p>L’utilizzo del pattern client-server, nella videosorveglianza, ha permesso di esporre il flusso video su un server apposito e di accederci da qualunque dispositivo dotato di connessione.</p>
</section>
<section id="pusblish-subscribe" data-number="4.3.2">
<h3 data-number="4.3.2"><span class="header-section-number">4.3.2</span> Pusblish-Subscribe</h3>
<p>L’utilizzo del pattern publish-subscribe, è stata una scelta chiave per la modularità del sistema. La divisione in topic ha portato un maggiore ordine e una modellazione più vicina al vero dominio.</p>
</section>
<section id="master-slave" data-number="4.3.3">
<h3 data-number="4.3.3"><span class="header-section-number">4.3.3</span> Master-Slave</h3>
<p>E’ stato fatto uso dell’architettura master-slave per la gestione dei microcontrollori. Questa permette di espanderne il numero a piacimento, mandando istruzioni specifiche o generali per controllarne il comportamento.</p>
</section>
<section id="scheduling-cooperativo" data-number="4.3.4">
<h3 data-number="4.3.4"><span class="header-section-number">4.3.4</span> Scheduling Cooperativo</h3>
<p>Nei sistemi embedded è stato adottato lo scheduling cooperativo per evitare tante pitfall dello scheduling preemptive, quali l’interruzione di un processo di misura Hard Real Time, quale quello della chiusura della valvola dell’acqua o la misura del battito cardiaco.</p>
</section>
<section id="state-machine" data-number="4.3.5">
<h3 data-number="4.3.5"><span class="header-section-number">4.3.5</span> State Machine</h3>
<p>Per definire il comportamento dei microcontrollori in maniera chiara è stata usata la modellazione con macchine a stati. Questa ha permesso di ridurre la probabilità di bug nel software e di isolare i componenti permettendo una futura espansione del comportamento.</p>
</section>
</section>
</section>
<section id="design-di-dettaglio" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Design di Dettaglio</h1>
<section id="design-del-database" data-number="5.1">
<h2 data-number="5.1"><span class="header-section-number">5.1</span> Design del Database</h2>
<ul class="incremental">
<li><p>ER</p></li>
<li><p>Sgranatura ER</p></li>
<li><p>Accessi</p></li>
<li><p>Struttura di PK e SK per comprimere tutto in una tabella</p></li>
<li><p>Global index su size</p></li>
</ul>
</section>
</section>
<section id="implementazione" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Implementazione</h1>
<section id="microcontrollori" data-number="6.1">
<h2 data-number="6.1"><span class="header-section-number">6.1</span> Microcontrollori</h2>
<section id="battito-cardiaco" data-number="6.1.1">
<h3 data-number="6.1.1"><span class="header-section-number">6.1.1</span> Battito Cardiaco</h3>
<p>Un parte particolarmente complessa è stata quella della modellazione del sensore per il battito. Il sensore, qualora interpellato, fornisce un singolo valore direttamente proporzionale alla dilatazione dei vasi sanguigni. Ne deriva la necessità di attuare misurazioni frequenti per non incorrere nella perdita della breve variazione di un battito. Abbiamo stabilito la frequenza di campionamento in base a quanto segue: Considerando che in condizioni di riposo, i battiti per minuto di un cane - da intendersi come pulsazioni - sono generalmente compresi tra 60 e 140 bpm, in base alla taglia, età e razza, e il valore può raggiungere valori anche più alti qualora in movimento, abbiamo preso come valore limite da rilevare 150 bpm. Ciò, significa che il tempo di ogni ciclo cardiaco <span class="math inline">\(T_{cc}\)</span> è: <span class="math display">\[T_{cc} = \frac{1}{bps} = \frac{1}{\frac{bpm}{60}}= \frac{60}{bpm} \Rightarrow \frac{60}{150 bpm} = 0.4s\]</span> Considerato che il ciclo cardiaco si compone in sistole (contrazione) e diastole (rilassamento), la fase sistolica è quella più facilmente rilevabile poiché la contrazione ventricolare causata è più violenta e breve. Questa fase durante le rilevazioni effettuate dura circa un mezzo del ciclo cardiaco e produce un picco nei valori particolarmente indicativo per rilevare il battito in mezzo al naturale rumore del sensore. Per non perdere il picco massimo il numero di campionamenti <span class="math inline">\(N_{c}\)</span> durante questa fase è stato fissato a 20. La frequenza di campionamento minima risultante <span class="math inline">\(f_{min}\)</span> è stata calcolata come: <span class="math display">\[f_{min} = \frac{ \frac{1}{2} *  T_{cc} }{N_{c}} \Rightarrow  \frac{ \frac{1}{2} *  0.4s }{20} = 0.01s = 10 ms\]</span></p>
<p>Salvando i valori risultanti e graficandoli con la libreria python "Mathplotlib" si ottiene una linea come quella di colore rosso in [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.1</a>]. Si può notare che il campionamento è sufficiente e permette di distinguere intuitivamente i battiti. Per rilevare le pulsazioni a livello digitale però è necessario formalizzare un altro modello matematico che non faccia incorrere il sistema in falsi positivi o falsi negativi. Un primo approccio si è basato su stabilire una singola soglia, oltre la quale il battito è rilevato e registrato. Questa soluzione si è rivelata inadatta in quanto il disturbo del sensore la farebbe attraversare più volte (si veda in [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.1</a>] poco prima del campionamento numero 2400 il valore attraversa la linea azzurra parecchie volte). Inadatti si sono rivelati anche i tentativi di normalizzare la linea dei valori, in quanto parecchio discontinui e di frequenza elevata, si perde la differenziazione dei picchi. Si è optato per stabilire una doppia soglia, la prima, più alta, oltre la quale il battito è rilevato, la seconda, più bassa, che determina la fine del battito. La prima volta che il valore attraversa la prima [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.1</a>, linea azzurra] una variabile registra il battito e nessun altra registrazione viene effettuata sino a che i valori non scendono sotto la soglia di fine battito [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.1</a>, linea gialla]. Queste soglie non possono essere fisse, variando la pressione di animale in animale e pure di giorno in giorno per lo stesso essere vivente. Per questo motivo i valori sono stati fissati per la prima a 4/5 e per la seconda a 1/2 tra minimo [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.1</a>, linea verde] e massimo [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.1</a>, linea blu] dei precedenti valori. La grandezza della finestra dei valori da cui prendere minimo e massimo è stata fissata a 250 valori. Questo perché, come si può notare dal grafico, comprende almeno due battiti. Un range troppo piccolo creerebbe dei minimi e massimi locali, rilevando picchi non propri e dando parecchi falsi positivi. Una finestra troppo ampia porterebbe a una staticità delle soglie rispetto alla variazione di pressione che creerebbe falsi negativi.</p>
<figure>
<img src="Images/heartbeatGraph.png" id="fig:Heartbeat" style="width:100.0%" alt="" /><figcaption>Grafico Battiti<span label="fig:Heartbeat"></span></figcaption>
</figure>
<p>Una volta rilevati i singoli battiti con il modello matematico, il calcolo del battiti al minuto è stato realizzato salvando la cronologia degli istanti di tempo per gli ultimi N battiti <span class="math inline">\(N_{beats}\)</span>. Sperimentalmente si è optato per 30 registrazioni per mantenere il valore dei bpm reattivo ma non dipendente solo da poche unità. Prelevando dalla cronologia il tempo passato <span class="math inline">\(T_{diff}\)</span> per questi battiti, si può facilmente derivare il rateo di <span class="math inline">\(bpm\)</span> attuale tramite la formula: <span class="math display">\[bpm = \frac{ N_{beats}*60 s/min }{T_{diff}} = \frac{ N_{beats}*60 s/min }{T_{last}-T_{first}}\]</span> Il battito cardiaco risultante viene poi inviato periodicamente al Database e, qualora ci fossero anomalie, una notifica viene invece generata e inviata immediatamente.</p>
</section>
</section>
<section id="raspberry" data-number="6.2">
<h2 data-number="6.2"><span class="header-section-number">6.2</span> Raspberry</h2>
<p>Il raspberry è stato scelto come board per la computazione delle immagini di video-sorveglianza. Il principale concorrente a questa scelta, l’ESP32-CAM è stato testato per lo streaming video ma non è provvisto delle risorse computazionali necessarie per il rilevamento di anomalie. Avendo un costo inferiore rispetto al Raspberry è stato comunque considerato come alternativa low-cost. Il motion detector base è stato costruito come segue: Accumulating the weighted average of the previous N frames Taking the current frame and subtracting it from the weighted average of frames Thresholding the output of the subtraction to highlight the regions with substantial differences in pixel values (“white” for foreground and “black” for background) Applying basic image processing techniques such as erosions and dilations to remove noise Utilizing contour detection to extract the regions containing motion</p>
</section>
</section>
<section id="testing-e-performance" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Testing e Performance</h1>
<section id="automazione-gabbia-e-monitoraggio-salute" data-number="7.1">
<h2 data-number="7.1"><span class="header-section-number">7.1</span> Automazione Gabbia e Monitoraggio Salute</h2>
<section id="hardware-1" data-number="7.1.1">
<h3 data-number="7.1.1"><span class="header-section-number">7.1.1</span> Hardware</h3>
<p>Per quanto riguarda l’automazione di cibo e acqua e il monitoraggio dei parametri vitali dell’animale sono state testate multiple soluzioni hardware. In fase di validazione del progetto sono stati prese in esame principalmente due board che soddisfacessero i requisiti di economicità, connettività e prestazioni: L’ESP8266 e il successore ESP32. Entrambi offrono la connettività Wi-Fi integrata e buona potenza computazionale, cosa di cui è carente la board Arduino, e un costo contenuto (5€ per il primo e 7€ per il secondo, dati del primo semestre 2021) rispetto alla board Raspberry. Quest’ultima board offre connettività e prestazioni ma i costi sono decisamente fuori budget per il committente e per la natura distribuita dei compiti. La piattaforma ESP si è rivelata un buon compromesso e quindi si è passati a testarne i due differenti modelli.</p>
<p>Dopo i testing eseguiti in fase iniziale sono emerse differenze sostanziali nei tempi di avvio del programma e di connessione. Inoltre l’ESP8266 ha riscontrato spesso problemi nel caricamento dei file e nell’esecuzione di micropython. Di seguito si riporta la tabella riassuntiva per i tempi di esecuzione/comunicazione, accompagnati dalle caratteristiche dell’hardware.</p>
<p>board &amp; velocità processore &amp; costo &amp; tempo medio avvio programma &amp; tempo medio connessione MQTT<br />
<a href="#https://en.wikipedia.org/wiki/ESP8266">ESP8266</a> &amp; 160 MHz &amp; 5€ &amp; 8,1 s &amp; 9,3 s<br />
<a href="#https://en.wikipedia.org/wiki/ESP32">ESP32</a> &amp; 240 MHz (dual core) &amp; 7€ &amp; 5,2 s &amp; 3,4 s<br />
</p>
<p>Alla luce della minima differenza di prezzo tra i due device rispetto alla capacità computazionale, la scelta è ricaduta sul più recente ESP32.</p>
</section>
</section>
<section id="videosorveglianza" data-number="7.2">
<h2 data-number="7.2"><span class="header-section-number">7.2</span> Videosorveglianza</h2>
<section id="hardware-2" data-number="7.2.1">
<h3 data-number="7.2.1"><span class="header-section-number">7.2.1</span> Hardware</h3>
<p>Come anticipato in precedenza, il lato visione, di per se più computazionalmente oneroso, ha reso necessaria un’analisi più approfondita delle performance e la scelta è ricaduta su Raspberry Pi e ESP32-CAM. Inizialmente stato implementato un server web in C, per l’ESP ma il development è stato in seguito interrotto per la scarsa potenza potenza di quest’ultimo nell’elaborazione delle immagini. E’ stato tuttavia ritenuto valido per un’alternativa economica per il semplice streaming video senza elaborazione e notifica. Le board Raspberry Pi testate sono state le seguenti, con i rispettivi tempi di elaborazione:</p>
<p>board &amp; velocità processore &amp; memoria RAM &amp; costo &amp; tempo medio forward immagine NN*<br />
<a href="#https://en.wikipedia.org/wiki/Raspberry_Pi">Pi 3 A+</a> &amp; 1.4 GHz (quad-core) &amp; 512 MB &amp; 20€ &amp; 6.3 s<br />
<a href="#https://en.wikipedia.org/wiki/Raspberry_Pi">Pi 3 B+</a> &amp; 1.4 GHz (quad-core) &amp; 1 GB &amp; 30€ &amp; 3.1 s<br />
<a href="#https://en.wikipedia.org/wiki/Raspberry_Pi">Pi 4</a> &amp; 1.5 GHz (quad-core) &amp; 2 GB &amp; 50€ &amp; 2.4 s<br />
</p>
<p>* i tempi si riferiscono all’attesa media per ottenere i risultati di object-detection attraverso una rete neurale con architettura Yolo3 con lo stesso set di immagini.</p>
<p>Considerando il rapporto costo/prestazioni, la scelta è ricaduta sul Raspberry Pi 3 B+ che con soli 0.7 secondi di distacco dal suo successore si posiziona su una fascia decisamente più economica.</p>
</section>
<section id="software" data-number="7.2.2">
<h3 data-number="7.2.2"><span class="header-section-number">7.2.2</span> Software</h3>
<p>Per quanto riguarda il software sono state testate le prestazioni dei due metodi per la detection di anomalie/intrusioni.Il secondo, più elaborato, su riconoscimento oggetti per mezzo di una rete neurale.</p>
<section id="motion-detection" data-number="7.2.2.1">
<h4 data-number="7.2.2.1"><span class="header-section-number">7.2.2.1</span> Motion Detection</h4>
<p>Il primo, più lineare, si basa su elaborazione delle immagini tramite sottrazione dello sfondo per rilevare del movimento. Le semplici operazioni di sfocatura gaussiana, differenza, soglia e calcolo dell’area sono state studiate per ottenere alte prestazioni circa la velocità di esecuzione dell’algoritmo. I test sperimentali sulla piattaforma scelta Raspberry Pi 3B+ hanno rilevato una media di 30 FPS sul materiale di test. Questa misura si è rivelata parecchio costante, poiché l’algoritmo non effettua un’analisi semantica delle immagini ma semplicemente delle operazioni matematiche indipendentemente dal contenuto. L’unico overhead dell’algoritmo risiede infatti nel calcolo dell’area dell’immagine cambiata qualora presente. Più questa è grande più tempo viene impiegato per calcolarla. Rispetto ai tempi di esecuzione e alle normale fluttuazioni delle prestazioni non è stata rilevata una differenza degna di nota (Si vedano gli FPS nonostante la grande area rilevata in [Fig. <a href="#fig:MDcomparison" data-reference-type="ref" data-reference="fig:MDcomparison">7.1</a>]</p>
<figure>
<img src="Images/MDcomparison.png" id="fig:MDcomparison" style="width:50.0%" alt="" /><figcaption>Surveillance with Motion Detection<span label="fig:MDcomparison"></span></figcaption>
</figure>
<p>La velocità dell’algoritmo va a discapito della precisione dello stesso. A seguito delle rilevazioni la matrice di confusione risulta non ottimale. Le motivazioni principali trovate risiedono nei seguenti scenari:</p>
<ul class="incremental">
<li><p>qualora una figura da rilevare stesse ferma o si muovesse lentamente, la soglia non sarebbe abbastanza alta da venir rilevata e ciò comporta dei falsi negativi. Non avendo nozione della semantica dell’immagine, l’algoritmo non può venir calibrato ulteriormente.</p></li>
<li><p>qualora un oggetto irrilevante (es: una mosca che passa vicino sulle lenti) produca un cambiamento significativo nell’immagine, la soglia viene superata e viene prodotto un falso positivo. Anche qui la mancanza di discernimento dell’algoritmo non può essere superata se non cambiandolo.</p></li>
<li><p>qualora l’oggetto estraneo sia lontano l’area di cambiamento risulta piccola e non supera la soglia, producendo falsi negativi. Se la soglia viene abbassata si incorre in falsi positivi per via di minimi cambiamenti ambientali.</p></li>
</ul>
<p>La matrice di confusione risultante in [Fig. <a href="#fig:MDmatrix" data-reference-type="ref" data-reference="fig:MDmatrix">7.2</a>] risulta chiaramente sbilanciata con parecchi falsi positivi. Questo deriva chiaramente dall’impossibilità discussa di discernere tra oggetti in movimento "non allarmanti" e viceversa. Per ovviare a questo problema nella sezione successiva si discuterà l’uso delle reti neurali e le prestazioni inerenti l’uso dell’object-detection.</p>
<figure>
<img src="DrawIo/ConfusionMatrixMotDet.png" id="fig:MDmatrix" style="width:90.0%" alt="" /><figcaption>Confusion matrix of Motion Detection<span label="fig:MDmatrix"></span></figcaption>
</figure>
</section>
<section id="object-detection" data-number="7.2.2.2">
<h4 data-number="7.2.2.2"><span class="header-section-number">7.2.2.2</span> Object Detection</h4>
<p>Il secondo metodo testato per la sorveglianza è l’object detection. Sono state confrontate 4 reti neurali per trovare la più adatta tra prestazioni e precisione. Nonostante sia stata scelta la board Raspberry tenendo il considerazione la potenza di calcolo, i fotogrammi al secondo hanno subito una brusca riduzione rispetto alla soluzione precedente. Il parametro minimo è stato fissato a 1 FPS, sotto il quale il divario temporale tra due immagini analizzate mancherebbe la rilevazione di possibili avvenimenti. La causa principale di tale crollo nelle prestazioni utilizzando questa soluzione è la mancanza di una GPU adatta nei Raspberry. Tale carenza è comunque colmabile con l’acquisto di espansioni USB dedicate all’espansione delle capacità grafiche della board (TPU). Immediatamente è risultato palese che le architetture delle reti tradizionalmente usate sui pc fossero troppo pesanti per il sistema ospitante. Per referenza è stata lasciata l’architettura (già di per se performante) Yolo3. Il focus quindi è stato soprattutto sull’individuazione di reti "leggere" che offrissero prestazioni adeguate. Sono state confrontate e testate le varie versioni "Tiny" della stessa rete come in tabella seguente:</p>
<p>Architettura &amp; Dimensioni &amp; Frames al secondo &amp; Rilevazioni<br />
<a href="#https://pjreddie.com/darknet/yolo/">Yolo V3</a> &amp; 280 MB &amp; 0.4 &amp; 699<br />
<a href="#https://pjreddie.com/darknet/yolo/">Yolo V2-Tiny</a> &amp; 45 MB &amp; 3.5 &amp; 20<br />
<a href="#https://pjreddie.com/darknet/yolo/">Yolo V3-Tiny</a> &amp; 35 MB &amp; 3.3 &amp; 214<br />
<a href="#https://pjreddie.com/darknet/yolo/">Yolo V4-Tiny</a> &amp; 24 MB &amp; 2.9 &amp; 269<br />
</p>
<p>Dopo l’analisi è risultato chiara la scelta della versione Yolo V4-Tiny, con il miglior numero di rilevazioni e una velocità adeguata alla videosorveglianza.</p>
<figure>
<img src="Images/ODcomparison.png" id="fig:ODcomparison" style="width:100.0%" alt="" /><figcaption>Surveillance with Object Detection<span label="fig:ODcomparison"></span></figcaption>
</figure>
<p>Le prestazioni sono state a livello di precisione sono state alte, come ci si aspetta da una rete neurale comparate "in the wild" a metodi tradizionali. Di seguito si riporta la matrice di confusione delle prove effettuate:</p>
<figure>
<img src="DrawIo/ConfusionMatrixObjDet.png" id="fig:ODmatrix" style="width:90.0%" alt="" /><figcaption>Confusion matrix of Object Detection<span label="fig:ODmatrix"></span></figcaption>
</figure>
</section>
</section>
</section>
</section>
<section id="analisi-di-deployment-su-larga-scala" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Analisi di Deployment su Larga Scala</h1>
<p>L’applicativo è stato modellato in ogni sua parte per scalare facilmente all’occorrenza. Il design distribuito e in cloud ne facilita l’eventuale evoluzione su larga scala. Verranno di seguito brevemente analizzati due scenari:</p>
<ul class="incremental">
<li><p><strong>Evoluzione Interna</strong> In termini di scalabilità del singolo software lo scenario più realistico consiste nell’aggiunta di elementi (gabbie o animali) da parte di un grande canile. L’aggiunta, anche cospicua, di elementi non porterebbe ulteriore complessità al sistema. Gli unici requisiti riguardano comprare l’hardware specifico da installare. Questo si occuperà attraverso il programma di mandare i dati direttamente al cloud, il quale li processerà e mostrerà le informazioni aggiornate sull’applicativo.</p></li>
<li><p><strong>Diffusione su Larga Scala</strong> In termini di diffusione del software in molteplici copie lo scenario riguarderebbe l’adozione dell’ applicativo da parte di molteplici amministrazioni. Grazie all’adozione dei servizi AWS in Cloud, l’ <strong>availability</strong> e la <strong>scalability</strong> del sistema sono garantite anche ad alti livelli.</p></li>
</ul>
</section>
<section id="piano-di-lavoro" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Piano di Lavoro</h1>
<p>Il piano di lavoro scelto ... Diagramma di Gantt del lavoro svolto:</p>
<p>] <img src="DrawIo/GanttChart.png" title="fig:" id="fig:Gantt" style="width:100.0%" alt="Gantt Chart del progetto" /></p>
</section>
<section id="iterazioni" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Iterazioni</h1>
<p>Gli sprint sono stati portati avanti nel seguente modo:</p>
<section id="sprint-planning" data-number="10.0.0.0.1">
<h5 data-number="10.0.0.0.1"><span class="header-section-number">10.0.0.0.1</span> Sprint Planning</h5>
<p>Pianificazione a inizio sprint degli obiettivi, tempistiche e responsabilità nel periodo dello sprint corrente. Diviso in due parti:</p>
<ul class="incremental">
<li><p><strong>parte 1</strong> Viene raffinato e rivisto il product backlog, viene effettuata la scelta dello sprint goal (what).</p></li>
<li><p><strong>parte 2</strong> Si decidono gli item e viene raffinato come implementarli (how). Effettuato con solo il team senza la figura del product owner</p></li>
</ul>
</section>
<section id="iterativo-daily-scrum" data-number="10.0.0.0.2">
<h5 data-number="10.0.0.0.2"><span class="header-section-number">10.0.0.0.2</span> [Iterativo] Daily scrum</h5>
<p>Breve meeting svolto giornalmente. Viene utilizzato per gli aggiornamenti sull’andamento del progetto, senza scendere nei dettagli implementativi.</p>
</section>
<section id="occasionale-pair-programming" data-number="10.0.0.0.3">
<h5 data-number="10.0.0.0.3"><span class="header-section-number">10.0.0.0.3</span> [Occasionale] Pair Programming </h5>
<p>Utilizzato per risolvere problemi che causano il blocco di un componente del team per parecchio tempo su una issue.</p>
</section>
<section id="meeting-finale" data-number="10.0.0.0.4">
<h5 data-number="10.0.0.0.4"><span class="header-section-number">10.0.0.0.4</span> Meeting finale</h5>
<p>Riflessioni e considerazioni finali sullo spint passato. Suggerimenti per migliorare il prossimo. Diviso in tre parti:</p>
<ul class="incremental">
<li><p><strong>Product backlog refinement</strong> aggiunta di dettagli e riordino del product backlog</p></li>
<li><p><strong>Sprint review</strong> è stato ispezionato l’incremento, il Minimum Viable Product o di risultati sul processo. Discernere cosa è stato fatto e cosa no</p></li>
<li><p><strong>Retrospettiva</strong> Considerazioni sul team stesso e sui miglioramenti per il prossimo sprint.</p></li>
</ul>
</section>
<section id="sprint-0" data-number="10.1">
<h2 data-number="10.1"><span class="header-section-number">10.1</span> Sprint 0</h2>
<p>All’interno dello sprint 0 il focus è stato sullo scegliere le giuste tecnologie di sviluppo e sull’apprenderle in maniera sufficiente per il kick-off del progetto. L’obiettivo è stato raggiungere una conoscenza e competenza minima per sviluppare il design in maniera consapevole e ottimale.</p>
<section id="deliverables" data-number="10.1.0.0.1">
<h5 data-number="10.1.0.0.1"><span class="header-section-number">10.1.0.0.1</span> Deliverables</h5>
<p>al termine di questo sprint si sono acquisite le competenze di base per poter iniziare a lavorare con AWS e i dispositivi IoT. Inoltre ci si è portati avanti con lo scheletro del sito.</p>
<ul class="incremental">
<li><p>ambiente di lavoro Linux standardizzato e virtualizzato</p></li>
<li><p>sito linkato, con le prime due pagine base: home e login</p></li>
<li><p>ESP32 con firmware installato MicroPython, script e guida all’uso</p></li>
<li><p>codice per sensori base, test relativi e stubs per eseguirli senza necessità del micro-controllore</p></li>
<li><p>repository software con CI e test automatizzati</p></li>
<li><p>database progettato e popolato con qualche dato ai fini di testing</p></li>
</ul>
</section>
</section>
<section id="sprint-1" data-number="10.2">
<h2 data-number="10.2"><span class="header-section-number">10.2</span> Sprint 1</h2>
<p>All’interno dello sprint 1 il focus è stato sull’usare le competenze tecnologiche acquisite precedentemente per sviluppare i componenti principali del progetto. Sono stati scelti come obiettivi le user stories per l’automatizzazione di cibo e acqua e la visualizzazione delle informazioni relative a un animale sulla webpage.</p>
<section id="deliverables-1" data-number="10.2.0.0.1">
<h5 data-number="10.2.0.0.1"><span class="header-section-number">10.2.0.0.1</span> Deliverables</h5>
<p>al termine di questo sprint sono state implementate le funzioni base dei maggiori componenti per l’automatizzazione fisica di cibo e acqua e il relativo prototipo fisico. Sono state aggiunte sull’applicativo la vista delle informazioni dell’animale e l’impostazione del cibo da erogargli.</p>
<ul class="incremental">
<li><p>codice per i sensori/attuatori per acqua e cibo, con stubs, test e automatizzazione. (Livello acqua, elettrovalvola, motore, bilancia, laser e rilevatore di luce)</p></li>
<li><p>prototipo fisico per i sensori per acqua e cibo.</p></li>
<li><p>database migliorato e rifattorizzato</p></li>
<li><p>visualizzazione dei dati del cane sul sito</p></li>
<li><p>visualizzazione dei grafici delle statistiche sul sito</p></li>
</ul>
</section>
</section>
<section id="sprint-2" data-number="10.3">
<h2 data-number="10.3"><span class="header-section-number">10.3</span> Sprint 2</h2>
<p>Nello sprint 2 il focus è stato sul realizzare la logica d’orchestrazione della sensoristica e l’integrazione tra essa e l’applicativo per mezzo del protocollo MQTT. Sono stati prodotti gli artefatti di documentazione e schemi esemplificativi. Inoltre, è stato dato peso alla creazione delle query che permettono di integrare le funzioni del sito con il database. In particolare ci si è concentrati sulle user-stories prioritarie, che costituiscono il core del dominio.</p>
<section id="deliverables-2" data-number="10.3.0.0.1">
<h5 data-number="10.3.0.0.1"><span class="header-section-number">10.3.0.0.1</span> Deliverables</h5>
<ul class="incremental">
<li><p>sviluppate query necessarie alla logica centrale dell’applicazione web</p></li>
<li><p>grafici per la temperatura e l’umidità nell’applicazione web</p></li>
<li><p>implementata coverage dei test Python, con relativa pagina web su Github pages.</p></li>
<li><p>aggiunta Quality Assurance con SonarCloud, Codacy e Codefactor</p></li>
<li><p>implementata Continuous Delivery con GitHub Actions e GitHub Releases</p></li>
<li><p>implementata macchina a stati per food delivery e water automation</p></li>
</ul>
</section>
</section>
<section id="sprint-3" data-number="10.4">
<h2 data-number="10.4"><span class="header-section-number">10.4</span> Sprint 3</h2>
<p>Nello sprint 3 sono state implementate le query che verranno chiamate dal sito per mostrare gli elementi all’utente. Inoltre, è stato migrato il codice JavaScript in un repository dedicato che permette il deployment delle funzioni in automatico su AWS con SAM. Sono state sviluppate le funzioni per ottenere i dati della sensoristica del collare smart, implementando la logica per il controllo dei valori e l’invio delle notifiche su MQTT.</p>
<section id="deliverables-3" data-number="10.4.0.0.1">
<h5 data-number="10.4.0.0.1"><span class="header-section-number">10.4.0.0.1</span> Deliverables</h5>
<ul class="incremental">
<li><p>sviluppate query complesse necessarie alla logica centrale dell’applicazione web</p></li>
<li><p>repository dedicato delle funzioni JavaScript per AWS</p></li>
<li><p>setup framework SAM per automazione AWS</p></li>
<li><p>prototipo fisico per i sensori di temperatura e battito</p></li>
<li><p>implementata macchina a stati per smart-collar heartbeat e temperature</p></li>
</ul>
</section>
</section>
<section id="sprint-4" data-number="10.5">
<h2 data-number="10.5"><span class="header-section-number">10.5</span> Sprint 4</h2>
</section>
</section>
<section id="conclusioni" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Conclusioni</h1>
<section id="sviluppi-futuri" class="unnumbered" data-number="">
<h5 class="unnumbered" data-number="">Sviluppi Futuri</h5>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-adams1995hitchhiker">
<p>Adams, D. 1995. <em>The Hitchhiker’s Guide to the Galaxy</em>. San Val. <a href="http://books.google.com/books?id=W-xMPgAACAAJ">http://books.google.com/books?id=W-xMPgAACAAJ</a>.</p>
</div>
<div id="ref-yolov3">
<p>Redmon, Joseph, and Ali Farhadi. 2018. “YOLOv3: An Incremental Improvement.” <em>arXiv</em>.</p>
</div>
<div id="ref-uasyncio">
<p>uasyncio. n.d. “ Application of uasyncio to hardware interfaces.” <a href="https://github.com/peterhinch/micropython-async/blob/master/v3/docs/TUTORIAL.md">https://github.com/peterhinch/micropython-async/blob/master/v3/docs/TUTORIAL.md</a>.</p>
</div>
</div>
</section>
</section>                    
                </div>
            </div>

            <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>
        </div>
    </body>
</html>
