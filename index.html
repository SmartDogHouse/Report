<!DOCTYPE html>
<html  dir="ltr">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title></title>
        <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
        <link rel="apple-touch-icon-precomposed" href="images/apple-touch-icon.png">

<link rel="stylesheet" href="./pandoc-uikit/uikit.css">

        <link rel="stylesheet" href="style.css">
        <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />
        <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
        <script src="./pandoc-uikit/uikit.js"></script>
        <script src="./pandoc-uikit/scripts.js"></script>
        <script src="./pandoc-uikit/jquery.sticky-kit.js"></script>

        <meta name="generator" content="pandoc-uikit" />
                        <title>main</title>
        <style type="text/css">code{white-space: pre;}</style>
                                                    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
                               
    </head>

    <body>


        <div class="uk-container uk-container-center uk-margin-top uk-margin-large-bottom">

            
            <div class="uk-grid" data-uk-grid-margin >          
                <div class="uk-width-medium-1-4">
                    <div class="uk-overflow-container" data-uk-sticky="{top:25,media: 768}">
                        <div class="uk-panel uk-panel-box menu-begin" >

                                                        <ul class="incremental">
                                                        <li><a href="#introduzione"><span class="toc-section-number">1</span> Introduzione</a>
                                                        <ul class="incremental">
                                                        <li><a href="#overview"><span class="toc-section-number">1.1</span> Overview</a></li>
                                                        <li><a href="#problemi"><span class="toc-section-number">1.2</span> Problemi</a></li>
                                                        <li><a href="#obiettivi"><span class="toc-section-number">1.3</span> Obiettivi</a></li>
                                                        </ul></li>
                                                        <li><a href="#stato-dellarte"><span class="toc-section-number">2</span> Stato dell’Arte</a></li>
                                                        <li><a href="#analisi-dei-requisiti"><span class="toc-section-number">3</span> Analisi dei Requisiti</a>
                                                        <ul class="incremental">
                                                        <li><a href="#requisiti-di-business"><span class="toc-section-number">3.1</span> Requisiti di Business</a></li>
                                                        <li><a href="#requisiti-utente"><span class="toc-section-number">3.2</span> Requisiti Utente</a></li>
                                                        <li><a href="#requisiti-funzionali"><span class="toc-section-number">3.3</span> Requisiti Funzionali</a></li>
                                                        <li><a href="#requisiti-non-funzionali"><span class="toc-section-number">3.4</span> Requisiti non Funzionali</a></li>
                                                        <li><a href="#requisiti-implementativi"><span class="toc-section-number">3.5</span> Requisiti Implementativi</a></li>
                                                        </ul></li>
                                                        <li><a href="#design-architetturale"><span class="toc-section-number">4</span> Design Architetturale</a>
                                                        <ul class="incremental">
                                                        <li><a href="#architettura-generale"><span class="toc-section-number">4.1</span> Architettura Generale</a></li>
                                                        <li><a href="#scelte-tecnologiche-cruciali"><span class="toc-section-number">4.2</span> Scelte Tecnologiche Cruciali</a></li>
                                                        <li><a href="#pattern-architetturali-utilizzati"><span class="toc-section-number">4.3</span> Pattern Architetturali Utilizzati</a></li>
                                                        </ul></li>
                                                        <li><a href="#design-di-dettaglio"><span class="toc-section-number">5</span> Design di Dettaglio</a>
                                                        <ul class="incremental">
                                                        <li><a href="#design-gestione-cibo-e-acqua"><span class="toc-section-number">5.1</span> Design Gestione Cibo e Acqua</a></li>
                                                        <li><a href="#design-monitoraggio-parametri-vitali"><span class="toc-section-number">5.2</span> Design Monitoraggio Parametri Vitali</a></li>
                                                        <li><a href="#design-videosorveglianza"><span class="toc-section-number">5.3</span> Design Videosorveglianza</a></li>
                                                        <li><a href="#design-del-database"><span class="toc-section-number">5.4</span> Design del Database</a></li>
                                                        <li><a href="#design-webapp"><span class="toc-section-number">5.5</span> Design WebApp</a></li>
                                                        <li><a href="#design-serverless-application"><span class="toc-section-number">5.6</span> Design Serverless Application</a></li>
                                                        </ul></li>
                                                        <li><a href="#implementazione"><span class="toc-section-number">6</span> Implementazione</a>
                                                        <ul class="incremental">
                                                        <li><a href="#software-microcontrollori"><span class="toc-section-number">6.1</span> Software Microcontrollori</a></li>
                                                        <li><a href="#software-videosorveglianza"><span class="toc-section-number">6.2</span> Software Videosorveglianza</a></li>
                                                        <li><a href="#web-app"><span class="toc-section-number">6.3</span> Web App</a></li>
                                                        <li><a href="#funzioni-serverless"><span class="toc-section-number">6.4</span> Funzioni Serverless</a></li>
                                                        <li><a href="#database-dynamodb"><span class="toc-section-number">6.5</span> Database DynamoDB</a></li>
                                                        <li><a href="#immagini-prototipi"><span class="toc-section-number">6.6</span> Immagini prototipi</a></li>
                                                        </ul></li>
                                                        <li><a href="#testing-e-performance"><span class="toc-section-number">7</span> Testing e Performance</a>
                                                        <ul class="incremental">
                                                        <li><a href="#automazione-gabbia-e-monitoraggio-salute"><span class="toc-section-number">7.1</span> Automazione Gabbia e Monitoraggio Salute</a></li>
                                                        <li><a href="#videosorveglianza"><span class="toc-section-number">7.2</span> Videosorveglianza</a></li>
                                                        </ul></li>
                                                        <li><a href="#analisi-di-deployment-su-larga-scala"><span class="toc-section-number">8</span> Analisi di Deployment su Larga Scala</a>
                                                        <ul class="incremental">
                                                        <li><a href="#analisi-interna"><span class="toc-section-number">8.1</span> Analisi Interna</a></li>
                                                        <li><a href="#analisi-esterna"><span class="toc-section-number">8.2</span> Analisi Esterna</a></li>
                                                        <li><a href="#analisi-complessiva"><span class="toc-section-number">8.3</span> Analisi complessiva</a></li>
                                                        </ul></li>
                                                        <li><a href="#piano-di-lavoro"><span class="toc-section-number">9</span> Piano di lavoro</a>
                                                        <ul class="incremental">
                                                        <li><a href="#contributi"><span class="toc-section-number">9.1</span> Contributi</a></li>
                                                        <li><a href="#svolgimento"><span class="toc-section-number">9.2</span> Svolgimento</a></li>
                                                        <li><a href="#sprint-0"><span class="toc-section-number">9.3</span> Sprint 0</a></li>
                                                        <li><a href="#sprint-1"><span class="toc-section-number">9.4</span> Sprint 1</a></li>
                                                        <li><a href="#sprint-2"><span class="toc-section-number">9.5</span> Sprint 2</a></li>
                                                        <li><a href="#sprint-3"><span class="toc-section-number">9.6</span> Sprint 3</a></li>
                                                        <li><a href="#sprint-4"><span class="toc-section-number">9.7</span> Sprint 4</a></li>
                                                        </ul></li>
                                                        <li><a href="#conclusioni"><span class="toc-section-number">10</span> Conclusioni</a>
                                                        <ul class="incremental">
                                                        <li><a href="#sviluppi-futuri"><span class="toc-section-number">10.1</span> Sviluppi Futuri</a></li>
                                                        </ul></li>
                                                        </ul>
                            
                        </div>
                    </div>
                </div>

                <div class="uk-width-medium-3-4">
<section id="introduzione" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduzione</h1>
<p>Smart DogHouse è un progetto che nasce con l’intento di migliorare le condizioni dei cani che si trovano ospiti di un <strong>canile</strong>, mediante l’introduzione di un <strong>supporto informatico</strong> che possa, da un lato, <strong>facilitare operazioni</strong> che già prima venivano svolte e dall’altro <strong>introdurre nuovi strumenti</strong> che vadano a migliorare la gestione del canile.</p>
<section id="overview" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> Overview</h2>
<p>Come riferimento è stato preso in considerazione il <strong>canile comunale di Pisa</strong>, il quale gestore si è offerto di indirizzarci permettendoci di rivolgerci a lui per avere feedback e indicazioni basate su <strong>esperienze reali</strong>.</p>
<p>L’idea ha avuto origine dopo un colloquio con il gestore del canile che, raccontando la propria esperienza, ha evidenziato alcuni <strong>problemi</strong> che riscontra nello svolgimento del proprio lavoro, molti dei quali sono risolvibili attraverso gli <strong>strumenti</strong> e le <strong>competenze</strong> che abbiamo a disposizione. Successivamente, le informazioni ottenute dal canile di Pisa sono state confrontate e integrate a fronte di un colloquio con il <strong>canile Comunale di Cesena</strong>, la quale consulenza è stata indispensabile per riuscire a discernere gli <strong>aspetti comuni</strong> alla maggior parte dei canili da quelle che invece sono <strong>peculiarità</strong> di un canile specifico. Questa capacità di <strong>astrazione</strong> ci ha permesso di definire meglio gli <strong>obiettivi</strong>. Anche se questo non può essere considerato un progetto su commissione, abbiamo fede nel fatto che una volta sviluppata la nostra soluzione, essa possa essere utilizzata come base per sviluppare altri sistemi o rendere più tecnologici canili e gattili che riscontrano le stesse difficoltà.</p>
<figure>
<img src="Images/canili.png" id="fig:Canili" style="width:80.0%" alt="" /><figcaption>I due canili interpellati in qualità di <strong>esperti del dominio</strong><span label="fig:Canili"></span></figcaption>
</figure>
</section>
<section id="problemi" data-number="1.2">
<h2 data-number="1.2"><span class="header-section-number">1.2</span> Problemi</h2>
<p>Il canile di Pisa ospita circa una <strong>sessantina</strong> di cani e gatti di diversa <strong>taglia</strong>, <strong>randagi</strong> o <strong>abbandonati</strong>, che vengono prelevati dagli addetti del canile su segnalazione dei cittadini. I cani restano poi in cura finché non vengono <strong>adottati</strong>, mentre i gatti vengono <strong>rilasciati</strong> subito dopo aver ricevuto le cure mediche ed essersi ripresi. Ad occuparsi della salute dei cani è un <strong>responsabile sanitario</strong> sempre presente nella struttura, che coordina alcuni <strong>veterinari</strong> convenzionati con la struttura. La situazione al canile di Cesena è similare, con la differenza che quest’ultimo non si occupa più del recupero di gatti randagi e il responsabile sanitario non coordina altri veterinari ma si occupa <strong>in autonomia</strong> di tutto ciò che riguarda la salute del cane, dai problemi di routine alle <strong>operazioni chirurgiche</strong>.</p>
<p>I principali problemi che vengono attualmente riscontrati sono i seguenti:</p>
<ul class="incremental">
<li><p><strong>responsabile sanitario:</strong> il responsabile sanitario e alcuni veterinari convenzionati, risiedono all’interno del canile. Attualmente non è possibile monitorare in maniera continuativa lo stato di salute di un animale. Questo spesso si traduce in un intervento tardivo che porta con sé delle limitazioni che con una diagnosi più veloce si sarebbero potute evitare.</p></li>
<li><p><strong>Rifornimento e consumi di cibo ed acqua:</strong> in entrambi i canili la maggior parte del lavoro manuale viene svolta dai volontari che prestano attività in forma gratuita e fortemente discontinua. Non è possibile sapere a priori quanti volontari si presenteranno a dare una mano, ed essendo in tanti non è nemmeno possibile sapere chi ha svolto quali mansioni. Operazioni come il rifornimento di cibo ed acqua vanno quindi monitorate personalmente dal gestore che deve recarsi fisicamente nelle gabbie per controllare gli approvvigionamenti; inoltre non è nemmeno possibile conoscere la quantità di cibo ed acqua consumata da un cane, il che rende più difficile individuare i segnali alimentari che sono sintomi di alcuni problemi di salute.</p></li>
<li><p><strong>Sorveglianza:</strong> né il canile di Pisa, né quello di Cesena, attualmente, dispongono di un sistema di sorveglianza da remoto, pertanto nel momento in cui si verificano furti, effrazioni ed atti vandalici, non è possibile risalire agevolmente al colpevole. E’ assente anche un sistema che possa permettere di sorvegliare da remoto cani che hanno particolari problemi. Nel caso di una gravidanza che volge al termine, ad esempio, il personale del canile è costretto a recarsi frequentemente sul luogo, durante la notte, per controllare se ha avuto inizio il travaglio o se si stanno verificando delle complicanze. Questa necessità crea un disagio al personale che si trova a doversi recare in canile fuori dall’orario di lavoro.</p></li>
<li><p><strong>Assenza di supporto informatico</strong>: attualmente nessuno dei due canili dispone di un’infrastruttura informatica già presente, da poter integrare; inoltre non dispongono nemmeno di un gestionale che dia supporto nella catalogazione degli animali presi in cura.</p></li>
</ul>
</section>
<section id="obiettivi" data-number="1.3">
<h2 data-number="1.3"><span class="header-section-number">1.3</span> Obiettivi</h2>
<p>L’obiettivo è quello di rendere il canile più "Smart", introducendo della strumentazione che permetta di risolvere in maniera parziale o totale le problematiche descritte precedentemente, mantenendo un costo accessibile.</p>
<figure>
<img src="Images/cani.png" id="fig:Obbiettivi" style="width:100.0%" alt="" /><figcaption>Obbiettivi principali<span label="fig:Obbiettivi"></span></figcaption>
</figure>
<p>Nello specifico si vogliono incontrare le esigenze del gestore e degli addetti, agevolando le operazioni di:</p>
<ul class="incremental">
<li><p><strong>monitoraggio dello stato di salute dei cani</strong> tramite:</p>
<ul class="incremental">
<li><p>rilevazione dei <strong>consumi</strong> di cibo e acqua;</p></li>
<li><p>monitoraggio del <strong>comportamento</strong> del cane.</p></li>
</ul>
<p>In questo modo è possibile cogliere in maniera preventiva segnali che possono indicare un problema di salute e aiutare il <strong>responsabile sanitario</strong> nella risoluzione e nella diagnosi dello stesso.</p></li>
<li><p>automatizzazione delle operazioni di <strong>cura quotidiana</strong> attraverso:</p>
<ul class="incremental">
<li><p>automatizzazione del <strong>rifornimento</strong> di cibo e acqua</p></li>
<li><p>possibilità di scegliere, per ciascun cane, la <strong>quantità</strong> del cibo da somministrare e la <strong>frequenza</strong>.</p></li>
</ul>
<p>In questo modo è possibile gestire in maniera più precisa l’alimentazione dei cani e impostare delle quantità di cibo particolari in caso di condizioni di salute che richiedono un particolare piano alimentare, sollevando da questo incarico i volontari, che svolgono un’attività non tracciabile e discontinua. Inoltre, sarà possibile per il <strong>responsabile sanitario</strong> consultare i dati riguardanti l’alimentazione del cane e, di conseguenza, fornire diagnosi più precise.</p></li>
<li><p><strong>sorveglianza globale del canile da remoto</strong>: l’introduzione di un sistema di sorveglianza permetterà a chi di competenza di monitorare lo stato del canile anche da casa.</p></li>
<li><p><strong>Mantenimento dello storico dei dati registrati</strong>: in questo modo sarà possibile consultare sia le informazioni riguardanti i cani che i dati che riguardano le condizioni del canile, permettendo anche di fare dei confronti su base temporale;</p></li>
<li><p><strong>consultazione dei dati acquisiti ed elaborati:</strong> verrà fornita la possibilità di accedere allo storico dei dati medici su un Database, affinché il veterinario abbia una visione globale del quadro medico e possa velocemente filtrare le informazioni anche se non ha seguito il paziente dall’inizio.</p></li>
<li><p><em><span>[</span>optional<span>]</span></em> <strong>monitoraggio approfondito dei parametri vitali</strong>: mediante l’installazione di sensoristica che permetta il monitoraggio di temperatura, battiti, movimento, ecc… sarà possibile tenere ulteriormente sott’occhio cani che si trovano in condizioni di salute che necessitano di particolari attenzioni.</p></li>
<li><p><strong>Introduzione di un sistema informatico:</strong> poiché non vi è un sistema informatico preesistente da integrare e vi sono poche disponibilità economiche, si è pensato di avvalersi di una piattaforma cloud sulla quale è possibile mantenere lo storico ed operare tramite l’utilizzo di un broker MQTT per la comunicazione con sensori e attuatori. Questa soluzione è stata indicata come preferibile dal canile che ritiene più accessibile pagare mensilmente un servizio piuttosto che investire in una soluzione ad hoc.</p></li>
</ul>
</section>
</section>
<section id="stato-dellarte" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Stato dell’Arte</h1>
<p>Il topic scelto non gode di particolare attenzione in letteratura. Dalle informazioni che abbiamo raccolto su ricerche, studi e applicazione di <strong>idee similari</strong> alla nostra è emerso quanto segue:</p>
<ul class="incremental">
<li><p><strong>Automazione</strong>: sono state condotte alcune ricerche che riguardano interventi di <strong>automazione</strong> del sistema di alimentazione per gli allevamenti, ma si tratta di progetti con un forte imprinting <strong>economico</strong>.</p></li>
<li><p><strong>Distribuzione del cibo</strong>: alcune soluzioni commerciali offrono la <strong>distribuzione automatica</strong> del cibo ad orari <strong>temporizzati</strong>, senza possibilità di <strong>dosaggio</strong> o di rilevamento dei <strong>consumi</strong>.</p></li>
<li><p><strong>Monitoraggio parametri</strong>: in ambito commerciale esistono soluzioni che si focalizzano soprattutto sul <strong>monitoraggio</strong> e la <strong>notifica</strong> dei <strong>parametri vitali</strong> dell’animale.</p></li>
<li><p><strong>Fusione dei due ambiti</strong>: <strong>non</strong> siamo riusciti a trovare progetti che fondono i due ambiti come invece fa la nostra proposta. La <strong>nostra</strong> soluzione, infatti, tenta di <strong>fondere</strong> le due idee e di proporre un <strong>sistema remoto</strong> e <strong>scalabile</strong>, che monitori i <strong>parametri vitali</strong>, che possa anche fornire un automatismo alla gestione del <strong>cibo</strong> e dell’<strong>acqua</strong> erogati al cane e, inoltre, che sia in grado sia di <strong>intercettare</strong> la presenza di <strong>sintomi</strong> riguardanti il consumo di cibo e acqua in base all’<strong>analisi</strong> dei dati raccolti.</p></li>
</ul>
<p>Per quanto riguarda, invece, l’ambito dei <strong>sensori</strong>; lo stato dell’arte è in continua evoluzione, e possiamo trovare:</p>
<ul class="incremental">
<li><p><strong><a href="https://ciigar.csc.ncsu.edu/files/bib/Brugarolas2015-DogHeartMonitor.pdf">Sensori ad hoc</a></strong>: impiegati nell’ambito della <strong>ricerca</strong> per il monitoraggio dei parametri vitali dei cani</p></li>
<li><p><strong><a href="https://petpace.com/">Collari smart</a></strong>: che si basano su un’idea simile alla nostra ma sono sistemi <strong>proprietari</strong>, commercializzati come prodotti ad uso domestico, completi di gps e altri sensori e supportati da un’<strong>applicazione</strong> che si rifà a quelle per gli smartwatch. Il costo di questi collari è dell’ordine delle centinaia di euro e deve essere associato ad un <strong>abbonamento</strong> mensile o annuale.</p>
<p><span id="fig:PetPace" label="fig:PetPace">[fig:PetPace]</span> <img src="Images/petpace.png" title="fig:" style="width:80.0%" alt="Pet Pace: uno dei collari smart in commercio basati su un’idea simile alla nostra" /></p></li>
</ul>
<p>I sensori di battiti tradizionali utilizzano un fascio luminoso per identificare la frequenza del battito cardiaco. Questa tecnologia si presta male per gli animali che presentano del pelo, come i cani, per questo sono in via di sviluppo sensori specifici che utilizzano principi diversi. Attualmente sono in corso delle <a href="https://vcs.vetmed.wsu.edu/research/clinical-studies/clinincal-studies-detail/vcs-clinical-studies/2017/06/28/new-ecg-technology">ricerche</a> su sensori di altro genere che possano essere adatti anche anche ai cani.</p>
<p><span>Lorem Ipsum</span></p>
<p><span>2</span> I sensori di battiti tradizionali utilizzano un fascio luminoso per identificare la frequenza del battito cardiaco. Questa tecnologia si presta male per gli animali che presentano del pelo, come i cani, per questo sono in via di sviluppo sensori specifici che utilizzano principi diversi. Attualmente sono in corso delle <a href="https://vcs.vetmed.wsu.edu/research/clinical-studies/clinincal-studies-detail/vcs-clinical-studies/2017/06/28/new-ecg-technology">ricerche</a> su sensori di altro genere che possano essere adatti anche anche ai cani. Nonostante ciò la nostra soluzione utilizza un sensore <a href="https://www.amazon.it/Haljia-Sensore-frequenza-cardiaca-Raspberry/dp/B01CBGH4N6">classico</a>. Presupponendo che si utilizzi un collare smart solo per gli animali che, a causa del loro stato di salute, sono in osservazione, è possibile supporre che il pelo possa essere rasato durante il periodo di degenza.</p>
<figure>
<img src="Images/canili.png" id="fig:doggos" style="width:30.0%" alt="" /><figcaption>I due canili interpellati in qualità di <strong>esperti del dominio</strong><span label="fig:doggos"></span></figcaption>
</figure>
<p>Nonostante ciò la nostra soluzione utilizza un sensore <a href="https://www.amazon.it/Haljia-Sensore-frequenza-cardiaca-Raspberry/dp/B01CBGH4N6">classico</a>. Presupponendo che si utilizzi un collare smart solo per gli animali che, a causa del loro stato di salute, sono in osservazione, è possibile supporre che il pelo possa essere rasato durante il periodo di degenza.</p>
<p>Per quanto riguarda le soluzioni riguardanti l’automatizzazione del cibo e dell’acqua le soluzioni commerciali sono davvero <a href="https://www.fruugo.it/alimentatore-automatico-per-animali-domestici-a-43-l-capacita-alimentatore-intelligente-per-alimentazione-intelligente-per-lalimentazione-del-tempo-e-razionale-con-telecamera-telecomandato-tipo-di-lusso/p-55093501-111996468?language=it&amp;ac=croud">tante</a> molto simili.</p>
<p>Da questo punto di vista la nostra soluzione può dirsi all’avanguardia pur non essendo incentrata sull’uso domestico. Grossa parte di questi sistemi, infatti, usano: sensori del livello dell’acqua, bilance e sensori luminosi. Inoltre alcuni sistemi più all’avanguardia consentono, tramite l’utilizzo di tecnologie come <strong>BLE</strong>, di monitorare da <strong>App</strong> i consumi e gli allarmi, non fornendo però alcun tipo di inferenza.</p>
<p>Attualmente il nostro sistema fornisce un’inferenza banale, ciò non toglie che in un futuro sviluppo associato ad uno studio comportamentale dell’animale non sia possibile implementare inferenze più complesse.</p>
<p>Quanto appena detto costituisce lo stato dell’arte nell’uso commerciale. Per quanto riguarda lo specifico ambito del canile, invece, non sono state trovate applicazioni simili.</p>
<p>Per avere una visione più chiara di quello che è lo stato dei canili in Italia ci siamo rivolti a due <strong>canili</strong>:</p>
<ul class="incremental">
<li><p><strong>ACPA - Canile intercomunale di Cesena</strong> Ci siamo recati fisicamente al canile di Cesena per discutere e toccare con mano lo stato tecnologico dello stabile, questo per valutare la fattibilità e la bontà della nostra soluzione.</p></li>
<li><p><strong>Canile intercomunale "Soffio di Vento"- Pisa</strong> Abbiamo contattato in via totalmente telematica il canile per comprendere se una soluzione del genere esistesse o fosse adottata da qualche parte e per avere una visione concreta dei problemi che vengono riscontrati per i quali avremmo potuto proporre una soluzione.</p></li>
</ul>
<p>Entrambe le fonti ci hanno confermato che almeno in Italia lo stato dei canili risulta essere tecnologicamente obsoleto. La soluzione proposta ha ricevuto un caloroso interesse da parte di entrambi i canili, con particolare entusiasmo per le rilevazioni dei consumi e il monitoraggio dei parametri vitali, con notifiche in caso di rilevazioni anomale. Attualmente i canili contattati sono privi di una qualunque forma di <strong>monitoraggio</strong>, o <strong>automatizzazione</strong> di qualunque genere. Il punto di forza di questo progetto risiede nella sua semplicità di dispiegamento, nelle tecnologie altamente accessibili e nel fatto che molti canili avrebbero il bisogno di una soluzione simile. Il <strong>collare</strong> e l’<strong>inferenza</strong> sui consumi sono la parte che ha riscosso più successo poiché l’automatizzazione presenta alcuni svantaggi. A detta del canile di Cesena dipende dalle norme del canile e dal modo con cui si vogliono addestrare i cani poiché buona parte delle pratiche di addestramento ruota attorno al cibo, che viene utilizzato sia come premio che come modo per far si che l’umano venga percepito come alpha. La più grande critica mossa riguarda il fatto che se l’animale viene nutrito in maniera automatica allora non sarà abituato a ricevere cibo da persone, ed essendo l’adozione dei cani lo scopo principe del canile è probabile che il sistema automatizzato venga adottato solo da canili di grandezza medio-grande o la quale gestione non prevede l’addestramento.</p>
</section>
<section id="analisi-dei-requisiti" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Analisi dei Requisiti</h1>
<p>In questa fase sono stati individuati i <strong>requisiti del sistema</strong>, partendo dalle descrizioni di alto livello, ottenute dal committente durante il <strong>knowledge crunching</strong>. Successivamente si è proceduto con un raffinamento che ha portato alla definizione di requisiti più <strong>specifici</strong>, <strong>chiari</strong> e <strong>strutturati</strong>.</p>
<section id="requisiti-di-business" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Requisiti di Business</h2>
<p>Si definiscono di seguito le aspettative del cliente e i requisiti che il prodotto dovrà soddisfare, espressi con una terminologia ad elevato livello astrattivo.</p>
<ul class="incremental">
<li><p>Il prodotto dovrà <strong>diminuire l’intervento umano</strong> necessario per la quotidiana cura degli ospiti (Riempimento ciotola acqua/cibo); la riduzione del lavoro deve essere maggiore o uguale al 30%.</p></li>
<li><p>Il prodotto dovrà consentire di <strong>diminuire il lavoro su base volontaria</strong>, grazie alla riduzione delle operazioni di cura quotidiana, permettendo ai volontari di concentrarsi solo sulla socializzazione e lo svago dell’animale. Diminuisce così l’interferenza al di fuori delle loro mansioni, e migliora la tracciabilità del lavoro svolto, essendo il lavoro volontario incostante e meno affidabile.</p></li>
<li><p>Opzionalmente il prodotto dovrà <strong>fornire un monitoraggio a distanza</strong> degli animali ospitati. Questo consentirà al personale incaricato di monitorare parametri come: frequenza cardiaca e temperatura corporea. Verrà diminuito anche l’intervento veterinario, non essendo necessaria la presenza in loco del professionista. La riduzione delle presenze dovrà consentire di diminuire i costi di un valore maggiore o uguale al 10%.</p></li>
</ul>
</section>
<section id="requisiti-utente" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> Requisiti Utente</h2>
<p>Di seguito vengono riportate le richieste mosse dal cliente in maniera informale evitando termini tecnici, successivamente tali richieste saranno formalizzate per quanto possibile. Il prodotto dovrà fornire:</p>
<ul class="incremental">
<li><p>l’accesso al sistema da <strong>qualunque dispositivo</strong> munito di connessione alla rete, anche esterna al canile</p></li>
<li><p><strong>prestazioni adeguate</strong> alle operazioni richieste (con soglie adeguate caso per caso), come il rilevare se il cane ha bisogno di cibo o acqua</p></li>
<li><p>un interfaccia intuitiva, comprensiva di una pagina per l’accesso e un menu principale</p></li>
<li><p>uno <strong>storico</strong> per ogni animale</p></li>
<li><p>un a<strong>accesso rapido e reattivo</strong> evitando tempi troppo lunghi per le operazioni</p></li>
<li><p>un <strong>sistema di sorveglianza semi automatizzato</strong> in grado di identificare eventuali anomalie, come cani che escono senza permesso</p></li>
<li><p><strong>opzionalmente</strong> delle <strong>notifiche sullo stato di salute</strong> dell’animale al personale</p></li>
<li><p>delle <strong>notifiche</strong> in caso di <strong>malfunzionamento</strong> del sistema stesso</p></li>
<li><p>delle <strong>notifiche</strong>, nel caso in cui il cibo sia in <strong>esaurimento</strong></p></li>
</ul>
<section id="user-stories" data-number="3.2.1">
<h3 data-number="3.2.1"><span class="header-section-number">3.2.1</span> User stories</h3>
<p>Di seguito sono riportate tutte le <strong>user stories</strong> ritenute utili per lo sviluppo del prodotto.</p>
<ul class="incremental">
<li><p>Come <strong>gestore</strong> voglio:</p>
<ul class="incremental">
<li><p>poter <strong>visualizzare</strong> le i dati relativi all’<strong>occupante</strong> di una <strong>gabbia</strong></p></li>
<li><p>voglio poter <strong>impostare</strong> i <strong>dati</strong> dell’occupante di una gabbia</p></li>
<li><p>poter <strong>aggiungere un cane</strong> a una gabbia</p></li>
<li><p>poter <strong>rimuovere un cane</strong> da una gabbia</p></li>
<li><p>poter visualizzare i <strong>consumi TOTALI</strong> del canile</p></li>
<li><p><em>opzionalmente</em> poter <strong>visualizzare</strong> l’<strong>umidità</strong> e la <strong>temperatura</strong> ambientale</p></li>
<li><p>poter <strong>impostare</strong> i dati relativi allo <strong>stato di salute</strong> di un cane</p></li>
<li><p>poter visualizzare i <strong>consumi di cibo</strong> relativi a un cane in un determinato lasso di tempo</p></li>
<li><p>poter visualizzare i <strong>consumi di acqua</strong> relativi a un cane in un determinato lasso di tempo</p></li>
</ul></li>
<li><p>Come <strong>responsabile sanitario</strong> voglio:</p>
<ul class="incremental">
<li><p><em>opzionalmente</em> poter <strong>visualizzare i battiti</strong> di un cane</p></li>
<li><p><em>opzionalmente</em> ricevere una <strong>notifica</strong> in caso di rilevazione di <strong>anomalie</strong> nei <strong>battiti</strong> o nella di un cane</p></li>
<li><p><em>opzionalmente</em> poter <strong>visualizzare la temperatura corporea</strong> di un cane</p></li>
<li><p><em>opzionalmente</em> ricevere una <strong>notifica</strong> in caso di rilevazione di <strong>anomalie</strong> nella <strong>temperatura</strong> corporea di un cane</p></li>
<li><p><em>opzionalmente</em> poter <strong>impostare</strong> gli intervalli di <strong>temperatura e battiti</strong> fuori dai quali vi è un’anomalia</p></li>
<li><p>poter <strong>impostare</strong> gli intervalli delle <strong>quantità di cibo e acqua</strong> assunti, fuori dai quali vi è un’anomalia</p></li>
<li><p>ricevere una <strong>notifica</strong> in caso di <strong>anomalie</strong> nella quantità di <strong>acqua</strong> assunta da un cane</p></li>
<li><p>ricevere una <strong>notifica</strong> in caso di <strong>anomalie</strong> nella quantità di <strong>cibo</strong> assunto da un cane</p></li>
<li><p>poter <strong>impostare</strong> i dati relativi allo <strong>stato di salute</strong> di un cane</p></li>
<li><p>poter <strong>impostare la quantità di cibo</strong> da erogare a un cane</p></li>
<li><p>poter visualizzare i <strong>consumi di cibo</strong> relativi a un cane in un determinato lasso di tempo</p></li>
<li><p>poter visualizzare i <strong>consumi di acqua</strong> relativi a un cane in un determinato lasso di tempo</p></li>
</ul></li>
<li><p>Come <strong>addetto ai rifornimenti</strong> voglio:</p>
<ul class="incremental">
<li><p>che la distribuzione di cibo agli animali sia automatizzata</p></li>
<li><p>che la distribuzione di acqua agli animali sia automatizzata</p></li>
<li><p>essere notificato se in una gabbia sta per esaurirsi il cibo</p></li>
<li><p>ricevere una notifica in caso di malfunzionamento al sistema</p></li>
<li><p>poter impostare la quantità di cibo da erogare a tutti i cani di una determinata taglia</p></li>
<li><p>poter <strong>impostare la quantità di cibo</strong> da erogare a un cane</p></li>
<li><p>poter visualizzare i <strong>consumi di cibo</strong> relativi a un cane in un determinato lasso di tempo</p></li>
<li><p>poter visualizzare i <strong>consumi di acqua</strong> relativi a un cane in un determinato lasso di tempo</p></li>
</ul></li>
<li><p>Come <strong>addetto alla sorveglianza</strong> voglio:</p>
<ul class="incremental">
<li><p>poter visualizzare le immagini acquisite dalla videocamera di sorveglianza</p></li>
<li><p>notificato in caso di uscita non autorizzata di un cane</p></li>
<li><p><em>opzionalmente</em> essere notificato in caso di rilevazione di suoni forti o anomali</p></li>
<li><p><em>opzionalmente</em> poter visualizzare l’umidità e la temperatura ambientale</p></li>
</ul></li>
</ul>
<p>Di seguito viene riportato lo schema, sotto-forma di diagramma di Venn, esplicativo delle intersezioni tra le User-Stories e le figure dell’organigramma.</p>
<figure>
<img src="Miro/DiagrammaUserStories.jpg" style="width:100.0%" alt="" /><figcaption>Diagramma di Venn delle User-Stories</figcaption>
</figure>
</section>
</section>
<section id="requisiti-funzionali" data-number="3.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> Requisiti Funzionali</h2>
<section id="casi-duso" data-number="3.3.1">
<h3 data-number="3.3.1"><span class="header-section-number">3.3.1</span> Casi d’uso</h3>
<figure>
<img src="DrawIo/useCaseWholeSystem.png" style="width:90.0%" alt="" /><figcaption>Diagramma dei casi d’uso del sistema, rappresenta le principali azioni effettuate degli attori</figcaption>
</figure>
<p>Si elencano i requisiti funzionali per ognuno dei seguenti macro-componenti:</p>
<ul class="incremental">
<li><p>Applicativo web</p></li>
<li><p>Opzionale collare</p></li>
<li><p>Strumentazione gabbia</p></li>
<li><p>Strumentazione videosorveglianza</p></li>
</ul>
</section>
<section id="applicativo-web" data-number="3.3.2">
<h3 data-number="3.3.2"><span class="header-section-number">3.3.2</span> Applicativo web</h3>
<p>L’applicativo web deve consentire ad ogni utente di accedere con una serie di credenziali, e dividere le operazioni consentite in base ai permessi concessi. Il sito è suddiviso in tre pagine principali:</p>
<ul class="incremental">
<li><p><strong>pagina di login</strong> La pagina iniziale a cui ogni utente deve far riferimento per effettuare l’accesso. Sostanzialmente contiene solo gli elementi necessari per effettuare il <strong>login</strong>, non è prevista una funzione di registrazione autonoma.</p></li>
<li><p><strong>home gestore</strong> Il gestore ha accesso alla pagina di amministrazione, dov’è possibile:</p>
<ul class="incremental">
<li><p>registrare un nuovo utente</p></li>
<li><p>eliminare un utente</p></li>
<li><p>visualizzare le statistiche del canile</p></li>
</ul></li>
<li><p><strong>home addetto rifornimenti</strong> La schermata deve consentire di:</p>
<ul class="incremental">
<li><p>visualizzare le eventuali notifiche</p></li>
<li><p>visualizzare i consumi di un cane</p></li>
<li><p>impostare la quantità di cibo adeguata per taglia di cane</p></li>
</ul></li>
<li><p><strong>home addetto sorveglianza</strong> La home del sorvegliante deve fornire:</p>
<ul class="incremental">
<li><p>un accesso in diretta alle videocamere disponibili</p></li>
<li><p>deve essere possibile aggiungere o rimuovere una videocamera</p></li>
<li><p>visualizzare le notifiche se presenti</p></li>
</ul></li>
<li><p><strong>home altri addetti</strong> In un futuro sviluppo del prodotto è certamente contemplata l’aggiunta di altre mansioni o addetti.</p></li>
<li><p><strong>responsabile sanitario</strong> La pagina deve consentire di:</p>
<ul class="incremental">
<li><p>visualizzare lo stato di salute di un cane</p></li>
<li><p>visualizzare i consumi di un cane</p></li>
<li><p>impostare la quantità di cibo per un cane degente o in terapia</p></li>
<li><p>aggiornare lo stato di salute di un cane</p></li>
</ul></li>
</ul>
<p>Nonostante un addetto possa ricoprire più ruoli, è stato scelto di modellare separatamente ogni mansione, questo consente: un maggiore controllo, rende più chiara la struttura e aiuta il lettore nella comprensione. Inoltre l’applicativo consentirà ad un utente di detenere uno o più ruoli, rendendo più agevole l’utilizzo.</p>
</section>
<section id="opzionale-collare" data-number="3.3.3">
<h3 data-number="3.3.3"><span class="header-section-number">3.3.3</span> Opzionale: collare</h3>
<p>Il collare smart deve costantemente inviare aggiornamenti sui parametri vitali dell’animale quali:</p>
<ul class="incremental">
<li><p>La frequenza cardiaca</p></li>
<li><p>La temperatura dell’animale</p></li>
</ul>
</section>
<section id="strumentazione-gabbia" data-number="3.3.4">
<h3 data-number="3.3.4"><span class="header-section-number">3.3.4</span> Strumentazione gabbia</h3>
<p>La gabbia smart deve:</p>
<ul class="incremental">
<li><p>monitorare il consumo di cibo e acqua del cane inviando aggiornamenti costanti</p></li>
<li><p>rifornire la ciotola di acqua quando troppo bassa</p></li>
<li><p>rifornire la ciotola di cibo con la quantità desiderata quando mancante</p></li>
<li><p>notificare la mancanza di cibo nel serbatoio</p></li>
</ul>
</section>
<section id="strumentazione-videosorveglianza" data-number="3.3.5">
<h3 data-number="3.3.5"><span class="header-section-number">3.3.5</span> Strumentazione videosorveglianza</h3>
<p>La strumentazione deve fornire uno streaming video e audio costante nel tempo. La bidirezionalità è opzionale.</p>
</section>
</section>
<section id="requisiti-non-funzionali" data-number="3.4">
<h2 data-number="3.4"><span class="header-section-number">3.4</span> Requisiti non Funzionali</h2>
<p>Il primo vicolo individuato è quello economico. Il costo del servizio, essendo l’attività non a scopo di lucro e mantenuta grazie all’azione dei volontari, deve essere minimo. Questo è comprensivo dell’istallazione, dei materiali e dei costi di servizio. Un secondo vincolo rappresenta la sicurezza, l’eventuale introduzione di strumentazione all’interno del canile non deve rappresentare in alcun modo un pericolo per la salute dell’animale.</p>
<p>Il sistema dovrà rispettare alcuni requisiti non funzionali che ne determineranno la <strong>qualità</strong>:</p>
<section id="di-sistema" data-number="3.4.1">
<h3 data-number="3.4.1"><span class="header-section-number">3.4.1</span> Di Sistema</h3>
<ul class="incremental">
<li><p><strong>Reattività</strong>:</p>
<ul class="incremental">
<li><p>l’utente non deve percepire <strong>ritardi</strong> nell’ordine dei secondi tra l’invio di un comando e l’esecuzione dello stesso all’interno della piattaforma.</p></li>
<li><p>le notifiche standard del sistema devono essere mostrate ai relativi utenti con un ritardo complessivo massimo non superiore al minuto.</p></li>
<li><p>le notifiche urgenti del sistema, ossia quelle relative a malfunzionamenti gravi o alla salute dell’animale, devono essere mostrate ai relativi utenti con un ritardo complessivo massimo non superiore ai dieci secondi.</p></li>
</ul></li>
<li><p><strong>Scalabilità</strong>: L’applicativo deve necessariamente consentire di aumentare o diminuire il numero di animali gestiti. Ciò deve avvenire senza una sensibile ripercussione sulle prestazioni del sistema e un disagio minimo a livello pratico. Per prevenire, inoltre, che la presenza di una connessione cablata limiti la scalabilità del sistema, è desiderabile che non ci siano altri collegamenti al di fuori dell’alimentazione già presente.</p></li>
<li><p><strong>Fault tolerance</strong>: la <strong>gestione degli errori</strong> deve essere adeguatamente implementata affinché le interruzioni involontarie non danneggino innanzitutto la salute degli animali. Eventuali malfunzionamenti di apparecchiature o sensoristica all’interno del canile non devono pregiudicare il funzionamento complessivo dell’applicativo, ma al massimo della singola unità logica.</p></li>
</ul>
</section>
<section id="della-sensoristica" data-number="3.4.2">
<h3 data-number="3.4.2"><span class="header-section-number">3.4.2</span> Della Sensoristica</h3>
<ul class="incremental">
<li><p><strong>Precisione</strong>:</p>
<ul class="incremental">
<li><p><strong>Bilancia</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 10 grammi.</p></li>
<li><p><strong>Temperatura</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 2 gradi.</p></li>
<li><p><strong>Umidità</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 5%.</p></li>
<li><p><strong>Livello acqua</strong> lo scostamento massimo tra più misure deve essere inferiore o uguale a 1 centimetro.</p></li>
<li><p><strong>Frequenza cardiaca</strong> lo scarto tra misure sulla stessa frequenza deve essere al massimo 10 battiti.</p></li>
</ul></li>
<li><p><strong>Risoluzione</strong>:</p>
<ul class="incremental">
<li><p><strong>Bilancia</strong> il range di misura, partendo da vuota, deve riuscire a comprendere almeno un Kg.</p></li>
<li><p><strong>Temperatura</strong> il range deve variare tra 0 e 50 gradi.</p></li>
<li><p><strong>Umidità</strong> il range di umidità deve essere incluso tra 20-80%.</p></li>
<li><p><strong>Livello acqua</strong> Il range deve variare almeno di tre cm.</p></li>
<li><p><strong>Videocamera</strong>: necessaria almeno una risoluzione di 420p, non è richiesta la visione notturna.</p></li>
<li><p><strong>Frequenza cardiaca</strong> la misurazione deve essere in grado di rilevare una frequenza che oscilla tra i 60 e i 160 battiti al minuto.</p></li>
<li><p><strong>Microfono</strong> deve essere in grado di determinare suoni ad elevata intensità compresi tra 50 e 130 dB.</p></li>
</ul></li>
<li><p><strong>Accuratezza</strong>:</p>
<ul class="incremental">
<li><p><strong>Bilancia</strong> lo scostamento massimo dal valore reale deve essere inferiore o uguale a 10 grammi.</p></li>
<li><p><strong>Temperatura</strong> Lo scostamento dalla temperatura effettiva deve essere minore di 2 gradi.</p></li>
<li><p><strong>Umidità</strong> Si accetta un massimo di 5% accuratezza.</p></li>
<li><p><strong>Livello acqua</strong> l’accuratezza minima deve essere di 2cm.</p></li>
<li><p><strong>Frequenza cardiaca</strong> l’errore non deve superare i cinque battiti al minuto.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="requisiti-implementativi" data-number="3.5">
<h2 data-number="3.5"><span class="header-section-number">3.5</span> Requisiti Implementativi</h2>
<p>Si definiscono i constraint a livello di implementazione che sarà necessario rispettare nella realizzazione del progetto.</p>
<section id="metodologie-e-tecnologie-utilizzate" data-number="3.5.1">
<h3 data-number="3.5.1"><span class="header-section-number">3.5.1</span> Metodologie e Tecnologie Utilizzate</h3>
<p>Il software dovrà essere realizzato utilizzando almeno in parte le tecnologie studiate durante il corso di Smart-City. Dovranno inoltre essere necessariamente applicati i principi e i paradigmi assimilati durante lo stesso. Lo scopo infatti è quello di sviluppare software di valore sociale e importanza strategica per le amministrazioni e l’economia locale. L’applicazione software dovrà essere infatti d’ausilio alla realizzazione di servizi innovativi in contesti di città digitali. E’ necessario al raggiungimento di tale scopo, l’utilizzo di tecnologie di sensing e sistemi embedded per l’interfacciamento con il mondo fisico. Il focus preferibilmente sarà sulla programmazione di sistemi studiati, quali Raspberry PI e microcontrollori. A questi dovranno essere interfacciati sensori e attuatori IoT, tra i quali ve ne devono essere alcuni di complessità non banale. L’utilizzo dei protocolli di comunicazione dovrà essere adeguato all’uso che ne verrà fatto (MQTT). La metodologia di progettazione inoltre dovrà favorire lo sviluppo di applicativi mobili, in grado di essere usati in contesti e con dispositivi differenti. Altre tecnologie preferibilmente utilizzabili, data la diffusione oramai pervasiva, sono Cloud Computing e Fog Computing, eventualmente con piattaforme studiate come Amazon Web Services. Per la parte interfaccia utente verranno sviluppate Dashboard ad-hoc per la visualizzazione delle informazioni ricavate dai dati trasmessi dai sensori. Infine verrà possibilmente anche inclusa una parte di visione artificiale tramite l’utilizzo di videocamere per lo streaming, eventualmente con una minima elaborazione per la sorveglianza.</p>
</section>
</section>
</section>
<section id="design-architetturale" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Design Architetturale</h1>
<p>Dopo un intenso periodo di Domain Driven Design, si è passati si è proceduto alla fase di Design Architetturale, agevolata di molto da quest’ultimo. Infatti da un confronto mirato con il cliente l’architettura ottimale è emersa quasi naturalmente. Lasciando spazio alla definizione dei dettagli più tecnici che riportiamo in seguito.</p>
<section id="architettura-generale" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Architettura Generale</h2>
<p>L’architettura generale del sistema è stata concepita in due macro aree: la parte IoT [Fig. <a href="#fig:DesignArchitettura" data-reference-type="ref" data-reference="fig:DesignArchitettura">4.1</a>. in alto] e la parte cloud [Fig. <a href="#fig:DesignArchitettura" data-reference-type="ref" data-reference="fig:DesignArchitettura">4.1</a>. in basso]. Le due sfruttano la connessione internet per connettersi, lo scambio di messaggi avviene attraverso il protocollo MQTT, mentre il flusso video viene passato per mezzo del protocollo RTSP.</p>
<p>Il sistema IoT risiede su una rete privata e comunica all’esterno per mezzo di questi due protocolli. Le parti salienti sono la sensoristica che fornisce le informaioni sull’ambiente circostante al microcontrollore, il quale le elabora e utilizza gli attuatori in base alle informazioni ricavate sia dai sensori che dal cloud.</p>
<p>La parte cloud si interfaccia per mezzo dell’applicativo IOT Core ai sensori, i messaggi MQTT vengono elaborati da AWS Lambda e, qualora opportuno, immagazzinati come dati nel database. L’applicativo web, hostato su AWS Amplify, si interfaccia anch’esso con AWS Lambda, passando per Amazon API Gateway. Questo sia per recuperare i dati dal database DynamoDB e mostrare le statistiche, che per diramare il cambio dei settaggi fino ai microcontrollori. Infine, l’applicativo si occupa anche di mostrare il flusso video proveniente dalla board per le telecamere di sorveglianza.</p>
<figure>
<img src="DrawIo/Architecture.png" id="fig:DesignArchitettura" style="width:80.0%" alt="" /><figcaption>Design dell’architettura generale del sistema<span label="fig:DesignArchitettura"></span></figcaption>
</figure>
</section>
<section id="scelte-tecnologiche-cruciali" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Scelte Tecnologiche Cruciali</h2>
<section id="aws" data-number="4.2.1">
<h3 data-number="4.2.1"><span class="header-section-number">4.2.1</span> AWS</h3>
<p>Tra i servizi messi a disposizione da AWS vi è anche Amazon Cognito che permette di gestire gli utenti. E’ stato valutato Amazon Cognito ma è stato scartato perché gli utenti sono troppo pochi.</p>
</section>
<section id="protocolli-di-comunicazione" data-number="4.2.2">
<h3 data-number="4.2.2"><span class="header-section-number">4.2.2</span> Protocolli di comunicazione</h3>
<section id="scambio-messaggi" data-number="4.2.2.1">
<h4 data-number="4.2.2.1"><span class="header-section-number">4.2.2.1</span> Scambio messaggi</h4>
<p>Come protocolli di comunicazione sono stati considerati i principali protocolli per la comunicazione IoT. Tra quelli di livello applicazione:</p>
<ul class="incremental">
<li><p><strong>AMQP (Advanced Message Queuing Protocol)</strong>, protocollo che consente a un’ampia gamma di sistemi e applicazioni di interagire, creando messaggistica standardizzata su scala industriale.</p></li>
<li><p><strong>CoAP (Constrained Application Protocol)</strong>, protocollo adatto alle limitazioni di larghezza di banda e di rete, per dispositivi con capacità limitata, ma prevalentemente per la connessione nelle comunicazioni da computer a computer.</p></li>
<li><p><strong>DDS (Data Distribution Service)</strong>, protocollo per comunicazioni peer-to-peer. In generale semplifica la distribuzione, incrementa l’affidabilità e riduce la complessità.</p></li>
<li><p><strong>MQTT (Message Queue Telemetry Transport)</strong>, protocollo di messaggistica progettato per comunicazioni IoT. MQTT usa un criterio di tipo publish-subscribe ed è ideale per dispositivi di dimensioni ridotte che richiedono efficienza a livello di larghezza di banda e uso della batteria.</p></li>
</ul>
<p>La scelta è ricaduta su MQTT per la sua leggerezza ed efficienza, per la possibilità di instaurare comunicazioni bidirezionali tra molti dispositivi. Il design inoltre è molto semplificato dalla possibilità di creare topic a cui iscriversi o in cui pubblicare i messaggi.</p>
</section>
<section id="streaming-video" data-number="4.2.2.2">
<h4 data-number="4.2.2.2"><span class="header-section-number">4.2.2.2</span> Streaming Video</h4>
<p>Per lo streaming video sono stati considerate due opzioni: streaming attraverso RTSP e attraverso HTTP con un server e HTML5. RTSP è di sicuro la scelta più popolare perché adottato come protocollo dalle IP-cam e telecamere di sorveglianza. Nonostante ciò non è compatibile con HTTP e, non potendo fare lo stream su HTTP direttamente, non è visualizzabile nativamente dai browser. Questo protocollo è infatti usato internamente alle reti private. Volendo esporre il flusso video anche al di fuori della rete privata del committente la scelta è ricaduta sulla seconda opzione. Inoltre, con questa tecnologia alla videosorveglianza si ha accesso con qualsiasi browser, da computer o da smartphone.</p>
</section>
</section>
<section id="microcontrollori-e-soc" data-number="4.2.3">
<h3 data-number="4.2.3"><span class="header-section-number">4.2.3</span> Microcontrollori e Soc</h3>
<section id="hardware" data-number="4.2.3.1">
<h4 data-number="4.2.3.1"><span class="header-section-number">4.2.3.1</span> Hardware</h4>
<p>Le piattaforme di sviluppo per l’IoT tenute presente sono state molteplici, da board con potenza computazionale più elevata, come Raspberry Pi, a scendere fino a ESP e le varianti Arduino.</p>
<p>Le board Arduino sono state scartate quasi subito, per la poca potenza computazionale e la necessità di moduli aggiuntivi per le connessioni. La board RaspBerry Pi è stata scelta per task più computazionalmente onerosi, legati alla gestione ambientale, quali la video sorveglianza e l’analisi immagini. Questa scelta non può essere invece adottata per la gestione delle gabbie. Le principali motivazioni risiedono nel fatto che il numero è variabile e il costo supererebbe molto superiore al budget. La scelta in questo caso è ricaduta sull’ESP, non solo per il forte fattore cost-competitive, e per il supporto a Bluetooth e WiFi integrati, ma anche per il supporto della community e l’ottima potenza computazionale. Inoltre, rinunciando all’analisi immagini e alla qualità video a favore dei costi, il cliente potrà anche scegliere di sostituire la board Raspberry con un più economico ESP32-CAM. Con l’ESP8266 le prime settimane il lavoro di indagine preliminare ha rilevato qualche che risultava troppo limitato per utilizzare MicroPython. Tra ESP8266 e ESP32 è stato preferito quest’ultimo, anche per lasciare della capacità di calcolo per eventuali future espansioni e richieste del committente.</p>
</section>
<section id="linguaggio-di-programmazione" data-number="4.2.3.2">
<h4 data-number="4.2.3.2"><span class="header-section-number">4.2.3.2</span> Linguaggio di programmazione</h4>
<p>Per quanto riguarda l’implementazione del codice nel microcontrollore, sono state presi in considerazione quattro scelte relative ai framework di sviluppo e ai linguaggi da adottare:</p>
<ul class="incremental">
<li><p><strong>C++</strong> è il linguaggio attualmente più diffuso nell’ambito.</p></li>
<li><p><strong>Node-RED</strong> è un tool di programmazione flow-based basato su browser, sviluppato su NodeJs e programmabile in JavaScript.</p></li>
<li><p><strong>MicroPython</strong> è un porting più leggero del compilatore Python3, eseguibile direttamente su microcontrollori. Include le principali librerie di Python e moduli aggiuntivi per l’accesso all’hardware di basso livello.</p></li>
<li><p><strong>Espruino</strong> è un interprete JavaScript open-source per microcontrollori. E’ stato progettato per unità con poca RAM.</p></li>
</ul>
<p>Sicuramente il più performante e con più librerie è C, ma risulta anche difficilmente testabile e pone challange non indifferenti per la configurazione dei sensori e per lo sviluppo di programmi molto complessi. Node-RED, basato su Node.js, ha il pieno vantaggio del suo modello non bloccante e event-driven. MicroPython d’altra parte offre un modello ad oggetti, testabile, sia semplice che elastico, con una buona base di librerie. Infine, Espruino, interprete JavaScript anch’esso, di facile utilizzo e dall’interfaccia semplificata. I fattori chiave che il team ha preso in considerazione per la scelta sono stati:</p>
<ul class="incremental">
<li><p>la potenza espressiva rapportata alla chiarezza del linguaggio.</p></li>
<li><p>la testabilità del codice</p></li>
<li><p>il numero di librerie e la futura possibilità di estensione del progetto.</p></li>
</ul>
<p>Alla luce delle considerazioni fatte, si è scelto <strong>MicroPython</strong> per lo sviluppo, il testing e l’automatizzazione nei microcontrollori. Questo permette di allinearsi con l’utilizzo di <strong>Pyhton</strong> per il Raspberry.</p>
</section>
</section>
</section>
<section id="pattern-architetturali-utilizzati" data-number="4.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> Pattern Architetturali Utilizzati</h2>
<section id="client-server" data-number="4.3.1">
<h3 data-number="4.3.1"><span class="header-section-number">4.3.1</span> Client-Server</h3>
<p>L’utilizzo del pattern client-server, nella videosorveglianza, ha permesso di esporre il flusso video su un server apposito e di accederci da qualunque dispositivo dotato di connessione.</p>
</section>
<section id="pusblish-subscribe" data-number="4.3.2">
<h3 data-number="4.3.2"><span class="header-section-number">4.3.2</span> Pusblish-Subscribe</h3>
<p>L’utilizzo del pattern publish-subscribe, è stata una scelta chiave per la modularità del sistema. La divisione in topic ha portato un maggiore ordine e una modellazione più vicina al vero dominio.</p>
</section>
<section id="master-slave" data-number="4.3.3">
<h3 data-number="4.3.3"><span class="header-section-number">4.3.3</span> Master-Slave</h3>
<p>E’ stato fatto uso dell’architettura master-slave per la gestione dei microcontrollori. Questa permette di espanderne il numero a piacimento, mandando istruzioni specifiche o generali per controllarne il comportamento.</p>
</section>
<section id="scheduling-cooperativo" data-number="4.3.4">
<h3 data-number="4.3.4"><span class="header-section-number">4.3.4</span> Scheduling Cooperativo</h3>
<p>Nei sistemi embedded è stato adottato lo scheduling cooperativo per evitare tante pitfall dello scheduling preemptive, quali l’interruzione di un processo di misura Real Time, quale quello della chiusura della valvola dell’acqua o la misura del battito cardiaco.</p>
</section>
<section id="state-machine" data-number="4.3.5">
<h3 data-number="4.3.5"><span class="header-section-number">4.3.5</span> State Machine</h3>
<p>Per definire il comportamento dei microcontrollori in maniera chiara è stata usata la modellazione con macchine a stati. Questa ha permesso di ridurre la probabilità di bug nel software e di isolare i componenti permettendo una futura espansione del comportamento.</p>
</section>
</section>
</section>
<section id="design-di-dettaglio" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Design di Dettaglio</h1>
<section id="design-gestione-cibo-e-acqua" data-number="5.1">
<h2 data-number="5.1"><span class="header-section-number">5.1</span> Design Gestione Cibo e Acqua</h2>
<p>Per l’automatizzazione e la gestione di cibo e acqua si è partiti dalle user-stories e dal modello del dominio costruito per sviluppare l’applicativo desiderato. Osservando i requisiti è stato progettato il modello fisico e l’interazione dell’animale con esso. Si riporta di seguito il <strong>design del prototipo fisico</strong>, con i sensori e attuatori in giallo e la spiegazione del suo funzionamento [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a>]. Il design permette la modularità tra cibo e acqua, scegliendo all’occorrenza solo uno dei due o entrambi.</p>
<figure>
<img src="Images/CiboAcqua.png" id="fig:ciboacqua" style="width:100.0%" alt="" /><figcaption>Design Prototipo Cibo e Acqua (sensori e attuatori in giallo)<span label="fig:ciboacqua"></span></figcaption>
</figure>
<section id="acqua" data-number="5.1.1">
<h3 data-number="5.1.1"><span class="header-section-number">5.1.1</span> Acqua</h3>
<p>Per far fronte alla misurazione dei consumi, è stato innanzitutto necessario scegliere un sensore per ricavarne il <strong>livello del liquido</strong> [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a>]. Il sensore deve ritornare un valore proporzionale alla percentuale di liquido rimanente. I consumi dell’animale a questo punto verranno inviati in cloud.</p>
<p>Per quanto riguarda l’esigenza di riempimento dell’acqua, inizialmente la scelta era ricaduta su due sensori che rivelassero quando il liquido è al minimo o al massimo. In seguito questo design è stato semplificato usando direttamente il sensore introdotto per l’invio dei dati relativi al livello del liquido. Successivamente è necessario che il sensore si interfacci con un’<strong>elettrovalvola</strong> [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a>] per poter riempire la ciotola aprendo o chiudendo il flusso d’acqua all’occorrenza.</p>
<p>Il sistema deve essere modulare per design: qualora non si disponga del sistema idrico per poter rifornire la ciotola, devono comunque essere mandati i consumi con l’aggiunta di una notifica se se l’acqua sta per terminare.</p>
<section id="macchina-a-stati" data-number="5.1.1.1">
<h4 data-number="5.1.1.1"><span class="header-section-number">5.1.1.1</span> Macchina a stati</h4>
<p>Il comportamento è stato modellato come una macchina a stati [Fig. <a href="#fig:statediagramWater" data-reference-type="ref" data-reference="fig:statediagramWater">5.2</a>]. Ciò ha permesso di chiarire meglio le azioni del sistema a fronte di un avvenimento, il suo stato corrente e il suo comportamento generale.</p>
<p>Inizialmente il comportamento prevede il controllo del <strong>consumo di acqua</strong>, ciclicamente e a intervalli regolari viene fatta una misurazione [Fig. <a href="#fig:statediagramWater" data-reference-type="ref" data-reference="fig:statediagramWater">5.2</a> "check water consumption"].</p>
<p>E’ stata stabilita una soglia minima di diminuzione del liquido per non incorrere in falsi positivi, dove le naturali oscillazioni del sensore potrebbero inviare consumi inesistenti. Talora questa soglia venisse superata, la <strong>percentuale</strong> di liquido consumata viene <strong>inviata</strong> in cloud, memorizzando l’ultima percentuale inviata [Fig. <a href="#fig:statediagramWater" data-reference-type="ref" data-reference="fig:statediagramWater">5.2</a> "send water consumption"]. Il sistema continua quindi a monitorare di nuovo il livello per ulteriori consumi.</p>
<p>Inevitabilmente il liquido nella ciotola andrà a finire, questo evento innescherà una transizione, dipendente dalla presenza o meno dell’elettrovalvola. Se il sistema non prevede un rifornimento idrico il sistema passerà allo stato di <strong>notifica di acqua esaurita</strong> [Fig. <a href="#fig:statediagramWater" data-reference-type="ref" data-reference="fig:statediagramWater">5.2</a> "finished water notify"]. In questo stato una notifica verrà mandata all’addetto ai rifornimenti. Quando la ciotola verrà ricaricata il sistema passerà in automatico nuovamente allo stato per il controllo dei consumi. Qualora il sistema fosse dotato di elettrovalvola, la transizione innescata la aprirebbe, passando allo stato di <strong>riempimento</strong> [Fig. <a href="#fig:statediagramWater" data-reference-type="ref" data-reference="fig:statediagramWater">5.2</a> "fill water bowl"].</p>
<p>In questo stato il livello viene controllato continuamente, per non incorrere in allagamenti indesiderati. Un meccanismo di sicurezza temporizzato infatti controlla se un determinato periodo di tempo è passato senza che il sistema sia riuscito a riempire la ciotola con la valvola aperta. In caso affermativo il sistema va in blocco, chiudendo la valvola e passando allo stato di <strong>notifica di errore</strong> [Fig. <a href="#fig:statediagramWater" data-reference-type="ref" data-reference="fig:statediagramWater">5.2</a> "water system error notify"]. Se il livello dell’acqua raggiunge il parametro desiderato invece lo stato torna a essere quello iniziale di osservazione.</p>
<figure>
<img src="DrawIo/stateDiagramWater.png" id="fig:statediagramWater" style="width:100.0%" alt="" /><figcaption>Macchina a Stati Acqua<span label="fig:statediagramWater"></span></figcaption>
</figure>
</section>
</section>
<section id="cibo" data-number="5.1.2">
<h3 data-number="5.1.2"><span class="header-section-number">5.1.2</span> Cibo</h3>
<p>Per far fronte all’esigenza di monitorare i consumi di cibo dell’animale è stata introdotto un <strong>sensore di peso</strong> [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a>]. Il sensore deve ritornare un valore proporzionale alla quantità di cibo presente nella ciotola. I consumi dell’animale verranno inviati in cloud.</p>
<p>Riguardo all’esigenza di rifornire il cibo, la bilancia si deve interfacciare con un attuatore che si occuperà della <strong>distribuzione del materiale</strong> [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a> attuatore di sinistra]. Il design meccanico scelto è stato quello di un nastro trasportatore per la semplicità di realizzazione e l’efficacia. Altri design presi in esame comprendevano una botola che si aprisse e chiudesse, ma presentava problemi di forza per trattenere il cibo in caduta, e la vite di Archimede, ma presentava problemi nell’incastrarsi nel meccanismo dell’eventuale cibo in pezzi solidi. Il design con il nastro sfrutta la gravità per far cadere i pezzi su di esso e, all’attivazione, trascinarli con se permettendo ad altri di cadere. La bilancia rileverà l’incremento e fermerà il sistema alla quantità desiderata.</p>
<p>Per evitare che l’animale mangi il cibo durante la distribuzione, falsandone le misure, è stato introdotto un altro <strong>attuatore bidirezionale</strong> [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a>] per estendere o ritrarre uno sportellino che ne previene l’accesso. Per determinare quando lo sportellino arriva al massimo o al minimo della sua estensione sono stati introdotti <strong>due pulsanti</strong> [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a>] che segnalano quando fermare il movimento.</p>
<p>Infine per segnalare quando il cibo di scorta sta anch’esso per finire sono stati introdotti un <strong>laser e un sensore luminoso</strong> [Fig. <a href="#fig:ciboacqua" data-reference-type="ref" data-reference="fig:ciboacqua">5.1</a>] nella riserva di cibo. Se il cibo è presente il fascio laser verrà interrotto e il sensore non rileverà alcuna luce. Quando il cibo durante l’erogazione scende sotto una soglia critica, il fascio raggiunge il dispositivo di sensing e una notifica verrà inviata all’addetto.</p>
<p>Anche qui il sistema deve essere modulare per design: qualora non ci si voglia avvalere del sistema per rifornire la ciotola, i consumi devono comunque essere mandati in cloud con l’aggiunta di una notifica se il cibo nella ciotola sta per terminare.</p>
<section id="macchina-a-stati-1" data-number="5.1.2.1">
<h4 data-number="5.1.2.1"><span class="header-section-number">5.1.2.1</span> Macchina a stati</h4>
<p>Anche in questo caso il comportamento, data la sua complessità, è stato modellato come una <strong>macchina a stati</strong> [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a>]. Il comportamento è simile alla macchina a stati mostrata in precedenza, essendo l’attuatore per il rifornimento del cibo paragonabile all’elettrovalvola e la bilancia paragonabile al sensore di livello dell’acqua.</p>
<p>Inizialmente il comportamento prevede il <strong>controllo dei consumi</strong> in maniera ciclica tramite la bilancia [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a> "check food consumption"]. Anche in questo caso talora la soglia minima venisse superata, la <strong>quantità consumata viene inviata</strong> in cloud [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a> "send food consumption"]. Il sistema continua quindi a monitorare di nuovo il peso per ulteriori consumi.</p>
<p>Se è stato scelto di non usufruire della parte di rifornimento cibo, il sistema quando questo si verrà ad esaurire, passerà allo <strong>stato di notifica</strong> [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a> "food finished notify"]. Similmente al comportamento del sistema per l’acqua , quando la ciotola verrà ricaricata il sistema passerà in automatico nuovamente allo stato per il controllo dei consumi. In caso fosse presente il sistema di ricarica cibo completo, l’attuatore per chiudere l’accesso al cibo si attiverà, passando allo <strong>stato di chiusura</strong> [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a> "blocking food access"]. Una volta completata la chiusura il nastro per l’erogazione del cibo verrà attivato e il sistema passerà allo <strong>stato di erogazione</strong> [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a> "fill food bowl"]. Se non fosse presente lo sportellino per l’accesso al cibo, dallo stato iniziale si passerà direttamente a quest’ultimo attivando il nastro, senza il passaggio intermedio.</p>
<p>In questo stato il livello viene controllato continuamente, per un dosaggio corretto. Assieme al peso del cibo erogato, viene controllata anche la presenza del fascio laser. Qualora venisse rilevato significa che il cibo di scorta sta per finire e una notifica viene inviata all’addetto. Anche in questo caso è presente un meccanismo di sicurezza temporizzato che, dopo un periodo di tempo massimo, blocca l’erogazione e <strong>passa allo stato di notifica errore</strong> di sistema [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a> "food system error notify"]</p>
<p>In caso il cibo invece raggiunga la quantità desiderata, il sistema tornerà allo stato iniziale, garantendo eventualmente l’accesso al cibo tramite lo <strong>stato di apertura</strong> [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a> "allowing food access"]</p>
<figure>
<img src="DrawIo/stateDiagramFood.png" id="fig:statediagramFood" style="width:100.0%" alt="" /><figcaption>Macchina a Stati Cibo<span label="fig:statediagramFood"></span></figcaption>
</figure>
</section>
</section>
</section>
<section id="design-monitoraggio-parametri-vitali" data-number="5.2">
<h2 data-number="5.2"><span class="header-section-number">5.2</span> Design Monitoraggio Parametri Vitali</h2>
<p>Per il monitoraggio dei parametri vitali il design fisico è stato semplificato di molto, richiedendo due sensori e un microcontrollore. Il <strong>design del prototipo fisico</strong>, con i sensori in giallo e la spiegazione del suo funzionamento [Fig. <a href="#fig:collare" data-reference-type="ref" data-reference="fig:collare">5.4</a>] sono riportati di seguito.</p>
<figure>
<img src="Images/collare.png" id="fig:collare" style="width:100.0%" alt="" /><figcaption>Design Prototipo Collare<span label="fig:collare"></span></figcaption>
</figure>
<p>Il primo device di sensing necessario è quello di <strong>temperatura</strong>, che periodicamente deve inviare i valori letti al cloud. Eventualmente, se i valori sono fuori norma, deve segnalarlo inviando una notifica immediatamente. Il secondo sensore è necessariamente quello dei <strong>battiti</strong>. Anch’esso deve inviare a intervalli regolari i battiti per minuto in cloud, affinché vengano registrati. Opzionalmente sarà presente un LED per visualizzare i battiti in real-time. In caso di anomalie tali da portare i valori oltre il minimo o il massimo, una notifica deve essere mandata tempestivamente. La macchina a stati si compone semplicemente di due stati divisi che ciclano su loro stessi, inviando periodicamente i valori letti ed eventualmente le notifiche per le anomalie.</p>
</section>
<section id="design-videosorveglianza" data-number="5.3">
<h2 data-number="5.3"><span class="header-section-number">5.3</span> Design Videosorveglianza</h2>
<p>Per la videosorveglianza il design ha richiesto necessariamente, come descritto in precedenza, una board più potente che sostenesse l’elaborazione delle immagini. Di seguito il <strong>design del prototipo fisico</strong>, con i sensori in giallo e la spiegazione del suo funzionamento [Fig. <a href="#fig:canile" data-reference-type="ref" data-reference="fig:canile">5.5</a>].</p>
<figure>
<img src="Images/Canile.png" id="fig:canile" style="width:60.0%" alt="" /><figcaption>Design Prototipo Monitoraggio Canile (sensori in giallo)<span label="fig:canile"></span></figcaption>
</figure>
<p>Per quanto riguarda i sensori, ovviamente è necessaria una <strong>videocamera</strong>, che catturi l’ambiente circostante e mandi il flusso video alla board per un analisi. Oltre alla videocamera, opzionalmente, sono stati modellati un <strong>sensore di temperatura e umidità</strong>, per salvare in cloud i parametri ambientali del canile, e un <strong>device di sensing sonoro</strong>, per rilevare suoni forti continuativi. La board deve anche fornire opzionalmente lo streaming video della telecamera, facendo da server, per l’addetto alla sorveglianza. Il flusso dei dati è chiaramente unidirezionale, dai sensori e dalla webcam verso l’esterno, come da architettura generale [Fig. <a href="#fig:DesignArchitettura" data-reference-type="ref" data-reference="fig:DesignArchitettura">4.1</a>].</p>
</section>
<section id="design-del-database" data-number="5.4">
<h2 data-number="5.4"><span class="header-section-number">5.4</span> Design del Database</h2>
<p>Per immagazzinare i dati necessari all’applicazione si è deciso di utilizzare <strong>Dynamo DB</strong>. Il database principale doveva immagazzinare:</p>
<ul class="incremental">
<li><p>I <strong>profili</strong> dei <strong>cani</strong> presenti all’interno del canile;</p></li>
<li><p>Gli <strong>orari</strong> e le <strong>quantità</strong> di cibo da somministrare a seconda del cane;</p></li>
<li><p>I <strong>valori</strong> rilevati dai dispositivi di <strong>sensing</strong>, che comprendono:</p>
<ul class="incremental">
<li><p>Temperatura corporea;</p></li>
<li><p>Frequenza cardiaca;</p></li>
<li><p>Consumo di acqua;</p></li>
<li><p>Consumo di cibo;</p></li>
<li><p>Temperatura ambientale del canile;</p></li>
<li><p>Umidità rilevata all’interno del canile;</p></li>
</ul></li>
<li><p>I profili degli <strong>utenti</strong>.</p></li>
</ul>
<p>La progettazione del database è stata portata a termine seguendo diversi passaggi:</p>
<ol class="incremental">
<li><p>Definizione di uno schema <strong>ER</strong> da utilizzare come base di partenza;</p></li>
<li><p>Individuazione degli <strong>accessi</strong> mediante la definizione delle <strong>query</strong> principali;</p></li>
<li><p>Definizione dei <strong>pattern</strong> di Primary Key e Sort Key;</p></li>
<li><p>Introduzione di indici e campi aggiuntivi;</p></li>
</ol>
<section id="definizione-di-un-er" data-number="5.4.1">
<h3 data-number="5.4.1"><span class="header-section-number">5.4.1</span> Definizione di un ER</h3>
<p>Nonostante non si tratti di un database relazionale, abbozzare uno schema Entity Relationship può essere utile per avere una buona visione di partenza di come devono essere gestiti i dati.</p>
<section id="informazioni-sui-cani" data-number="5.4.1.1">
<h4 data-number="5.4.1.1"><span class="header-section-number">5.4.1.1</span> Informazioni sui cani</h4>
<p>Il primo schema ad essere stato elaborato è stato quello che racchiude tutto ciò che ha a che fare con i dati di un cane, ovvero il profilo del cane, i dettagli della sua relativa distribuzione del cibo e le rilevazioni di cibo, acqua, temperatura e battiti che lo riguardano.</p>
<figure>
<img src="DrawIo/EntityRelationship.png" id="fig:dogER" style="width:60.0%" alt="" /><figcaption>ER dati del cane<span label="fig:dogER"></span></figcaption>
</figure>
<ul class="incremental">
<li><p><strong>Cane</strong>: il profilo del cane è modellato mediante la tabella <code>Dog</code> che, oltre alle consuete informazioni presenta anche le soglie, impostate dal veterinario, al di fuori delle quali si rileva un’anomalia.</p></li>
<li><p><strong>Programma dei pasti</strong>: l’entità <code>Food_Schedule</code> immagazzina gli orari e le quantità dei pasti. Il criterio secondo cui, nel caso standard, vengono decisi questi dati è la taglia, tuttavia si è deciso di collegare l’entità direttamente al cane poiché ciò permette di effettuare una programmazione più a grana fine. In questo modo, infatti, si può consentire ad un veterinario di effettuare modifiche sul regime alimentare di un unico cane, senza influenzare gli altri cani della stessa taglia.</p></li>
<li><p><strong>Rilevazioni</strong>: nello schema in figura è già stata collassata la gerarchia delle rilevazioni sopra elencate, concentrandole nell’entità <code>Dog_log</code> che ne distingue la natura mediante il campo <code>type</code>.</p></li>
</ul>
</section>
<section id="informazioni-sugli-utenti" data-number="5.4.1.2">
<h4 data-number="5.4.1.2"><span class="header-section-number">5.4.1.2</span> Informazioni sugli utenti</h4>
<p>In fase di progettazione si voleva che il database gestisse anche gli utenti che agiscono sul sito, in maniera tale che ne fossero definiti i ruoli in base ai quali avrebbero avuto diversi permessi e una diversa visualizzazione dei dati sul sito web. Questo ER si distacca da quello relativo ai cani e si presenta in questo modo:</p>
<figure>
<img src="DrawIo/UserER.png" id="fig:userER" style="width:60.0%" alt="" /><figcaption>ER utenti<span label="fig:userER"></span></figcaption>
</figure>
</section>
<section id="rilevazioni-ambientali" data-number="5.4.1.3">
<h4 data-number="5.4.1.3"><span class="header-section-number">5.4.1.3</span> Rilevazioni ambientali</h4>
<p>Anche per quanto riguarda le rilevazioni ambientali ci si trova di fronte a un’area separata dalle precedenti, perché non ha alcun tipo di correlazione né con i cani, né con gli utenti. Esse sono modellate con una tabella di nome <code>Env_Logs</code> che ne immagazzina il <code>timestamp</code>, il <code>type</code>, che serve a distinguere le rilevazioni di temperatura e quelle di umidità e il <code>value</code> che, nel caso della temperatura è espresso in gradi mentre nel caso dell’umidità è espresso in percentuale.</p>
</section>
</section>
<section id="individuazione-degli-accessi" data-number="5.4.2">
<h3 data-number="5.4.2"><span class="header-section-number">5.4.2</span> Individuazione degli accessi</h3>
<p>Una volta ottenuta una bozza dello schema Entity Relationship si è passati a definire gli accessi in base alle query che sarà necessario chiamare per interrogare il database. Definire gli accessi si rivela essere di vitale importanza quando si lavora con un database come DynamoDB perché permette di impostare le tabelle in modo da rendere più facile l’accesso ai dati più richiesti. Per permettere ciò si è portati anche a introdurre delle ridondanze e a sacrificare l’integrità referenziale prediligendo i benefici sulle performance. Di seguito le interrogazioni suddivise per frequenza</p>
<ul class="incremental">
<li><p><strong>Frequenza molto elevata</strong> (ogni pochi minuti)</p>
<ul class="incremental">
<li><p>inserimento di una rilevazione riguardante consumi, parametri vitali del cane, valori ambientali</p></li>
</ul></li>
<li><p><strong>Frequenza elevata</strong> (poche volte all’ora)</p>
<ul class="incremental">
<li><p>visualizzazione dei cani presenti</p></li>
<li><p>visualizzazione dei consumi di un cane</p></li>
<li><p>visualizzazione dell’ultima rilevazione di temperatura e battiti di un cane</p></li>
</ul></li>
<li><p><strong>Frequenza media</strong> (una o poche volte al giorno)</p>
<ul class="incremental">
<li><p>visualizzazione storico delle rilevazioni di un cane</p></li>
<li><p>visualizzazione dei consumi di un cane</p></li>
<li><p>inserimento di un nuovo cane</p></li>
<li><p>interrogazione sull’orario e la quantità dei pasti</p></li>
<li><p>a fine giornata, comparazione dei consumi totali di acqua e cibo odierni, per ciascun cane, con i rispettivi range giornalieri contenuti nel profilo dell’animale.</p></li>
</ul></li>
<li><p><strong>Frequenza bassa</strong> (meno di una volta a settimana)</p>
<ul class="incremental">
<li><p>impostazione delle soglie dei consumi di un cane oltre le quali vi è un’anomalia</p></li>
<li><p>impostazione delle soglie dei parametri vitali di un cane oltre le quali vi è un’anomalia</p></li>
<li><p>aggiornamento del programma dei pasti</p></li>
<li><p>aggiornamento dello stato di un cane</p></li>
</ul></li>
</ul>
</section>
<section id="definizione-dei-pattern-di-primary-key-e-sort-key" data-number="5.4.3">
<h3 data-number="5.4.3"><span class="header-section-number">5.4.3</span> Definizione dei pattern di Primary Key e Sort Key</h3>
<p>Dopo aver individuato le interrogazioni che verranno fatte sul database e le loro frequenze si è passati alla progettazione vera e propria dell’<strong>unica tabella</strong> del database. A differenza di un database relazionale, infatti, DynamoDB non permette di ricorrere alle <strong>join</strong>, se non con dei workaround la quale adozione è un chiaro sintomo del fatto che non si è scelta correttamente la tipologia di database da adottare. La tabella che è stata creata è strutturata con i seguenti campi:</p>
<ul class="incremental">
<li><p><strong>PK</strong>: o Primary Key, è la chiave primaria e consiste in una stringa che determinerà la natura del record a cui appartiene.</p></li>
<li><p><strong>SK</strong>: o Sort Key, è la chiave di ordinamento e consiste anch’essa in una stringa che segue uno specifico pattern e che assieme alla PK determinerà univocamente il record.</p></li>
<li><p><strong>Altri campi</strong>: che sono dati dall’unione dei campi di tutte le entità che si è deciso di coinvolgere, con l’aggiunta di alcuni campi introdotti per fornire un’indicizzazione o per inserire delle ridondanze che facilitino l’accesso.</p>
<p>I pattern che sono stati definiti per PK e SK sono i seguenti:</p>
<figure>
<img src="DrawIo/KeysPattern.png" id="fig:KeyPattern" style="width:60.0%" alt="" /><figcaption>Pattern PK e SK suddivisi per entità di riferimento<span label="fig:KeyPattern"></span></figcaption>
</figure></li>
</ul>
<p>Dalla tabella, oltre ai pattern per i valori delle chiavi è possibile anche intuire il modo in cui si è deciso di effettuare la trasposizione dallo schema relazionale. Si può notare infatti che:</p>
<ul class="incremental">
<li><p><strong><code>Food_Schedule</code></strong>: si è deciso di mantenere la programmazione dei pasti separata dai dati del cane poiché mantenerla come struttura dati all’interno del profilo avrebbe reso meno immediata la modifica e il recupero degli orari e delle quantità che il sistema automatizzato deve erogare.</p></li>
<li><p><strong><code>Dog_Log</code></strong>: la stessa decisione è stata presa per quanto riguarda i dati delle rilevazioni, poiché la query che permette l’inserimento di questi dati è quella che verrà chiamata con la massima frequenza ed era quindi importante facilitarne la fruizione.</p></li>
<li><p><code>User</code>: una sorte diversa è spettata ai ruoli ricoperti dagli utenti. Si è deciso di modellare i ruoli come una set di stringhe all’interno del profilo dell’utente, poiché si tratterebbe di un campo che viene modificato raramente.</p></li>
</ul>
</section>
<section id="introduzione-di-indici-e-campi-aggiuntivi" data-number="5.4.4">
<h3 data-number="5.4.4"><span class="header-section-number">5.4.4</span> Introduzione di indici e campi aggiuntivi</h3>
<p>L’ultima fase è stata quella di individuare quali altre modifiche potevano essere apportate al risultato finale della tabella per favorire le interrogazioni. Si è deciso pertanto di:</p>
<ul class="incremental">
<li><p>aggiungere i <strong>campi</strong> <code>last_temp</code> e <code>last_hb</code> nel profilo del cane per permettere una più prestante interrogazione nel momento in cui, nella homepage del sito si vogliono visualizzare le ultime rilevazioni dei parametri vitali del cane. In assenza di questi due campi sarebbe stato necessario interrogare il database con un range di timestamp sensato per ottenere una fetta dello storico delle rilevazioni, ordinarle e restituire la più recente. Questo per la temperatura che per la frequenza cardiaca.</p></li>
<li><p>aggiungere un nuovo <strong>indice</strong> sul campo <strong><code>size</code></strong> per permettere di effettuare alcune query basandosi sulla taglia del cane.</p></li>
</ul>
</section>
</section>
<section id="design-webapp" data-number="5.5">
<h2 data-number="5.5"><span class="header-section-number">5.5</span> Design WebApp</h2>
<p>La WebApp è stata suddivisa in due <strong>Macro</strong> aree:</p>
<ul class="incremental">
<li><p><strong>Login</strong>: la schermata si occupa di fornire un accesso base all’utente, l’unica funzione esposta è la possibilità di effettuare il <strong>login</strong>, attualmente rappresenta un placeholder, dato che non contine alcuna logica né funzione utile, questo per concentrarsi maggiormente su aspetti più inerenti.</p></li>
<li><p><strong>Home</strong>: fornisce tutte le funzioni principali dell’applicativo, la schermata è divisa in schede, ogni scheda è a sua volta divisa in più componenti, uno per la visualizzazione dei cani presenti e uno per le azioni specifiche da attuare su di esso, o in generale. L’unica scheda che contiene un solo</p>
<p>dove ogni scheda consente determinate operazioni:</p>
<ul class="incremental">
<li><p><strong>Gestore</strong>: Consente di effettuare le principali azioni del sito, inoltre può anche effettuare le azioni seguenti.</p></li>
<li><p><strong>Addetto alla salute</strong>: Può visualizzare i parametri vitali e lo stato di salute degli animali.</p></li>
<li><p><strong>Addetto ai rifornimenti</strong>: Può visualizzare i dati di un cane, i suoi consumi e impostare l’orario e la quantità di cibo.</p></li>
<li><p><strong>Addetto alla sorveglianza</strong>: Puù visualizzare lo streaming video.</p></li>
<li><p><strong>Altro addetto</strong>: placeholder per funzioni future</p></li>
</ul></li>
</ul>
</section>
<section id="design-serverless-application" data-number="5.6">
<h2 data-number="5.6"><span class="header-section-number">5.6</span> Design Serverless Application</h2>
<p>L’esposizione delle funzioni del back-end, segue a braccetto la definizione delle query necessarie per interrogare e inserire nuovi dati all’interno di DynamoDB.</p>
<p>Le funzioni sono state divise per innesco, dove abbiamo:</p>
<ul class="incremental">
<li><p>Lambda ad innesco <strong>API REST</strong>: rappresentano la maggioranza delle funzioni, sono ulteriormente divise in base allo scopo di interrogazione(GET) o inserimento(POST)</p></li>
<li><p>Lambda ad innesco <strong>Crono</strong>: i consumi dei cani sono controllati a fine giornata per verificare che le soglie dei consumi siano nei parametri. l’innesco avviene tramite eventi <strong>CloudWatch</strong></p></li>
<li><p>Lambda ad innesco <strong>MQTT</strong>: rappresentano i diretti inserimenti delle rilevazioni all’interno del database, sono in ascolto su un sul topic <strong>ESP/#</strong>, questo consente di ascoltare tutti i messaggi provenienti da i sotto topic.</p></li>
</ul>
</section>
</section>
<section id="implementazione" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Implementazione</h1>
<section id="software-microcontrollori" data-number="6.1">
<h2 data-number="6.1"><span class="header-section-number">6.1</span> Software Microcontrollori</h2>
<section id="classe-principale" data-number="6.1.0.0.1">
<h5 data-number="6.1.0.0.1"><span class="header-section-number">6.1.0.0.1</span> Classe principale</h5>
<p>Come spiegato nel capitolo Scelte tecnologiche cruciali, i microcontrollori sono stati programmati in <strong>MicroPython</strong>. Nella classe principale, condivisa e riutilizzabile tra tutti i microcontrollori, dopo la connessione a internet e al broker MQTT è stato creato uno <strong>scheduler</strong>. Questo si occupa di eseguire i <strong>task a lui assegnati</strong>, siano relativi al cibo, all’acqua, o ai parametri vitali. In questo modo è facilmente programmabile il comportamento di un microcontrollore con task modulari.</p>
<pre><code>        # array of tasks
        print(&quot;Creating array of tasks&quot;)
        tasks = [smart_collar_temperature_task.get_behaviour(), smart_collar_heartbeat_task.get_behaviour()]  # array of coroutines
        
        # create the scheduler and start tasks
        print(&quot;--- Starting Scheduler ---&quot;)
        scheduler = Scheduler()
        scheduler.start(tasks)</code></pre>
</section>
<section id="classi-per-sensori-e-attuatori" data-number="6.1.0.0.2">
<h5 data-number="6.1.0.0.2"><span class="header-section-number">6.1.0.0.2</span> Classi per sensori e attuatori</h5>
<p>Avendo adottato MicroPython è stato possibile usufruire del linguaggio ad oggetti per modellare attuatori e sensori come classi, con proprietà chiamabili all’occorrenza. Ogni classe è stata testata individualmente grazie ai test scritti appositamente per prevenire comportamenti indesiderati. Si può trovare il diagramma delle classi di ogni device con cui si interfaccia il microcontrollore in [Fig. <a href="#fig:classdiagram" data-reference-type="ref" data-reference="fig:classdiagram">6.1</a>].</p>
<figure>
<img src="DrawIo/ClassDiagram.png" id="fig:classdiagram" style="width:80.0%" alt="" /><figcaption>Diagramma delle classi<span label="fig:classdiagram"></span></figcaption>
</figure>
<p>In particolare, ogni device di sensing, è stato modellato ereditando dalla classe Sensor, che mette a disposizione una serie di metodi per poter calcolare la media pesata, la percentuale misurata nel range minimo e massimo e l’ultima misurazione. La media è pesata è calcolata esponenzialmente in base alle ultime misure, le quali hanno peso maggiore:</p>
<pre><code>    def measure(self):
        &quot;&quot;&quot;measures 3 times, measure is the mean of them, updates global average, returns measure.&quot;&quot;&quot;
        sum_raw_measures = 0
        for _ in range(3):
            sum_raw_measures += self.raw_measure()
        self.last_measure = sum_raw_measures / 3
        # average calculated from last average, weighted and actual measure, weighted
        self.average = self.last_measure * self.average_converging_speed +                           self.average * ( 1 - self.average_converging_speed)
        return self.last_measure</code></pre>
</section>
<section id="gestione-cibo-e-acqua" data-number="6.1.1">
<h3 data-number="6.1.1"><span class="header-section-number">6.1.1</span> Gestione Cibo e Acqua</h3>
<section id="cibo-1" data-number="6.1.1.1">
<h4 data-number="6.1.1.1"><span class="header-section-number">6.1.1.1</span> Cibo</h4>
<p>L’implementazione del task relativo alla gestione del cibo da passare allo scheduler è stato implementato in una classe dedicata. Il comportamento che il task espone rispecchia la macchina a stati discussa nel design [Fig. <a href="#fig:statediagramFood" data-reference-type="ref" data-reference="fig:statediagramFood">5.3</a>]. Grazie alla possibilità di Python di avere funzioni higher-order, il loop principale esegue ciclicamente lo stato corrente:</p>
<pre><code>        async def get_behaviour(self):
        &quot;&quot;&quot;async method called returns a coroutine&quot;&quot;&quot;
            while True:
                # executes the current state
                await self.state()</code></pre>
<p>Quando il task è creato, nel costruttore è possibile scegliere lo stato iniziale assegnando la funzione relativa allo stato corrente.</p>
<pre><code>        # state variable holds the current state, this is the initial state
        self.state = self.check_food_consumption</code></pre>
<p>All’interno di ogni stato vengono effettuate le operazioni necessarie e, qualora le condizioni si verifichino, le transizioni a un nuovo stato.</p>
<pre><code>        # check consumption
        self.reduction_percentage = self.previous_sent_perc - self.scale.get_percentage()
        print(&quot;\t\tReduction Percentage: {:.2f}&quot;.format(self.reduction_percentage))
        if self.reduction_percentage &gt;= PERCENTAGE_CONSUMPTION_THRESHOLD:
            self.state = self.send_food_consumption
            return</code></pre>
<p>Particolarmente impegnativa è stata la modellazione della bilancia. Questa va tarata inizialmente affinché il peso della ciotola vuota non vada ad influire sul peso del cibo. Inoltre parecchie prove sono state effettuate per trovare il coefficiente di conversione tra i valori del sensore e il peso in grammi. Infine la gestione del motore bidirezionale per aprire e chiudere lo sportellino di accesso al cibo ha anch’esso richiesto parecchia cura, dovendo implementare una classe che si preoccupasse di invertire la polarità al motore attraverso un ponte-H e la logica di interruzione del movimento al momento giusto.</p>
</section>
<section id="acqua-1" data-number="6.1.1.2">
<h4 data-number="6.1.1.2"><span class="header-section-number">6.1.1.2</span> Acqua</h4>
<p>Il task relativo alla gestione della ciotola dell’acqua è stato implementato, similmente a quello del cibo, in una classe apposita, per poter essere passato allo scheduler. Essendo i task più di uno, a questo punto è sorto naturale implementare una classe task da cui tutti quelli descritti nel seguente capitolo erediteranno. La logica a stati del design è stata implementata rispecchiandolo a pieno. Ciò perché la precedente modellazione dei sensori ha agevolato di parecchio la scrittura del codice, rendendolo pulito e facilmente comprensibile.</p>
<pre><code>        # measure
        self.waterSensor.measure()
        print(&quot;\t\t\tWater Measure:  {:.2f}&quot;.format(self.waterSensor.get_percentage()))
        # check empty
        if self.waterSensor.get_percentage() &lt; self.min_water_lvl_perc:
            print(&quot;\t\t\tWater LOW: {:.2f} &lt; {:.2f}&quot;.format(self.waterSensor.get_percentage(), self.min_water_lvl_perc))
            if self.valve_present:
                print(&quot;\t\t\tOpening Valve&quot;)
                self.valve.open()
                self.state = self.fill_water_bowl
                return</code></pre>
<p>In questo caso il sensore dell’acqua è stato ampliato con delle funzioni per il ritorno della percentuale. Non è possibile infatti dedurre il quantitativo bevuto da un’animale semplicemente dal sensore, poiché il range di questo è proporzionale all’altezza del liquido nel contenitore, ma non è dato sapere la sua capienza. Per questo motivo il parametro capienza massima può essere passato al dispositivo di sensing. Grazie a questo dato verrà calcolata la quantità di acqua bevuta al diminuire della percentuale rilevata dal sensore.</p>
<section id="comunicazioni" data-number="6.1.1.2.1">
<h5 data-number="6.1.1.2.1"><span class="header-section-number">6.1.1.2.1</span> Comunicazioni</h5>
<p>Entrambi i task di cibo e acqua adottano il protocollo MQTT per comunicare con il cloud. Lo scambio è bidirezionale ed è gestito dalla classe "MQTTManager". Questa si occupa dell’invio dei messaggi e, qualora il task "MQTTMessageChecker" sia in esecuzione, di ricevere i messaggi dal server. Questi messaggi innescheranno la gestione delle callback passando allo scheduler un task "MQTTMessageHandler". I messaggi sono scambiati in formato JSON. Ogni unità di controllo gabbia inizialmente si identifica mandando un messaggio al broker. In seguito vengono iniziate le rilevazioni per i consumi e, in caso di necessità, un messaggio affinché il server invii la notifica all’addetto.</p>
<figure>
<img src="DrawIo/sequenceWaterAutomation.png" id="fig:sequencewater" style="width:80.0%" alt="" /><figcaption>Sequenza scambio dei messaggi del sistema acqua<span label="fig:sequencewater"></span></figcaption>
</figure>
</section>
</section>
</section>
<section id="monitoraggio-parametri-vitali" data-number="6.1.2">
<h3 data-number="6.1.2"><span class="header-section-number">6.1.2</span> Monitoraggio Parametri Vitali</h3>
<section id="temperatura" data-number="6.1.2.1">
<h4 data-number="6.1.2.1"><span class="header-section-number">6.1.2.1</span> Temperatura</h4>
<p>Il task relativo al monitoraggio della temperatura nel collare è stato sviluppato affinché possa essere usato con due sensori diversi: il ds18x20 e il dht11. Creando il task si può scegliere il modello posseduto e, quando lo scheduler inizierà a eseguire ciclicamente le misurazioni, i dati e le notifiche verranno inviati in cloud.</p>
<pre><code>        # measure temp
        if self.using_ds18x20:
            temp = self.check_ds18x20()
        else:
            temp = self.check_dht()
        # send data
        self.mqtt_manager.send_msg(self.topic, &quot;Temperature: {}&quot;.format(temp))</code></pre>
</section>
<section id="battito-cardiaco" data-number="6.1.2.2">
<h4 data-number="6.1.2.2"><span class="header-section-number">6.1.2.2</span> Battito Cardiaco</h4>
<p>Il task relativo al battito cardiaco svolge, come il precedente, delle misurazioni cicliche e invia i dati rilevati. Un parte particolarmente complessa è stata quella della gestione del sensore per il battito. Il sensore, qualora interpellato, fornisce un singolo valore direttamente proporzionale alla dilatazione dei vasi sanguigni. Ne deriva la necessità di attuare misurazioni frequenti per non incorrere nella perdita della breve variazione di un battito. Abbiamo stabilito la frequenza di campionamento in base a quanto segue: Considerando che in condizioni di riposo, i battiti per minuto di un cane - da intendersi come pulsazioni - sono generalmente compresi tra 60 e 140 bpm, in base alla taglia, età e razza, e il valore può raggiungere valori anche più alti qualora in movimento, abbiamo preso come valore limite da rilevare 150 bpm. Ciò, significa che il tempo di ogni ciclo cardiaco <span class="math inline">\(T_{cc}\)</span> è: <span class="math display">\[T_{cc} = \frac{1}{bps} = \frac{1}{\frac{bpm}{60}}= \frac{60}{bpm} \Rightarrow \frac{60}{150 bpm} = 0.4s\]</span> Considerato che il ciclo cardiaco si compone in sistole (contrazione) e diastole (rilassamento), la fase sistolica è quella più facilmente rilevabile poiché la contrazione ventricolare causata è più violenta e breve. Questa fase durante le rilevazioni effettuate dura circa un mezzo del ciclo cardiaco e produce un picco nei valori particolarmente indicativo per rilevare il battito in mezzo al naturale rumore del sensore. Per non perdere il picco massimo il numero di campionamenti <span class="math inline">\(N_{c}\)</span> durante questa fase è stato fissato a 20. La frequenza di campionamento minima risultante <span class="math inline">\(f_{min}\)</span> è stata calcolata come: <span class="math display">\[f_{min} = \frac{ \frac{1}{2} *  T_{cc} }{N_{c}} \Rightarrow  \frac{ \frac{1}{2} *  0.4s }{20} = 0.01s = 10 ms\]</span></p>
<p>Salvando i valori risultanti e graficandoli con la libreria python "Mathplotlib" si ottiene una linea come quella di colore rosso in [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.3</a>]. Si può notare che il campionamento è sufficiente e permette di distinguere intuitivamente i battiti. Per rilevare le pulsazioni a livello digitale però è necessario formalizzare un altro modello matematico che non faccia incorrere il sistema in falsi positivi o falsi negativi. Un primo approccio si è basato su stabilire una singola soglia, oltre la quale il battito è rilevato e registrato. Questa soluzione si è rivelata inadatta in quanto il disturbo del sensore la farebbe attraversare più volte (si veda in [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.3</a>] poco prima del campionamento numero 2400 il valore attraversa la linea azzurra parecchie volte). Inadatti si sono rivelati anche i tentativi di normalizzare la linea dei valori, in quanto parecchio discontinui e di frequenza elevata, si perde la differenziazione dei picchi. Si è optato per stabilire una doppia soglia, la prima, più alta, oltre la quale il battito è rilevato, la seconda, più bassa, che determina la fine del battito. La prima volta che il valore attraversa la prima [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.3</a>, linea azzurra] una variabile registra il battito e nessun altra registrazione viene effettuata sino a che i valori non scendono sotto la soglia di fine battito [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.3</a>, linea gialla]. Queste soglie non possono essere fisse, variando la pressione di animale in animale e pure di giorno in giorno per lo stesso essere vivente. Per questo motivo i valori sono stati fissati per la prima a 4/5 e per la seconda a 1/2 tra minimo [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.3</a>, linea verde] e massimo [Fig. <a href="#fig:Heartbeat" data-reference-type="ref" data-reference="fig:Heartbeat">6.3</a>, linea blu] dei precedenti valori. La grandezza della finestra dei valori da cui prendere minimo e massimo è stata fissata a 250 valori. Questo perché, come si può notare dal grafico, comprende almeno due battiti. Un range troppo piccolo creerebbe dei minimi e massimi locali, rilevando picchi non propri e dando parecchi falsi positivi. Una finestra troppo ampia porterebbe a una staticità delle soglie rispetto alla variazione di pressione che creerebbe falsi negativi.</p>
<figure>
<img src="Images/heartbeatGraph.png" id="fig:Heartbeat" style="width:100.0%" alt="" /><figcaption>Grafico Battiti<span label="fig:Heartbeat"></span></figcaption>
</figure>
<pre><code>       val = self.pulse_sensor.raw_measure()
        self.history.append(val)  # add to history of values
        # crop to MAX_HISTORY length, getting the tail (last ones)
        self.history = self.history[-MAX_HISTORY:]
        # get min max in the history
        minima, maxima = min(self.history), max(self.history)
        # get thresholds
        threshold_on = (minima + maxima * 4) // 5  # 4/5
        threshold_off = (minima + maxima) // 2  # 1/2
        # if val goes above beat threshold and no beat has previously been detected.
        if val &gt; threshold_on and self.still_beat == False:
            # beat detected
            self.led.on()
            self.still_beat = True  # prevents multiple appends for all the measures during a beat
            # once every beat
            self.beats.append(time.time())</code></pre>
<p>Una volta rilevati i singoli battiti con il modello matematico, il calcolo del battiti al minuto è stato realizzato salvando la cronologia degli istanti di tempo per gli ultimi N battiti <span class="math inline">\(N_{beats}\)</span>. Sperimentalmente si è optato per 30 registrazioni per mantenere il valore dei bpm reattivo ma non dipendente solo da poche unità. Prelevando dalla cronologia il tempo passato <span class="math inline">\(T_{diff}\)</span> per questi battiti, si può facilmente derivare il rateo di <span class="math inline">\(bpm\)</span> attuale tramite la formula: <span class="math display">\[bpm = \frac{ N_{beats}*60 s/min }{T_{diff}} = \frac{ N_{beats}*60 s/min }{T_{last}-T_{first}}\]</span> Il battito cardiaco risultante viene poi inviato periodicamente al Database e, qualora ci fossero anomalie, una notifica viene invece generata e inviata immediatamente.</p>
<pre><code>        # calculate bpm
        beats_time = self.beats[-1] - self.beats[0]  # time difference between end and start of the queue
        if beats_time:
            bpm = (len(self.beats) / beats_time) * 60
            print(&quot;HeartBeat: {}&quot;.format(bpm))
            # if outside range
            if bpm &lt; self.min_heartbeat or bpm &gt; self.max_heartbeat:
                # send notification now
                self.mqtt_manager.send_msg(MQTT_NOTIFY_TOPIC, ujson.dumps({&quot;Notify&quot;:&quot;Heartbeat is abnormal: {}&quot;.format(bpm)}))</code></pre>
<section id="comunicazioni-1" data-number="6.1.2.2.1">
<h5 data-number="6.1.2.2.1"><span class="header-section-number">6.1.2.2.1</span> Comunicazioni</h5>
<p>I task di temperatura e battiti adottano anch’essi il protocollo MQTT per comunicare con il cloud. Lo scambio è bidirezionale per via della necessità di settare i range di temperatura e battiti per le notifiche di anomalia. Ogni unità collare inizialmente si identifica mandando un messaggio al broker. Successivamente partono le rilevazioni per i battiti e la temperatura. I parametri vitali vengono periodicamente inviati al server assieme ai messaggi per le notifiche di anomalie.</p>
<figure>
<img src="DrawIo/sequenceSmartCollar.png" id="fig:sequencesmartcollar" style="width:80.0%" alt="" /><figcaption>Sequenza scambio dei messaggi del sistema collare<span label="fig:sequencesmartcollar"></span></figcaption>
</figure>
</section>
</section>
</section>
</section>
<section id="software-videosorveglianza" data-number="6.2">
<h2 data-number="6.2"><span class="header-section-number">6.2</span> Software Videosorveglianza</h2>
<p>Il Raspberry è stato scelto come board per la computazione delle immagini di video-sorveglianza. Il principale concorrente a questa scelta, l’ESP32-CAM è stato testato per lo streaming video ma non è provvisto delle risorse computazionali necessarie per il rilevamento di anomalie. Ciononostante, avendo un costo inferiore rispetto al Raspberry è stato comunque considerato come alternativa low-cost. Il linguaggio scelto per la programmazione è stato <strong>Python</strong> per continuità con i microcontrollori e per la flessibilità di utilizzo. Sono state programmate multiple classi per di complessità crescente per agevolare l’utilizzo del software in caso di errori. La prima classe "camera tester" ha infatti semplicemente il ruolo di testare lo stream con ffmpeg e OpenCV. Un’altra classe "mqtt tester" si occupa di un semplice test di invio e ricezione attraverso il pacchetto mqtt di "awsiotsdk". Infine l’ultima classe di test "stream base" si occupa di testare lo stream attraverso l’utilizzo del pacchetto "flask" per creare un webserver su cui verrà pubblicato il video feed.</p>
<section id="comunicazione" data-number="6.2.0.0.1">
<h5 data-number="6.2.0.0.1"><span class="header-section-number">6.2.0.0.1</span> Comunicazione</h5>
<p>La parte di comunicazione è stata gestita creando una classe MQTT apposita che permette di connettersi, disconnettersi, mandare dei messaggi e impostare le callback. Questa classe viene usata da tutte le classi successive per le comunicazioni. Infine, per passare lo stream video da un dispositivo ad un altro nella stessa rete, sono state incluse due classe "sender udp" e "receiver udp" atte allo scopo.</p>
</section>
<section id="motion-detection" data-number="6.2.1">
<h3 data-number="6.2.1"><span class="header-section-number">6.2.1</span> Motion Detection</h3>
<p>Una delle due implementazioni proposte per il rilevamento di anomalie utilizza la motion detection. Questa tecnica si basa sul rilevare i cambiamenti dell’immagine corrente dato uno sfondo di riferimento. Il motion detector base è stato costruito come segue: Viene preso il frame corrente e viene sfumato con un filtro gaussiano per rimuovere minime differenze. Il risultato viene sottratto al frame di riferimento per il background. Nel nostro caso il frame di riferimento per il background viene aggiornato periodicamente. L’immagine che contiene le differenze viene passata attraverso una soglia per rilevare le zone con cambiamenti sostanziali e non minimi. Viene applicata la dilatazione per unire le zone discontinue in modo tale da unire aree vicine di cambiamento. Viene calcolata l’area delle zone di differenza e vengono scelte solo le zone con un’area maggiore di una soglia. Le zone scelte sono zone effettive di cambiamento dell’immagine.</p>
<pre><code>    # blur
    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)
    # compute the absolute difference between the current frame and reference frame
    frameDelta = cv2.absdiff(referenceFrame, gray_frame)
    thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]
    # dilate the thresholded image to fill in holes, then find contours
    # on thresholded image
    thresh = cv2.dilate(thresh, None, iterations=2)
    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_SIMPLE)</code></pre>
<p>Il motion detector base è stato ampliato in altre due classi per comprendere l’invio di messaggi MQTT al rilevamento di un movimento ("motion detection mqtt") e lo streaming video assieme all’invio di messaggi ("motion detection mqtt stream").</p>
</section>
<section id="object-detection" data-number="6.2.2">
<h3 data-number="6.2.2"><span class="header-section-number">6.2.2</span> Object Detection</h3>
<p>La seconda implementazione proposta per la rilevazione di anomalie o intrusioni nel sistema di videosorveglianza fa uso di reti neurali per l’object detecion. La classe "object detection base" fa uso della rete neurale Yolo (una più approfondita discussione sulla scelta delle reti è presente nel capitolo Testing) per predire la presenza di oggetti anomali nella scena. Il codice permette di venir usato per il forward alla rete di una singola immagine, di un video, o di uno streaming da webcam. Nel mentre vengono calcolati i tempi di computazione per derivare gli FPS a cui il sistema sta andando. Assieme a questa classe è stata implementata la variante "object detection mqtt" con l’invio su MQTT del messaggio di anomalia e dell’oggetto rilevato per la notifica.</p>
<pre><code>            # capture frame
            ret, image = cap.read()

            #predition
            boxes, confidences, classIDs, idxs = make_prediction(net, layer_names, labels, image, args.confidence, args.threshold)
            #draw boxes
            image = draw_bounding_boxes(image, boxes, confidences, classIDs, idxs, colors)</code></pre>
</section>
</section>
<section id="web-app" data-number="6.3">
<h2 data-number="6.3"><span class="header-section-number">6.3</span> Web App</h2>
<p>La <strong>Web App</strong> è stata sviluppata come un prototipo funzionante, tuttavia per essere considerato completo richiederebbe ancora del lavoro di rifinitura.</p>
<section id="considerazioni-tecnologiche" data-number="6.3.1">
<h3 data-number="6.3.1"><span class="header-section-number">6.3.1</span> Considerazioni tecnologiche</h3>
<p>L’applicazione è stata sviluppata utilizzando <strong>nodeJS</strong> e <strong>VueJS</strong>. Una scelta guidata dalla semplicità del framework javascript, che a differenza di <strong>React</strong> e <strong>Angular</strong> offre una curva di apprendimento ben più bassa, favorendo lo sviluppo. <strong>VueJS</strong> forniva inoltre il vantaggio di integrarsi perfettamente con AWS <strong>Amplify</strong>, a livello di <strong>front-end</strong>. Mentre a livello di <strong>back-end</strong> le comunicazioni sono perfettamente supportate dato che anche l’applicativo <strong>back-end</strong> è stato sviluppato con <strong>nodeJS</strong>.</p>
<p>Il comparto estetico è sviluppato utilizzando <strong>Vuetify</strong>, questa è un’estensione di <strong>VueJS</strong> che sembrava integrarsi meglio con il framework rispetto a <strong>BootstrapVue</strong>.</p>
<p>Per la comunicazione con le API <strong>REST</strong> si è scelto di utilizzare <strong>AXIOS</strong> rispetto ad <strong>AJAX</strong>, questo perché risulta di facile integrazione con <strong>VueJS</strong>, supporta le <strong>SPA</strong> e consente il facile utilizzo di <code>Async</code> e <code>Await</code>.</p>
<p>Mentre per le <code>websocket</code> si è scelto di usare le librerie di default, principalmente per la loro semplicità di utilizzo. È stata valutata l’adozione di <code>Socket.io</code> che forniva maggiori funzionalità e supporto a comunicazioni come l’utilizzo di <code>fall back</code>. Tali funzionalità, tuttavia, non erano utili per un utilizzo così basilare, pertanto l’idea di utilizzare questa libreria è stata accantonata.</p>
<p>Per quanto riguarda le <code>route</code> della pagina è stato utilizzato <strong>VueRouter</strong>, essendo l’unica alternativa.</p>
<p>Infine per facilitare lo sviluppo è stato utilizzato <strong>Vuex</strong> che consente di accedere da più punti ad un oggetto condiviso.</p>
</section>
<section id="note-sul-codice" data-number="6.3.2">
<h3 data-number="6.3.2"><span class="header-section-number">6.3.2</span> Note sul codice</h3>
<p>Per questioni di velocità e leggibilità si è deciso di dividere l’applicativo su più <code>view</code> : <strong>Home</strong> e <strong>Login</strong>.</p>
<p>Ogni <code>view</code> è composta da più componenti che a loro volta sono composti.</p>
<p>Tutti gli elementi di <strong>VueJS</strong> sono stati strutturati seguendo il modello del <strong>Single File Components</strong> che prevede di inserire il codice per lo <strong>Style</strong>(CSS), <strong>Markup</strong>(Vue/HTML) e <strong>Script</strong>(JavaScript) tutto nello stesso file.</p>
</section>
<section id="difficoltà-durante-lo-sviluppo" data-number="6.3.3">
<h3 data-number="6.3.3"><span class="header-section-number">6.3.3</span> Difficoltà durante lo sviluppo</h3>
<p>Lo sviluppo della <strong>Web App</strong> è stato fluido fino all’integrazione della prima chiamata alle <strong>API</strong>. Qui ci si è resi conto che le api non potevano essere chiamate direttamente dal <strong>Browser</strong>, mentre funzionavano perfettamente utilizzando sistemi come <strong>Postman</strong> e <strong>Reqbin</strong>.</p>
<p>E’ stato più volte riscontrato l’errore <strong>Cross-Origin Resource Sharing</strong> (CORS), che riguarda la possibilità di utilizzare altre sorgenti per attingere alle informazioni. Questo genere di verifica viene effettuata solo dal Browser ed è invece saltata su Postman e simili.</p>
<p>Dopo un investigazione siamo giunti alla conclusione che in fase di <strong>sviluppo</strong> avremmo potuto consentire ogni richiesta. Abbiamo quindi aggiunto le seguenti linee di codice nel file <code>Template.yaml</code> di <strong>SAM</strong>, per istruire il proxy cors di AWS a rispondere alle richieste con i campi aggiunti:</p>
<pre><code>        Globals:
          Api:
            EndpointConfiguration: REGIONAL
            Cors:
              AllowMethods: &quot;&#39;*&#39;&quot;
              AllowHeaders: &quot;&#39;*&#39;&quot;
              AllowOrigin: &quot;&#39;*&#39;&quot;</code></pre>
<p>L’errore ha smesso di presentarsi, ma poiché avevamo la necessità di testare sempre più funzioni e non era pensabile effettuare il deploy di sam per ogni prova, abbiamo iniziato ad eseguire un’ istanza di AWS <strong>Lambda</strong> localmente tramite il comando : <code>sam build &amp;&amp; sam local start-api</code>.</p>
<p>Giunti a questo punto il problema si è ripresentato e questa volta la soluzione è stata molto più ostica da trovare, nonostante il problema fosse lo stesso, ovvero la mancanza della risposta <strong>CORS</strong>.</p>
<figure>
<img src="Images/CorsErrorFrontEnd.PNG" id="fig:ErrorCorsBroswer" style="width:80.0%" alt="" /><figcaption>Errore lato Broswer<span label="fig:ErrorCorsBroswer"></span></figcaption>
</figure>
<figure>
<img src="Images/CorsErrorConsole.PNG" id="fig:ErrorCorsConsole" style="width:100.0%" alt="" /><figcaption>Errore lato console<span label="fig:ErrorCorsConsole"></span></figcaption>
</figure>
<p>Volenterosi di utilizzare e testare le funzioni lambda localmente abbiamo cercato una soluzione che risolvesse il problema in maniera esaustiva, giungendo finalmente una <a href="https://github.com/aws/aws-sam-cli/issues/323#issuecomment-483650280">Issue</a> che ha fornito la soluzione se pur non ottimale.</p>
<p>Il comando utilizzato: <code>npx lcp –proxyUrl http://localhost:3000/</code></p>
<p>La soluzione adottata implica l’avviare un server proxy CORS che risponda alle richieste <strong>OPTIONS</strong> e poi reindirizzi all’immagine docker di lambda. Ovviamente la WebApp dovra contattare il proxy e non direttamente il container.</p>
<p>Nonostante gli sviluppatori di SAM confermino il supporto alle chiamate CORS locali non siamo riusciti a farle funzionare in altra maniera.</p>
</section>
<section id="deployment" data-number="6.3.4">
<h3 data-number="6.3.4"><span class="header-section-number">6.3.4</span> Deployment</h3>
<p>Il repository è stato collegato e configurato per il continuous deployment, così da pubblicare le modifiche online non appena rilasciate, se il sito compila. Il sito, essendo pubblico, è stato protetto da password con l’utilizzo di Amplify.</p>
</section>
</section>
<section id="funzioni-serverless" data-number="6.4">
<h2 data-number="6.4"><span class="header-section-number">6.4</span> Funzioni Serverless</h2>
<p>In questa sezione del progetto sono, le principali difficoltà affrontate sono state legate all’apprendimento delle tecnologie <strong>AWS</strong> utilizzate:</p>
<ul class="incremental">
<li><p><strong>Lambda</strong>: I due principali problemi incontrati sono stati:</p>
<ul class="incremental">
<li><p>Lo sviluppo e il testing in locale che richiede l’ausilio della <strong>SAM CLI</strong> e della <strong>AWS CLI</strong>.</p></li>
<li><p>L’utilizzo del sdk di AWS per javascript, sopratutto quando era necessario contattare altri servizi come IoT Core o API Gateways.</p></li>
</ul></li>
<li><p><strong>IoT Core</strong>: Non sono state riscontrate particolari difficoltà se non con i certificati che non sono in un formato compatibile con la libreria <code>UMQTT</code> di Micropython.</p></li>
<li><p><strong>CloudWatch</strong>: Consultare i log delle funzioni lambda non risulta complicato, stesso non si può dire per i log delle websocket.</p></li>
<li><p><strong>IAM</strong>: Il sistema dei permessi di AWS è molto articolato e ci sono più modi per fornire i permessi, in generale la gestione dei permessi è stata faticosa. Alcuni permessi sono molto immediati, altri come quello per consultare i log di <strong>CloudWatch</strong> delle websocket molto meno, non tanto per i permessi più per il tool grafico o la sintassi di SAM.</p></li>
<li><p><strong>API gateway</strong>: L’esposizione delle <code>API</code> <strong>REST</strong> e delle web socket non è stata difficoltosa.</p></li>
<li><p><strong>SAM</strong>: Forse la parte più complicata dell’applicativo serverless, fornisce la possibilità di effettuare il deploy di <strong>Stack</strong> su <strong>AWS CloudFormation</strong>, con una sintassi tutta sua, orchestrare il deploy di : Funzioni Lambda, Regole IoT Core, Permessi IAM, Tabelle DynamoDB, API REST, Websocket e CloudWatch Event via Crono. Nonostante il grande sforzo per sfruttare al meglio SAM, il lavoro potrebbe essere ulteriormente automatizzato e perfezionato.</p></li>
</ul>
<section id="deployment-1" data-number="6.4.1">
<h3 data-number="6.4.1"><span class="header-section-number">6.4.1</span> Deployment</h3>
<p>L’intero stack che esclude il database principale, Aws Aplify e i dispositivi IOT può essere dispiegato tramite il comando <code>sam build &amp;&amp; sam deploy</code> Attualmente il deploy è dipendente da alcune variabili che sono configurabili con il flag <code>-g</code>, altre variabili sono incorporate e potrebbero essere scorporate alla stessa maniera se si volesse rendere il deploy multi-account.</p>
</section>
</section>
<section id="database-dynamodb" data-number="6.5">
<h2 data-number="6.5"><span class="header-section-number">6.5</span> Database DynamoDB</h2>
<p>Lo sviluppo del database è una parte critica del progetto, in un ottica di rendere l’applicativo veloce e scalabile il più possibile, abbiamo scelto di procedere con lo sviluppo di una tabella DynamoDB. DynamoDB offre una scalabilità e una velocità di interrogazione superiori ai database relazionali, per questo lo abbiamo scelto, inoltre la sua prefetta integrazione con il <strong>back-end</strong> lo rendeva ancora più appetibile.</p>
<p>Le difficoltà durante lo sviluppo del database sono state enormi. Partendo dalla documentazione e dalle guide che siamo riusciti a reperire, subito ci siamo trovati in difficoltà con il mindset necessario allo sviluppo del database, troppo legati all’ambito relazionale. Il database ha passato molti <strong>schemi</strong> diversi che sono stati raffinati mano a mano che la complessità e i meccanismi del DB venivano compresi. Questo comportava continue modifiche al DB e il testare e studiare sono diventati essenziali, motivo per cui abbiamo scelto di non includerlo all’interno del deploy <strong>SAM</strong>, non si voleva complicare il complicato.</p>
<section id="tool-utilizzati" data-number="6.5.1">
<h3 data-number="6.5.1"><span class="header-section-number">6.5.1</span> Tool utilizzati</h3>
<p>Durante lo sviluppo abbiamo utilizzato due strumenti per aiutarci aiutarci nella comprensione e nello sviluppo del sistema:</p>
<ul class="incremental">
<li><p><strong>NoSQL Workbench</strong> Il nuovo tool grafico di AWS ci ha permesso di visualizzare con maggiore chiarezza il database e di elaborare le query utilizzando <strong>PartiQL</strong>. Inoltre ci ha anche permesso di effettuare la creazione di tabelle utilizzando la connessione ad AWS.</p></li>
</ul>
<p><strong>PartiQL</strong> Una gradita sorpresa durante lo studi e lo sviluppo del database. Infatti questo consente di interrogare <strong>DynamoDB</strong> utilizzando la classica sintassi <strong>SQL</strong>, molto più espressiva dell’<strong>SDK</strong> javascript. Purtroppo l’implementazione al supporto <strong>PartiQL</strong> non è supportata totalmente e quindi grossa parte della sintassi <strong>SQL</strong> come proiezioni e query annidate non sono disponibili. Questo rende l’implementazione delle query più frammentata, e ci ha obbligato a riscrivere varie parti di codice e DB. Tali limiti sono intrinseci di DynamoDB e non una mancanza di sviluppo parziale.</p>
</section>
</section>
<section id="immagini-prototipi" data-number="6.6">
<h2 data-number="6.6"><span class="header-section-number">6.6</span> Immagini prototipi</h2>
<figure>
<img src="Images/SmartCam.jpeg" id="fig:SmartCam" style="width:100.0%" alt="" /><figcaption>Prototipo Smart Cam<span label="fig:SmartCam"></span></figcaption>
</figure>
<figure>
<img src="Images/SmartCollar.jpeg" id="fig:SmartCollar" style="width:100.0%" alt="" /><figcaption>Prototipo Smart Collar<span label="fig:SmartCollar"></span></figcaption>
</figure>
<figure>
<img src="Images/SmartCage.png" id="fig:SmartCage" style="width:100.0%" alt="" /><figcaption>Prototipo Smart Cage<span label="fig:SmartCage"></span></figcaption>
</figure>
</section>
</section>
<section id="testing-e-performance" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Testing e Performance</h1>
<section id="automazione-gabbia-e-monitoraggio-salute" data-number="7.1">
<h2 data-number="7.1"><span class="header-section-number">7.1</span> Automazione Gabbia e Monitoraggio Salute</h2>
<section id="hardware-1" data-number="7.1.1">
<h3 data-number="7.1.1"><span class="header-section-number">7.1.1</span> Hardware</h3>
<p>Per quanto riguarda l’automazione di cibo e acqua e il monitoraggio dei parametri vitali dell’animale sono state testate multiple soluzioni hardware. In fase di validazione del progetto sono stati prese in esame principalmente due board che soddisfacessero i requisiti di economicità, connettività e prestazioni: L’ESP8266 e il successore ESP32. Entrambi offrono la connettività Wi-Fi integrata e buona potenza computazionale, cosa di cui è carente la board Arduino, e un costo contenuto (5€ per il primo e 7€ per il secondo, dati del primo semestre 2021) rispetto alla board Raspberry. Quest’ultima board offre connettività e prestazioni ma i costi sono decisamente fuori budget per il committente e per la natura distribuita dei compiti. La piattaforma ESP si è rivelata un buon compromesso e quindi si è passati a testarne i due differenti modelli.</p>
<p>Dopo i testing eseguiti in fase iniziale sono emerse differenze sostanziali nei tempi di avvio del programma e di connessione. Inoltre l’ESP8266 ha riscontrato spesso problemi nel caricamento dei file e nell’esecuzione di micropython. Di seguito si riporta la tabella riassuntiva per i tempi di esecuzione/comunicazione, accompagnati dalle caratteristiche dell’hardware.</p>
<p><img src="DrawIo/ConfrontoMicrocontrollori.png" style="width:90.0%" alt="image" /></p>
<p>Alla luce della minima differenza di prezzo tra i due device rispetto alla capacità computazionale, la scelta è ricaduta sul più recente ESP32.</p>
</section>
</section>
<section id="videosorveglianza" data-number="7.2">
<h2 data-number="7.2"><span class="header-section-number">7.2</span> Videosorveglianza</h2>
<section id="hardware-2" data-number="7.2.1">
<h3 data-number="7.2.1"><span class="header-section-number">7.2.1</span> Hardware</h3>
<p>Come anticipato in precedenza, il lato visione, di per se più computazionalmente oneroso, ha reso necessaria un’analisi più approfondita delle performance e la scelta è ricaduta su Raspberry Pi e ESP32-CAM. Inizialmente stato implementato un server web in C, per l’ESP ma il development è stato in seguito interrotto per la scarsa potenza potenza di quest’ultimo nell’elaborazione delle immagini. E’ stato tuttavia ritenuto valido per un’alternativa economica per il semplice streaming video senza elaborazione e notifica. Le board Raspberry Pi testate sono state le seguenti, con i rispettivi tempi di elaborazione:</p>
<p><img src="DrawIo/ConfrontoRaspberry.png" style="width:90.0%" alt="image" /></p>
<p>* i tempi si riferiscono all’attesa media per ottenere i risultati di object-detection attraverso una rete neurale con architettura Yolo3 con lo stesso set di immagini.</p>
<p>Considerando il rapporto costo/prestazioni, la scelta è ricaduta sul Raspberry Pi 3 B+ che con soli 0.7 secondi di distacco dal suo successore si posiziona su una fascia decisamente più economica.</p>
</section>
<section id="software" data-number="7.2.2">
<h3 data-number="7.2.2"><span class="header-section-number">7.2.2</span> Software</h3>
<p>Per quanto riguarda il software sono state testate le prestazioni dei due metodi per la detection di anomalie/intrusioni.Il secondo, più elaborato, su riconoscimento oggetti per mezzo di una rete neurale.</p>
<section id="motion-detection-1" data-number="7.2.2.1">
<h4 data-number="7.2.2.1"><span class="header-section-number">7.2.2.1</span> Motion Detection</h4>
<p>Il primo, più lineare, si basa su elaborazione delle immagini tramite sottrazione dello sfondo per rilevare del movimento. Le semplici operazioni di sfocatura gaussiana, differenza, soglia e calcolo dell’area sono state studiate per ottenere alte prestazioni circa la velocità di esecuzione dell’algoritmo. I test sperimentali sulla piattaforma scelta Raspberry Pi 3B+ hanno rilevato una media di 30 FPS sul materiale di test. Questa misura si è rivelata parecchio costante, poiché l’algoritmo non effettua un’analisi semantica delle immagini ma semplicemente delle operazioni matematiche indipendentemente dal contenuto. L’unico overhead dell’algoritmo risiede infatti nel calcolo dell’area dell’immagine cambiata qualora presente. Più questa è grande più tempo viene impiegato per calcolarla. Rispetto ai tempi di esecuzione e alle normale fluttuazioni delle prestazioni non è stata rilevata una differenza degna di nota (Si vedano gli FPS nonostante la grande area rilevata in [Fig. <a href="#fig:MDcomparison" data-reference-type="ref" data-reference="fig:MDcomparison">7.1</a>]</p>
<figure>
<img src="Images/MDcomparison.png" id="fig:MDcomparison" style="width:50.0%" alt="" /><figcaption>Surveillance with Motion Detection<span label="fig:MDcomparison"></span></figcaption>
</figure>
<p>La velocità dell’algoritmo va a discapito della precisione dello stesso. A seguito delle rilevazioni la matrice di confusione risulta non ottimale. Le motivazioni principali trovate risiedono nei seguenti scenari:</p>
<ul class="incremental">
<li><p>qualora una figura da rilevare stesse ferma o si muovesse lentamente, la soglia non sarebbe abbastanza alta da venir rilevata e ciò comporta dei falsi negativi. Non avendo nozione della semantica dell’immagine, l’algoritmo non può venir calibrato ulteriormente.</p></li>
<li><p>qualora un oggetto irrilevante (es: una mosca che passa vicino sulle lenti) produca un cambiamento significativo nell’immagine, la soglia viene superata e viene prodotto un falso positivo. Anche qui la mancanza di discernimento dell’algoritmo non può essere superata se non cambiandolo.</p></li>
<li><p>qualora l’oggetto estraneo sia lontano l’area di cambiamento risulta piccola e non supera la soglia, producendo falsi negativi. Se la soglia viene abbassata si incorre in falsi positivi per via di minimi cambiamenti ambientali.</p></li>
</ul>
<p>La matrice di confusione risultante in [Fig. <a href="#fig:MDmatrix" data-reference-type="ref" data-reference="fig:MDmatrix">7.2</a>] risulta chiaramente sbilanciata con parecchi falsi positivi. Questo deriva chiaramente dall’impossibilità discussa di discernere tra oggetti in movimento "non allarmanti" e viceversa. Per ovviare a questo problema nella sezione successiva si discuterà l’uso delle reti neurali e le prestazioni inerenti l’uso dell’object-detection.</p>
<figure>
<img src="DrawIo/ConfusionMatrixMotDet.png" id="fig:MDmatrix" style="width:90.0%" alt="" /><figcaption>Confusion matrix of Motion Detection<span label="fig:MDmatrix"></span></figcaption>
</figure>
</section>
<section id="object-detection-1" data-number="7.2.2.2">
<h4 data-number="7.2.2.2"><span class="header-section-number">7.2.2.2</span> Object Detection</h4>
<p>Il secondo metodo testato per la sorveglianza è l’object detection. Sono state confrontate 4 reti neurali per trovare la più adatta tra prestazioni e precisione. Nonostante sia stata scelta la board Raspberry tenendo il considerazione la potenza di calcolo, i fotogrammi al secondo hanno subito una brusca riduzione rispetto alla soluzione precedente. Il parametro minimo è stato fissato a 1 FPS, sotto il quale il divario temporale tra due immagini analizzate mancherebbe la rilevazione di possibili avvenimenti. La causa principale di tale crollo nelle prestazioni utilizzando questa soluzione è la mancanza di una GPU adatta nei Raspberry. Tale carenza è comunque colmabile con l’acquisto di espansioni USB dedicate all’espansione delle capacità grafiche della board (TPU). Immediatamente è risultato palese che le architetture delle reti tradizionalmente usate sui pc fossero troppo pesanti per il sistema ospitante. Per referenza è stata lasciata l’architettura (già di per se performante) Yolo3. Il focus quindi è stato soprattutto sull’individuazione di reti "leggere" che offrissero prestazioni adeguate. Sono state confrontate e testate le varie versioni "Tiny" della stessa rete come in tabella seguente:</p>
<p><img src="DrawIo/ConfrontoNeuralNetworks.png" style="width:90.0%" alt="image" /></p>
<p>Dopo l’analisi è risultato chiara la scelta della versione Yolo V4-Tiny, con il miglior numero di rilevazioni e una velocità adeguata alla videosorveglianza.</p>
<figure>
<img src="Images/ODcomparison.png" id="fig:ODcomparison" style="width:100.0%" alt="" /><figcaption>Surveillance with Object Detection<span label="fig:ODcomparison"></span></figcaption>
</figure>
<p>Le prestazioni sono state a livello di precisione sono state alte, come ci si aspetta da una rete neurale comparata "in the wild" a metodi tradizionali. Di seguito si riporta la matrice di confusione delle prove effettuate:</p>
<figure>
<img src="DrawIo/ConfusionMatrixObjDet.png" id="fig:ODmatrix" style="width:90.0%" alt="" /><figcaption>Confusion matrix of Object Detection<span label="fig:ODmatrix"></span></figcaption>
</figure>
</section>
</section>
</section>
</section>
<section id="analisi-di-deployment-su-larga-scala" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Analisi di Deployment su Larga Scala</h1>
<p>L’applicativo è stato modellato in ogni sua parte per scalare facilmente all’occorrenza. Il design distribuito e in cloud ne facilita l’eventuale evoluzione su larga scala. Verranno di seguito brevemente analizzati due scenari:</p>
<ul class="incremental">
<li><p><strong>Evoluzione Interna</strong> In termini di scalabilità del singolo software lo scenario più realistico consiste nell’aggiunta di elementi (gabbie o animali) da parte di un grande canile. L’aggiunta, anche cospicua, di elementi non porterebbe ulteriore complessità al sistema. Gli unici requisiti riguardano comprare l’hardware specifico da installare. Questo si occuperà attraverso il programma di mandare i dati direttamente al cloud, il quale li processerà e mostrerà le informazioni aggiornate sull’applicativo.</p></li>
<li><p><strong>Diffusione su Larga Scala</strong> In termini di diffusione del software in molteplici copie lo scenario riguarderebbe l’adozione dell’applicativo da parte di molteplici amministrazioni. Grazie all’adozione dei servizi AWS in Cloud, l’ <strong>availability</strong> e la <strong>scalability</strong> del sistema sono garantite anche ad alti livelli.</p></li>
</ul>
<p>L’attuale architettura hub and spoke, si rivela essere la scelta più fattibile anche su larga scala, data la sua buona integrazione con MQTT.</p>
<p>Uno dei principali punti di criticità dell’attuale architettura, nel momento in cui verrebbe fatto un deploy su larga scala, è dato dalla forte dipendenza del sistema dalla disponibilità di AWS in quanto se l’infrastruttura web crollasse o avesse dei problemi che ne influenzano il servizio, l’applicativo smetterebbe di funzionare. Questo problema può essere affrontato principalmente in due modi:</p>
<ul class="incremental">
<li><p>effettuare una replica dei servizi e dei dati in un’altra <strong>Availability Zone</strong> che si trova sotto la stessa <strong>region</strong> per ottenere <strong>fault tolerance</strong></p></li>
<li><p>effettuare una replica in una diversa regione di AWS. questa farà da base per l’applicazione di una strategia di <strong>disaster recovery</strong>.</p></li>
</ul>
<figure>
<img src="DrawIo/ScaledArchitecture.png" id="fig:NewArch" style="width:100.0%" alt="" /><figcaption>Nuova architettura in generale<span label="fig:NewArch"></span></figcaption>
</figure>
<section id="analisi-interna" data-number="8.1">
<h2 data-number="8.1"><span class="header-section-number">8.1</span> Analisi Interna</h2>
<p>I cambiamenti nella rete interna sono relativamente limitati, si suddividono in due parti</p>
<section id="adozione-di-hw-specifico" data-number="8.1.1">
<h3 data-number="8.1.1"><span class="header-section-number">8.1.1</span> Adozione di HW specifico</h3>
<p>L’utilizzo di Micro-python consente di sviluppare codice per una grande famiglia di micro-controllori. L’ESP-32 è stato scelto anche pensando ad uno sviluppo futuro dato che la sua famiglia presenta varie board che forniscono feature adatte agli ambienti più disparati. Su larga scala è ragionevole pensare che il codice di micro-python opportunamente riadattato consenta la scelta di una qualcunque di queste board alternative fornendo così un’adattabilità in termini di hardware elevata. Ad esempio, vi è la possibilità di integrare ESP che dispongono di tipi di connessione diversi, come l’ESP32-Ethernet-Kit V1.2 e l’ESP32-PICO-KIT-1.</p>
</section>
<section id="centralina-controllo" data-number="8.1.2">
<h3 data-number="8.1.2"><span class="header-section-number">8.1.2</span> Centralina controllo</h3>
<p>Dato che ogni ESP gestisce un singolo cane e ha una funzione critica, avere un ulteriore livello di controllo dell’ESP locale può aiutare nella preventiva rilevazione dei guasti locali dato che la rete locale è più affidabile ha una minore propensione ai guasti, fornendo alla centralina la possibilità di diagnosticare tramite messaggi interni eventuali guasti, effettuando controlli periodici.</p>
<p>L’integrazione delle funzioni tralasciate nell’applicativo locale realizzato durante questo progetto possono essere introdotte tramite <strong>Cloud formation</strong> mediante l’utilizzo di <strong>SAM</strong> (Serverless Application Model). Alcune di queste funzioni sono:</p>
<ul class="incremental">
<li><p><strong>Amazon Cognito:</strong> attualmente il sistema gestisce il salvataggio degli utenti all’interno del DataBase. In un’ottica di deployment su larga scala l’attuale soluzione risulterebbe poco adatta. Un approccio decisamente migliore sarebbe quello di affidare la gestione degli utenti ad Amazon Cognito ed integrarlo con Amazon AWS Amplify.</p></li>
<li><p><strong>Dynamo DB:</strong> il sistema attuale utilizza due tabelle Dynamo DB, la prima è creata tramite SAM e viene utilizzata per la gestione delle WebSocket, la seconda è creata manualmente e contiene i dati del canile. Dato che la seconda modalità non è applicabile su larga scala, sarebbe necessario automatizzare anche la creazione del database principale, specificando le varie proprietà come lo schema e i valori di throughput.</p></li>
<li><p><strong>IoT Core:</strong> è possibile automatizzare il rilascio dei certificati e dei permessi necessari per i dispositivi e aggiungere il relativo dispositivo <strong>shadow</strong> che mantiene l’ultimo stato conosciuto consentendo così di interrogare il dispositivo anche quando offline.</p></li>
</ul>
<p>La libreria UMQTT di Micro-Python consente di utilizzare solo la QoS (Quality of Service) di livello 1 o 0. Attualmente il sistema utilizza QoS di livello 0. Poiché questo applicativo non ha particolari vincoli di velocità per lo scambio dei messaggi è possibile valutare anche l’utilizzo di una QoS superiore. Nel caso in cui si volesse avere la possibilità di avere una QoS di livello 2, che garantisce di ricevere messaggi con certezza, sarà necessario ricorre ad un’alternativa poiché UMQTT supporta fino al livello 1. Sarà inoltre necessario sostituire il broker MQTT di IoT Core con un broker in grado di supportare lvl 2, come ad esempio HiveMQ</p>
</section>
</section>
<section id="analisi-esterna" data-number="8.2">
<h2 data-number="8.2"><span class="header-section-number">8.2</span> Analisi Esterna</h2>
<p>Il database principale gestisce attualmente i dati dei cani, le relative rilevazioni e gli utenti. Questa struttura si è rivelata necessaria poiché ai fini della realizzazione del progetto non vi era la possibilità di sviluppare una parte gestionale in quanto non inerente al corso. Uno sviluppo futuro vede necessaria una rielaborazione del sistema che permetta di effettuare una netta divisione tra la parte gestionale e quella relativa ai dati provenienti dai dispositivi di sensing. Questo porterebbe ad utilizzare il Database attuale solo per immagazzinare le rilevazioni, le quali generano una grande quantità di record. La gestione dei profili dei cani e di quelli degli utenti, andrebbe invece considerata a parte all’interno di un sistema prettamente gestionale. Si potrebbe, ad esempio, utilizzare Amazon Cognito per gestire gli utenti e un DB relazionale per i profili dei cani, il quale porterebbe come vantaggio l’integrità referenziale dei dati e seppur meno performante dovrebbe gestire pochi record.</p>
</section>
<section id="analisi-complessiva" data-number="8.3">
<h2 data-number="8.3"><span class="header-section-number">8.3</span> Analisi complessiva</h2>
<section id="sicurezza" data-number="8.3.1">
<h3 data-number="8.3.1"><span class="header-section-number">8.3.1</span> Sicurezza</h3>
<p>Nella realizzazione della soluzione attuale non ci si è preoccupati particolarmente della sicurezza. Attualmente le API REST disponibili su API Gateway sono prive di qualunque tipo di autenticazione, questo vale anche per le WEB Socket. Per effettuare il deploy dell’applicativo è necessario autenticare ogni richiesta utilizzando, ad esempio API Gateway Lambda Authorizer. Ciò richiede la scrittura di policy dedicate e maggiormente restrittive rispetto alle attuali full access policy.</p>
<p>Attualmente i micro-controllori, per autenticarsi presso AWS, utilizzano una chiave privata senza verificare la validità del certificato del server. Questo espone i micro-controllori ad un attacco di tipo <strong>man in the middle</strong>. Se si volesse fare un utilizzo reale del sistema, questo sarebbe un problema da risolvere in maniera prioritaria.</p>
<p>Se il sistema dovesse essere dispiegato su larga scala si dovrebbe tenere in considerazione il fatto che, a fronte di modifiche a livello di codice, sarebbe pesante dover fare ogni volta il deploy in corso d’opera per testare le funzionalità. Per questo motivo è utile fare in modo che le funzionalità possano essere provate anche in locale, permettendo così di fare il deploy solo quando davvero necessario. Per abilitare il testing in locale è possibile utilizzare SAM CLI che permette di hostare localmente un’istanza Docker per le chiamale Lambda.</p>
</section>
</section>
</section>
<section id="piano-di-lavoro" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Piano di lavoro</h1>
<p>Il lavoro è stato svolto utilizzando un approccio Scrum, con quattro sprint, più uno iniziale incentrato sullo studio delle tecnologie.</p>
<section id="contributi" data-number="9.1">
<h2 data-number="9.1"><span class="header-section-number">9.1</span> Contributi</h2>
<p>Di seguito vi è una descrizione delle mansioni che sono state svolte dai membri del gruppo.</p>
<section id="sara-kiade" data-number="9.1.0.0.1">
<h5 data-number="9.1.0.0.1"><span class="header-section-number">9.1.0.0.1</span> Sara Kiade</h5>
<ul class="incremental">
<li><p>progettazione e realizzazione del database</p></li>
<li><p>implementazione logiche di interrogazione e calcolo nel back-end della Web-App</p></li>
<li><p>implementazione e testing delle funzioni nel front end</p></li>
<li><p>stesura template delle funzioni nel back-end</p></li>
<li><p>configurazione SAM</p></li>
<li><p>prototyping della sensoristica</p></li>
<li><p>realizzazione diagrammi sequenza</p></li>
</ul>
</section>
<section id="gyordan-caminati" data-number="9.1.0.0.2">
<h5 data-number="9.1.0.0.2"><span class="header-section-number">9.1.0.0.2</span> Gyordan Caminati</h5>
<ul class="incremental">
<li><p>implementazione del front-end</p></li>
<li><p>integrazione nelle adeguate pagine del front-end delle chiamate al backend</p></li>
<li><p>configurazione SAM</p></li>
<li><p>implementazione di alcune funzioni nel backend</p></li>
<li><p>scheduling di funzioni lambda innescate da Crono Cloud Watch, MQTT, Api Gateway</p></li>
<li><p>implementazione scheduler Micropython</p></li>
<li><p>prototyping della sensoristica</p></li>
<li><p>realizzazione diagrammi sequenza</p></li>
</ul>
</section>
<section id="igor-lirussi" data-number="9.1.0.0.3">
<h5 data-number="9.1.0.0.3"><span class="header-section-number">9.1.0.0.3</span> Igor Lirussi</h5>
<ul class="incremental">
<li><p>implementazione scheduler Micropython</p></li>
<li><p>implementazione funzioni core di Micropython e classi per sensori/attuatori</p></li>
<li><p>implementazione sistema di videosorveglianza con motion detecion e object detection</p></li>
<li><p>implementazione script di automatizzazione caricamento file</p></li>
<li><p>prototyping della sensoristica</p></li>
<li><p>progettazione e implementazione macchina a stati</p></li>
</ul>
<p>La collocazione temporale degli sprint è descritta nel seguente diagramma di Gantt:</p>
<p>] <img src="DrawIo/GanttChart.png" title="fig:" id="fig:Gantt" style="width:100.0%" alt="Gantt Chart del progetto" /></p>
</section>
</section>
<section id="svolgimento" data-number="9.2">
<h2 data-number="9.2"><span class="header-section-number">9.2</span> Svolgimento</h2>
<p>Gli sprint sono stati portati avanti nel seguente modo:</p>
<section id="sprint-planning" data-number="9.2.0.0.1">
<h5 data-number="9.2.0.0.1"><span class="header-section-number">9.2.0.0.1</span> Sprint Planning</h5>
<p>Pianificazione a inizio sprint degli obiettivi, tempistiche e responsabilità nel periodo dello sprint corrente. Diviso in due parti:</p>
<ul class="incremental">
<li><p><strong>parte 1</strong> Viene raffinato e rivisto il product backlog, viene effettuata la scelta dello sprint goal (what).</p></li>
<li><p><strong>parte 2</strong> Si decidono gli item e viene raffinato come implementarli (how). Effettuato con solo il team senza la figura del product owner</p></li>
</ul>
</section>
<section id="iterativo-daily-scrum" data-number="9.2.0.0.2">
<h5 data-number="9.2.0.0.2"><span class="header-section-number">9.2.0.0.2</span> [Iterativo] Daily scrum</h5>
<p>Breve meeting svolto giornalmente. Viene utilizzato per gli aggiornamenti sull’andamento del progetto, senza scendere nei dettagli implementativi.</p>
</section>
<section id="occasionale-pair-programming" data-number="9.2.0.0.3">
<h5 data-number="9.2.0.0.3"><span class="header-section-number">9.2.0.0.3</span> [Occasionale] Pair Programming </h5>
<p>Utilizzato per risolvere problemi che causano il blocco di un componente del team per parecchio tempo su una issue.</p>
</section>
<section id="meeting-finale" data-number="9.2.0.0.4">
<h5 data-number="9.2.0.0.4"><span class="header-section-number">9.2.0.0.4</span> Meeting finale</h5>
<p>Riflessioni e considerazioni finali sullo spint passato. Suggerimenti per migliorare il prossimo. Diviso in tre parti:</p>
<ul class="incremental">
<li><p><strong>Product backlog refinement</strong> aggiunta di dettagli e riordino del product backlog</p></li>
<li><p><strong>Sprint review</strong> è stato ispezionato l’incremento, il Minimum Viable Product o di risultati sul processo. Discernere cosa è stato fatto e cosa no</p></li>
<li><p><strong>Retrospettiva</strong> Considerazioni sul team stesso e sui miglioramenti per il prossimo sprint.</p></li>
</ul>
</section>
</section>
<section id="sprint-0" data-number="9.3">
<h2 data-number="9.3"><span class="header-section-number">9.3</span> Sprint 0</h2>
<p>All’interno dello sprint 0 il focus è stato sullo scegliere le giuste tecnologie di sviluppo e sull’apprenderle in maniera sufficiente per il kick-off del progetto. L’obiettivo è stato raggiungere una conoscenza e competenza minima per sviluppare il design in maniera consapevole e ottimale.</p>
<section id="deliverables" data-number="9.3.0.0.1">
<h5 data-number="9.3.0.0.1"><span class="header-section-number">9.3.0.0.1</span> Deliverables</h5>
<p>al termine di questo sprint si sono acquisite le competenze di base per poter iniziare a lavorare con AWS e i dispositivi IoT. Inoltre ci si è portati avanti con lo scheletro del sito.</p>
<ul class="incremental">
<li><p>ambiente di lavoro Linux standardizzato e virtualizzato</p></li>
<li><p>sito linkato, con le prime due pagine base: home e login</p></li>
<li><p>ESP32 con firmware installato MicroPython, script e guida all’uso</p></li>
<li><p>codice per sensori base, test relativi e stubs per eseguirli senza necessità del micro-controllore</p></li>
<li><p>repository software con CI e test automatizzati</p></li>
<li><p>database progettato e popolato con qualche dato ai fini di testing</p></li>
</ul>
</section>
</section>
<section id="sprint-1" data-number="9.4">
<h2 data-number="9.4"><span class="header-section-number">9.4</span> Sprint 1</h2>
<p>All’interno dello sprint 1 il focus è stato sull’usare le competenze tecnologiche acquisite precedentemente per sviluppare i componenti principali del progetto. Sono stati scelti come obiettivi le user stories per l’automatizzazione di cibo e acqua e la visualizzazione delle informazioni relative a un animale sulla webpage.</p>
<section id="deliverables-1" data-number="9.4.0.0.1">
<h5 data-number="9.4.0.0.1"><span class="header-section-number">9.4.0.0.1</span> Deliverables</h5>
<p>al termine di questo sprint sono state implementate le funzioni base dei maggiori componenti per l’automatizzazione fisica di cibo e acqua e il relativo prototipo fisico. Sono state aggiunte sull’applicativo la vista delle informazioni dell’animale e l’impostazione del cibo da erogargli.</p>
<ul class="incremental">
<li><p>codice per i sensori/attuatori per acqua e cibo, con stubs, test e automatizzazione. (Livello acqua, elettrovalvola, motore, bilancia, laser e rilevatore di luce)</p></li>
<li><p>prototipo fisico per i sensori per acqua e cibo.</p></li>
<li><p>database migliorato e rifattorizzato</p></li>
<li><p>visualizzazione dei dati del cane sul sito</p></li>
<li><p>visualizzazione dei grafici delle statistiche sul sito</p></li>
</ul>
</section>
</section>
<section id="sprint-2" data-number="9.5">
<h2 data-number="9.5"><span class="header-section-number">9.5</span> Sprint 2</h2>
<p>Nello sprint 2 il focus è stato sul realizzare la logica d’orchestrazione della sensoristica e l’integrazione tra essa e l’applicativo per mezzo del protocollo MQTT. Sono stati prodotti gli artefatti di documentazione e schemi esemplificativi. Inoltre, è stato dato peso alla creazione delle query che permettono di integrare le funzioni del sito con il database. In particolare ci si è concentrati sulle user-stories prioritarie, che costituiscono il core del dominio.</p>
<section id="deliverables-2" data-number="9.5.0.0.1">
<h5 data-number="9.5.0.0.1"><span class="header-section-number">9.5.0.0.1</span> Deliverables</h5>
<ul class="incremental">
<li><p>sviluppate query necessarie alla logica centrale dell’applicazione web</p></li>
<li><p>grafici per la temperatura e l’umidità nell’applicazione web</p></li>
<li><p>implementata coverage dei test Python, con relativa pagina web su Github pages.</p></li>
<li><p>aggiunta Quality Assurance con SonarCloud, Codacy e Codefactor</p></li>
<li><p>implementata Continuous Delivery con GitHub Actions e GitHub Releases</p></li>
<li><p>implementata macchina a stati per food delivery e water automation</p></li>
</ul>
</section>
</section>
<section id="sprint-3" data-number="9.6">
<h2 data-number="9.6"><span class="header-section-number">9.6</span> Sprint 3</h2>
<p>Nello sprint 3 sono state implementate le query che verranno chiamate dal sito per mostrare gli elementi all’utente. Inoltre, è stato migrato il codice JavaScript in un repository dedicato che permette il deployment delle funzioni in automatico su AWS con SAM. Sono state sviluppate le funzioni per ottenere i dati della sensoristica del collare smart, implementando la logica per il controllo dei valori e l’invio delle notifiche su MQTT.</p>
<section id="deliverables-3" data-number="9.6.0.0.1">
<h5 data-number="9.6.0.0.1"><span class="header-section-number">9.6.0.0.1</span> Deliverables</h5>
<ul class="incremental">
<li><p>sviluppate query complesse necessarie alla logica centrale dell’applicazione web</p></li>
<li><p>repository dedicato delle funzioni JavaScript per AWS</p></li>
<li><p>setup framework SAM per automazione AWS</p></li>
<li><p>prototipo fisico per i sensori di temperatura e battito</p></li>
<li><p>implementata macchina a stati per smart-collar heartbeat e temperature</p></li>
</ul>
</section>
</section>
<section id="sprint-4" data-number="9.7">
<h2 data-number="9.7"><span class="header-section-number">9.7</span> Sprint 4</h2>
<p>Lo sprint 4 è stato il più impegnativo, perché vi era la necessità di chiudere il progetto, portando a termine tutti i task preventivati. Una grossa parte dello sprint è stata dedicata all’integrazione delle diverse parti, alla chiusura delle ultime interrogazioni al database, all’inserimento degli ultimi pezzi dell’interfaccia grafica che permettono all’utente di interagire con il back-end e alla conclusione del sistema di sorveglianza.</p>
<section id="deliverables-4" data-number="9.7.0.0.1">
<h5 data-number="9.7.0.0.1"><span class="header-section-number">9.7.0.0.1</span> Deliverables</h5>
<ul class="incremental">
<li><p>Completamento WebApp che permette all’utente di interagire con il sistema, visualizzando i dati e apportando delle modifiche.</p></li>
<li><p>Completamento Back-end che gestisce la logica del sito</p></li>
<li><p>Completamento gestione di sensori, attuatori e sistema di sorveglianza.</p></li>
</ul>
</section>
</section>
</section>
<section id="conclusioni" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Conclusioni</h1>
<p>Al termine del percorso che ha portato alla realizzazione di questo progetto è stato raggiunto un risultato che riteniamo molto soddisfacente. Sono state utilizzate e integrate diverse tecnologie, il che ci ha permesso di acquisire ed affinare competenze a tutto tondo. Riteniamo inoltre che il progetto sia stato particolarmente ambizioso e gli sforzi sono stati commisurati alla soddisfazione finale per averlo completato. Questo lavoro, inoltre, potrebbe rappresentare una buona base di partenza per lo sviluppo di un sistema reale che porti un reale vantaggio alla realtà dei rifugi per animali.</p>
<section id="sviluppi-futuri" data-number="10.1">
<h2 data-number="10.1"><span class="header-section-number">10.1</span> Sviluppi Futuri</h2>
<p>In futuro sarebbe possibile estendere il sistema aggiungendo una parte gestionale. I due canili che abbiamo interpellato, infatti, sono sprovvisti anche della più basilare forma di sistema informatico, fatta eccezione per l’anagrafe canina che però non è ottimizzata per l’utilizzo che ne devono fare e ancora tanto lavoro viene affidato alle capacità di ragionamento e deduzione del personale del canile. Si potrebbe inoltre integrare il sistema aggiungendo altre feature, come l’inserimento di un nuovo cane mediante la lettura dei dati direttamente dal chip oppure l’introduzione di una più importante elaborazione dei dati, soprattutto per quanto riguarda le immagini provenienti dalla videocamera che potrebbero dare un importante aiuto ai gestori se gli venisse applicata una logica che, ad esempio, permette di rilevare comportamenti anomali del cane. Si potrebbe inoltre aggiungere un sistema di tracciamento mediante gps in maniera tale da permettere ai volontari o alle famiglie che, nella fase di pre-affidamento, vorrebbero abituare il cane alla loro presenza, di portare il cane a fare una passeggiata, senza temere che il cane possa scappare e perdersi.</p>
<p>Un altro possibile sviluppo riguarda il dispiegamento del sistema su larga scala, affinché possa essere utilizzato da più canili. A questo punto se si riuscisse ad introdurre un’elaborazione migliore delle soglie standard dei consumi e dei parametri vitali, ci si potrebbe basare sulle medie di più cani, cosa che permetterebbe di evitare che debba essere il veterinario ad impostare manualm,ente le soglie che ritiene più adeguate per ciascuna cane basandosi su razza, tagli, età e precedenti clinici.</p>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-umqtt2">
<p>8266, UMQTT ESP. n.d. <a href="https://awsiot.wordpress.com/2019/01/10/connect-8266-to-aws-mqtt-using-miropython/">https://awsiot.wordpress.com/2019/01/10/connect-8266-to-aws-mqtt-using-miropython/</a>.</p>
</div>
<div id="ref-Cors">
<p>CORS Error, Usefull Issue for. n.d. <a href="https://github.com/aws/aws-sam-cli/issues/323#issuecomment-483650280">https://github.com/aws/aws-sam-cli/issues/323#issuecomment-483650280</a>.</p>
</div>
<div id="ref-VueJS">
<p>Docs, VueJS. n.d. <a href="https://vuejs.org/v2/guide/">https://vuejs.org/v2/guide/</a>.</p>
</div>
<div id="ref-Vuetify">
<p>Docs, Vuetify. n.d. <a href="https://vuetifyjs.com/en/getting-started/installation/">https://vuetifyjs.com/en/getting-started/installation/</a>.</p>
</div>
<div id="ref-AWSSAM">
<p>documentation, AmazonWebServices SAM. n.d. <a href="https://github.com/aws/serverless-application-model/blob/master/versions/2016-10-31.md#api">https://github.com/aws/serverless-application-model/blob/master/versions/2016-10-31.md#api</a>.</p>
</div>
<div id="ref-Microp">
<p>Documentation, Micropython. n.d. <a href="https://docs.micropython.org/en/latest/esp32/quickref.html">https://docs.micropython.org/en/latest/esp32/quickref.html</a>.</p>
</div>
<div id="ref-AWS">
<p>Documentations, AWS. n.d. <a href="https://docs.aws.amazon.com/index.html">https://docs.aws.amazon.com/index.html</a>.</p>
</div>
<div id="ref-DynamoDbW">
<p>DynamoDB, Workbench for. n.d. <a href="https://aws.amazon.com/it/blogs/database/data-modeling-with-nosql-workbench-for-amazon-dynamodb/">https://aws.amazon.com/it/blogs/database/data-modeling-with-nosql-workbench-for-amazon-dynamodb/</a>.</p>
</div>
<div id="ref-ESP8266MQTT">
<p>Example, ESP8266 MQTT. n.d. <a href="https://girishjoshi.io/post/esp8266-using-mqtt/">https://girishjoshi.io/post/esp8266-using-mqtt/</a>.</p>
</div>
<div id="ref-umqtt">
<p>Example, UMQTT. n.d. <a href="https://mpython.readthedocs.io/en/master/library/mPython/umqtt.simple.html?highlight=umqtt.#module-umqtt.simple">https://mpython.readthedocs.io/en/master/library/mPython/umqtt.simple.html?highlight=umqtt.#module-umqtt.simple</a>.</p>
</div>
<div id="ref-DynamoDbData">
<p>Model, DynamoDB Data. n.d. <a href="https://codeburst.io/dynamodb-data-modeling-7f11950b25bf">https://codeburst.io/dynamodb-data-modeling-7f11950b25bf</a>.</p>
</div>
<div id="ref-yolov3">
<p>Redmon, Joseph, and Ali Farhadi. 2018. “YOLOv3: An Incremental Improvement.” <em>arXiv</em>. <a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a>.</p>
</div>
<div id="ref-WearableH">
<p>Rita Brugarolas, James Dieffenderfe, Tahmid Latif. n.d. “Wearable Heart Rate Sensor Systems for Wireless Canine Health Monitoring.” <a href="https://ciigar.csc.ncsu.edu/files/bib/Brugarolas2015-DogHeartMonitor.pdf">https://ciigar.csc.ncsu.edu/files/bib/Brugarolas2015-DogHeartMonitor.pdf</a>.</p>
</div>
<div id="ref-StackOverflow">
<p>StackOverflow, Some. n.d. <a href="https://stackoverflow.com/">https://stackoverflow.com/</a>.</p>
</div>
<div id="ref-AWSTutorialonSAM">
<p>Tutorial, AmazonWebServices SAM. n.d. <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-getting-started-hello-world.html">https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-getting-started-hello-world.html</a>.</p>
</div>
<div id="ref-uasyncio">
<p>uasyncio. n.d. “ Application of uasyncio to hardware interfaces.” <a href="https://github.com/peterhinch/micropython-async/blob/master/v3/docs/TUTORIAL.md">https://github.com/peterhinch/micropython-async/blob/master/v3/docs/TUTORIAL.md</a>.</p>
</div>
</div>
</section>
</section>                    
                </div>
            </div>

            <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>
        </div>
    </body>
</html>
